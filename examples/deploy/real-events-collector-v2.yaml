apiVersion: v1
kind: ConfigMap
metadata:
  name: real-events-collector-script
  namespace: right-sizer
data:
  collector.py: |
    #!/usr/bin/env python3
    import json
    import re
    import time
    import os
    from datetime import datetime, timedelta
    from collections import deque
    from http.server import HTTPServer, BaseHTTPRequestHandler
    import threading
    from kubernetes import client, config

    class EventsCollector:
        def __init__(self, max_events=100):
            self.events = deque(maxlen=max_events)
            self.lock = threading.Lock()
            self.v1 = None
            self.setup_kubernetes_client()

        def setup_kubernetes_client(self):
            """Setup Kubernetes client using in-cluster config"""
            try:
                config.load_incluster_config()
                self.v1 = client.CoreV1Api()
                print("Kubernetes client configured successfully")
            except Exception as e:
                print(f"Error configuring Kubernetes client: {e}")
                raise

        def parse_log_line(self, line):
            """Parse a log line for optimization events"""
            # Pattern for resize events
            resize_pattern = r'(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2}).*Pod (\S+)/(\S+)/(\S+) - Planned resize: CPU: (\S+)→(\S+), Memory: (\S+)→(\S+)'
            match = re.search(resize_pattern, line)

            if match:
                timestamp_str, namespace, pod_name, container, cpu_from, cpu_to, mem_from, mem_to = match.groups()

                # Parse actual usage from scaling analysis if available
                actual_cpu = None
                actual_mem = None
                analysis_pattern = r'Scaling analysis - CPU: scale \w+ \(usage: ([\d.]+)m?/[\d.]+m?, [\d.]+%\), Memory: scale \w+ \(usage: ([\d.]+)Mi?/[\d.]+Mi?, [\d.]+%\)'
                analysis_match = re.search(analysis_pattern, line)
                if analysis_match:
                    actual_cpu = f"{analysis_match.group(1)}m"
                    actual_mem = f"{analysis_match.group(2)}Mi"

                # Calculate savings
                cpu_savings = self.calculate_savings(cpu_from, cpu_to)
                mem_savings = self.calculate_savings(mem_from, mem_to)

                event = {
                    "timestamp": datetime.now().isoformat() + "Z",
                    "eventId": f"opt-{namespace}-{pod_name}-{int(time.time() * 1000)}",
                    "podName": pod_name,
                    "namespace": namespace,
                    "containerName": container,
                    "operation": "resource_optimization",
                    "reason": "Real-time optimization based on actual metrics",
                    "status": "completed",
                    "action": "resource_change",
                    "previousCPU": cpu_from,
                    "newCPU": cpu_to,
                    "previousMemory": mem_from,
                    "newMemory": mem_to,
                    "currentCPU": actual_cpu or cpu_to,
                    "currentMemory": actual_mem or mem_to,
                    "actualUsageCPU": actual_cpu,
                    "actualUsageMemory": actual_mem,
                    "savings": max(cpu_savings, mem_savings),
                    "source": "real-metrics",
                    "isRealData": True
                }
                return event

            # Pattern for usage detection
            usage_pattern = r'Container (\S+)/(\S+)/(\S+) will be resized - CPU: (\S+)→(\S+), Memory: (\S+)→(\S+)'
            match = re.search(usage_pattern, line)
            if match:
                namespace, pod_name, container, cpu_from, cpu_to, mem_from, mem_to = match.groups()

                event = {
                    "timestamp": datetime.now().isoformat() + "Z",
                    "eventId": f"opt-{namespace}-{pod_name}-{int(time.time() * 1000)}",
                    "podName": pod_name,
                    "namespace": namespace,
                    "containerName": container,
                    "operation": "container_resize",
                    "reason": "Container resource adjustment",
                    "status": "planned",
                    "action": "resource_change",
                    "previousCPU": cpu_from,
                    "newCPU": cpu_to,
                    "previousMemory": mem_from,
                    "newMemory": mem_to,
                    "savings": self.calculate_savings(cpu_from, cpu_to),
                    "source": "real-metrics",
                    "isRealData": True
                }
                return event

            return None

        def calculate_savings(self, from_val, to_val):
            """Calculate percentage savings"""
            try:
                from_num = self.parse_resource_value(from_val)
                to_num = self.parse_resource_value(to_val)

                if from_num > 0:
                    savings = ((from_num - to_num) / from_num) * 100
                    return max(0, int(savings))
            except:
                pass
            return 0

        def parse_resource_value(self, value):
            """Parse resource value to float"""
            if not value or value == "0":
                return 0
            # Remove units and convert
            match = re.search(r'([\d.]+)', value)
            if match:
                return float(match.group(1))
            return 0

        def collect_from_logs(self):
            """Continuously collect events from Right Sizer logs"""
            while True:
                try:
                    # Get Right Sizer pods
                    pods = self.v1.list_namespaced_pod(
                        namespace="right-sizer",
                        label_selector="app=right-sizer"
                    )

                    for pod in pods.items:
                        if pod.status.phase != "Running":
                            continue

                        try:
                            # Get logs from the last 5 minutes
                            since_seconds = 300
                            logs = self.v1.read_namespaced_pod_log(
                                name=pod.metadata.name,
                                namespace="right-sizer",
                                since_seconds=since_seconds,
                                tail_lines=1000
                            )

                            for line in logs.split('\n'):
                                event = self.parse_log_line(line)
                                if event:
                                    with self.lock:
                                        # Check for duplicates
                                        exists = any(
                                            e['podName'] == event['podName'] and
                                            e['namespace'] == event['namespace'] and
                                            abs(self.timestamp_diff(e['timestamp'], event['timestamp'])) < 60
                                            for e in self.events
                                        )
                                        if not exists:
                                            self.events.append(event)
                                            print(f"Added real event: {event['podName']} in {event['namespace']}")

                        except Exception as e:
                            print(f"Error reading logs from {pod.metadata.name}: {e}")

                    # Also check for actual metrics
                    self.add_current_metrics_events()

                except Exception as e:
                    print(f"Error collecting logs: {e}")

                time.sleep(30)  # Check every 30 seconds

        def timestamp_diff(self, ts1, ts2):
            """Calculate difference between timestamps in seconds"""
            try:
                dt1 = datetime.fromisoformat(ts1.replace('Z', '+00:00'))
                dt2 = datetime.fromisoformat(ts2.replace('Z', '+00:00'))
                return abs((dt2 - dt1).total_seconds())
            except:
                return 0

        def add_current_metrics_events(self):
            """Add events based on current pod metrics"""
            try:
                # Try to get metrics
                metrics_api = client.CustomObjectsApi()
                pods_metrics = metrics_api.list_cluster_custom_object(
                    group="metrics.k8s.io",
                    version="v1beta1",
                    plural="pods"
                )

                for pod_metric in pods_metrics.get('items', []):
                    namespace = pod_metric['metadata']['namespace']
                    pod_name = pod_metric['metadata']['name']

                    for container in pod_metric.get('containers', []):
                        cpu_usage = container['usage'].get('cpu', '0')
                        mem_usage = container['usage'].get('memory', '0')

                        # Create a metrics observation event
                        event = {
                            "timestamp": datetime.now().isoformat() + "Z",
                            "eventId": f"metrics-{namespace}-{pod_name}-{int(time.time() * 1000)}",
                            "podName": pod_name,
                            "namespace": namespace,
                            "containerName": container['name'],
                            "operation": "metrics_observation",
                            "reason": "Current resource usage",
                            "status": "active",
                            "action": "monitoring",
                            "currentCPU": cpu_usage,
                            "currentMemory": mem_usage,
                            "source": "metrics-server",
                            "isRealData": True
                        }

                        with self.lock:
                            # Only keep the latest metrics for each pod
                            self.events = deque(
                                [e for e in self.events if not (
                                    e.get('operation') == 'metrics_observation' and
                                    e['podName'] == pod_name and
                                    e['namespace'] == namespace
                                )],
                                maxlen=self.events.maxlen
                            )
                            self.events.append(event)

            except Exception as e:
                print(f"Could not fetch current metrics: {e}")

        def get_events(self):
            """Get all collected events"""
            with self.lock:
                # Sort by timestamp, most recent first
                events_list = list(self.events)
                events_list.sort(key=lambda x: x['timestamp'], reverse=True)
                return events_list

    class EventsHTTPHandler(BaseHTTPRequestHandler):
        collector = None

        def do_GET(self):
            if self.path in ['/events', '/events.json']:
                events = self.collector.get_events()
                response = {
                    "events": events,
                    "total": len(events),
                    "source": "real-time-collector",
                    "timestamp": datetime.now().isoformat() + "Z",
                    "isRealData": True
                }

                self.send_response(200)
                self.send_header('Content-Type', 'application/json')
                self.send_header('Access-Control-Allow-Origin', '*')
                self.send_header('Cache-Control', 'no-cache')
                self.end_headers()
                self.wfile.write(json.dumps(response, indent=2).encode())

            elif self.path == '/health':
                self.send_response(200)
                self.send_header('Content-Type', 'text/plain')
                self.end_headers()
                self.wfile.write(b"OK")

            else:
                self.send_response(404)
                self.end_headers()

        def do_OPTIONS(self):
            self.send_response(200)
            self.send_header('Access-Control-Allow-Origin', '*')
            self.send_header('Access-Control-Allow-Methods', 'GET, OPTIONS')
            self.send_header('Access-Control-Allow-Headers', '*')
            self.end_headers()

        def log_message(self, format, *args):
            # Only log errors
            if args[1] != '200':
                print(f"{self.address_string()} - {args[0]} - {args[1]}")

    def main():
        collector = EventsCollector(max_events=200)

        # Set the collector for the handler
        EventsHTTPHandler.collector = collector

        # Start log collection in background thread
        log_thread = threading.Thread(target=collector.collect_from_logs)
        log_thread.daemon = True
        log_thread.start()

        # Create HTTP server
        port = 8083
        server = HTTPServer(('0.0.0.0', port), EventsHTTPHandler)
        print(f"Real Events Collector v2 started on port {port}")
        print("Collecting real optimization events from Right Sizer...")
        print("Using Kubernetes API for direct log access")

        try:
            server.serve_forever()
        except KeyboardInterrupt:
            print("\nShutting down...")
            server.shutdown()

    if __name__ == "__main__":
        main()

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: real-events-collector
  namespace: right-sizer
  labels:
    app: real-events-collector
    component: events
    version: v2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: real-events-collector
  template:
    metadata:
      labels:
        app: real-events-collector
        component: events
        version: v2
    spec:
      serviceAccountName: right-sizer
      containers:
      - name: collector
        image: bitnami/kubectl:latest
        command:
        - sh
        - -c
        - |
          pip install kubernetes && \
          python /app/collector.py
        ports:
        - containerPort: 8083
          name: http
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        volumeMounts:
        - name: script
          mountPath: /app
        resources:
          requests:
            cpu: 50m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 8083
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 8083
          initialDelaySeconds: 20
          periodSeconds: 5
      volumes:
      - name: script
        configMap:
          name: real-events-collector-script
          defaultMode: 0755

---
apiVersion: v1
kind: Service
metadata:
  name: optimization-events-server
  namespace: right-sizer
  labels:
    app: real-events-collector
    component: events
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 8083
    protocol: TCP
    name: http
  selector:
    app: real-events-collector

---
apiVersion: v1
kind: Service
metadata:
  name: real-events-api
  namespace: right-sizer
  labels:
    app: real-events-collector
    component: events
spec:
  type: ClusterIP
  ports:
  - port: 8083
    targetPort: 8083
    protocol: TCP
    name: http
  selector:
    app: real-events-collector
