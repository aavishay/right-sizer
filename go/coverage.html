
<!DOCTYPE html>
<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<title>admission: Go Coverage Report</title>
		<style>
			body {
				background: black;
				color: rgb(80, 80, 80);
			}
			body, pre, #legend span {
				font-family: Menlo, monospace;
				font-weight: bold;
			}
			#topbar {
				background: black;
				position: fixed;
				top: 0; left: 0; right: 0;
				height: 42px;
				border-bottom: 1px solid rgb(80, 80, 80);
			}
			#content {
				margin-top: 50px;
			}
			#nav, #legend {
				float: left;
				margin-left: 10px;
			}
			#legend {
				margin-top: 12px;
			}
			#nav {
				margin-top: 10px;
			}
			#legend span {
				margin: 0 5px;
			}
			.cov0 { color: rgb(192, 0, 0) }
.cov1 { color: rgb(128, 128, 128) }
.cov2 { color: rgb(116, 140, 131) }
.cov3 { color: rgb(104, 152, 134) }
.cov4 { color: rgb(92, 164, 137) }
.cov5 { color: rgb(80, 176, 140) }
.cov6 { color: rgb(68, 188, 143) }
.cov7 { color: rgb(56, 200, 146) }
.cov8 { color: rgb(44, 212, 149) }
.cov9 { color: rgb(32, 224, 152) }
.cov10 { color: rgb(20, 236, 155) }

		</style>
	</head>
	<body>
		<div id="topbar">
			<div id="nav">
				<select id="files">
				
				<option value="file0">right-sizer/admission/webhook.go (0.0%)</option>
				
				<option value="file1">right-sizer/api/v1alpha1/rightsizerconfig_types.go (0.0%)</option>
				
				<option value="file2">right-sizer/api/v1alpha1/rightsizerpolicy_types.go (0.0%)</option>
				
				<option value="file3">right-sizer/api/v1alpha1/zz_generated.deepcopy.go (0.0%)</option>
				
				<option value="file4">right-sizer/audit/audit.go (0.0%)</option>
				
				<option value="file5">right-sizer/config/config.go (94.4%)</option>
				
				<option value="file6">right-sizer/controllers/adaptive_rightsizer.go (0.0%)</option>
				
				<option value="file7">right-sizer/controllers/deployment_rightsizer.go (0.0%)</option>
				
				<option value="file8">right-sizer/controllers/enhanced_setup.go (0.0%)</option>
				
				<option value="file9">right-sizer/controllers/inplace_rightsizer.go (22.1%)</option>
				
				<option value="file10">right-sizer/controllers/nondisruptive_rightsizer.go (0.0%)</option>
				
				<option value="file11">right-sizer/controllers/pod_controller_memory.go (0.0%)</option>
				
				<option value="file12">right-sizer/controllers/rightsizer_controller.go (0.0%)</option>
				
				<option value="file13">right-sizer/controllers/rightsizerconfig_controller.go (0.0%)</option>
				
				<option value="file14">right-sizer/controllers/rightsizerpolicy_controller.go (0.0%)</option>
				
				<option value="file15">right-sizer/health/checker.go (1.0%)</option>
				
				<option value="file16">right-sizer/logger/logger.go (0.0%)</option>
				
				<option value="file17">right-sizer/main.go (0.0%)</option>
				
				<option value="file18">right-sizer/metrics/memory_metrics.go (0.0%)</option>
				
				<option value="file19">right-sizer/metrics/metrics_server.go (0.0%)</option>
				
				<option value="file20">right-sizer/metrics/operator_metrics.go (0.0%)</option>
				
				<option value="file21">right-sizer/metrics/prometheus.go (0.0%)</option>
				
				<option value="file22">right-sizer/policy/engine.go (0.0%)</option>
				
				<option value="file23">right-sizer/retry/retry.go (0.0%)</option>
				
				<option value="file24">right-sizer/validation/resource_validator.go (0.0%)</option>
				
				</select>
			</div>
			<div id="legend">
				<span>not tracked</span>
			
				<span class="cov0">not covered</span>
				<span class="cov8">covered</span>
			
			</div>
		</div>
		<div id="content">
		
		<pre class="file" id="file0" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package admission

import (
        "context"
        "encoding/json"
        "fmt"
        "net/http"
        "strings"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"
        "right-sizer/validation"

        admissionv1 "k8s.io/api/admission/v1"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/apimachinery/pkg/runtime/serializer"
        "k8s.io/client-go/kubernetes"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// WebhookServer represents the admission webhook server
type WebhookServer struct {
        server       *http.Server
        client       client.Client
        clientset    *kubernetes.Clientset
        validator    *validation.ResourceValidator
        config       *config.Config
        metrics      *metrics.OperatorMetrics
        codecs       serializer.CodecFactory
        deserializer runtime.Decoder
}

// WebhookConfig holds webhook configuration
type WebhookConfig struct {
        CertPath          string
        KeyPath           string
        Port              int
        EnableValidation  bool
        EnableMutation    bool
        DryRun            bool
        RequireAnnotation bool
}

// NewWebhookServer creates a new admission webhook server
func NewWebhookServer(
        client client.Client,
        clientset *kubernetes.Clientset,
        validator *validation.ResourceValidator,
        cfg *config.Config,
        metrics *metrics.OperatorMetrics,
        webhookConfig WebhookConfig,
) *WebhookServer <span class="cov0" title="0">{
        scheme := runtime.NewScheme()
        corev1.AddToScheme(scheme)
        codecs := serializer.NewCodecFactory(scheme)

        mux := http.NewServeMux()
        server := &amp;http.Server{
                Addr:    fmt.Sprintf(":%d", webhookConfig.Port),
                Handler: mux,
        }

        ws := &amp;WebhookServer{
                server:       server,
                client:       client,
                clientset:    clientset,
                validator:    validator,
                config:       cfg,
                metrics:      metrics,
                codecs:       codecs,
                deserializer: codecs.UniversalDeserializer(),
        }

        // Register webhook endpoints
        if webhookConfig.EnableValidation </span><span class="cov0" title="0">{
                mux.HandleFunc("/validate", ws.handleValidate)
                logger.Info("Registered validation webhook at /validate")
        }</span>

        <span class="cov0" title="0">if webhookConfig.EnableMutation </span><span class="cov0" title="0">{
                mux.HandleFunc("/mutate", ws.handleMutate)
                logger.Info("Registered mutation webhook at /mutate")
        }</span>

        // Health check endpoint
        <span class="cov0" title="0">mux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                w.WriteHeader(http.StatusOK)
                w.Write([]byte("healthy"))
        }</span>)

        <span class="cov0" title="0">return ws</span>
}

// Start starts the webhook server
func (ws *WebhookServer) Start(certPath, keyPath string) error <span class="cov0" title="0">{
        logger.Info("Starting admission webhook server on %s", ws.server.Addr)

        if certPath != "" &amp;&amp; keyPath != "" </span><span class="cov0" title="0">{
                return ws.server.ListenAndServeTLS(certPath, keyPath)
        }</span>

        <span class="cov0" title="0">logger.Warn("Running webhook server without TLS (not recommended for production)")
        return ws.server.ListenAndServe()</span>
}

// Stop stops the webhook server
func (ws *WebhookServer) Stop(ctx context.Context) error <span class="cov0" title="0">{
        logger.Info("Stopping admission webhook server")
        return ws.server.Shutdown(ctx)
}</span>

// handleValidate handles validation admission requests
func (ws *WebhookServer) handleValidate(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        timer := metrics.NewTimer()
        defer func() </span><span class="cov0" title="0">{
                if ws.metrics != nil </span><span class="cov0" title="0">{
                        ws.metrics.RecordProcessingDuration("validation_webhook", timer.Duration())
                }</span>
        }()

        <span class="cov0" title="0">body, err := ws.readRequestBody(r)
        if err != nil </span><span class="cov0" title="0">{
                ws.sendError(w, fmt.Errorf("failed to read request body: %v", err))
                return
        }</span>

        <span class="cov0" title="0">var review admissionv1.AdmissionReview
        if err := json.Unmarshal(body, &amp;review); err != nil </span><span class="cov0" title="0">{
                ws.sendError(w, fmt.Errorf("failed to decode admission review: %v", err))
                return
        }</span>

        <span class="cov0" title="0">response := ws.validatePodResourceChange(&amp;review)
        ws.sendResponse(w, response.Response)</span>
}

// handleMutate handles mutation admission requests
func (ws *WebhookServer) handleMutate(w http.ResponseWriter, r *http.Request) <span class="cov0" title="0">{
        timer := metrics.NewTimer()
        defer func() </span><span class="cov0" title="0">{
                if ws.metrics != nil </span><span class="cov0" title="0">{
                        ws.metrics.RecordProcessingDuration("mutation_webhook", timer.Duration())
                }</span>
        }()

        <span class="cov0" title="0">body, err := ws.readRequestBody(r)
        if err != nil </span><span class="cov0" title="0">{
                ws.sendError(w, fmt.Errorf("failed to read request body: %v", err))
                return
        }</span>

        <span class="cov0" title="0">var review admissionv1.AdmissionReview
        if err := json.Unmarshal(body, &amp;review); err != nil </span><span class="cov0" title="0">{
                ws.sendError(w, fmt.Errorf("failed to decode admission review: %v", err))
                return
        }</span>

        <span class="cov0" title="0">response := ws.mutatePodResources(&amp;review)
        ws.sendResponse(w, response.Response)</span>
}

// validatePodResourceChange validates pod resource changes
func (ws *WebhookServer) validatePodResourceChange(review *admissionv1.AdmissionReview) admissionv1.AdmissionReview <span class="cov0" title="0">{
        req := review.Request
        response := &amp;admissionv1.AdmissionResponse{
                UID:     req.UID,
                Allowed: true,
        }

        // Only validate pods
        if req.Kind.Kind != "Pod" </span><span class="cov0" title="0">{
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Skip if not enabled for this namespace
        <span class="cov0" title="0">if !ws.config.IsNamespaceIncluded(req.Namespace) </span><span class="cov0" title="0">{
                logger.Debug("Skipping validation for namespace %s (not included)", req.Namespace)
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Parse old and new pod objects
        <span class="cov0" title="0">var oldPod, newPod corev1.Pod
        if req.OldObject.Raw != nil </span><span class="cov0" title="0">{
                if err := json.Unmarshal(req.OldObject.Raw, &amp;oldPod); err != nil </span><span class="cov0" title="0">{
                        response.Allowed = false
                        response.Result = &amp;metav1.Status{
                                Message: fmt.Sprintf("Failed to parse old pod: %v", err),
                        }
                        return admissionv1.AdmissionReview{Response: response}
                }</span>
        }

        <span class="cov0" title="0">if err := json.Unmarshal(req.Object.Raw, &amp;newPod); err != nil </span><span class="cov0" title="0">{
                response.Allowed = false
                response.Result = &amp;metav1.Status{
                        Message: fmt.Sprintf("Failed to parse new pod: %v", err),
                }
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Skip if pod has opt-out annotation
        <span class="cov0" title="0">if ws.shouldSkipValidation(&amp;newPod) </span><span class="cov0" title="0">{
                logger.Debug("Skipping validation for pod %s/%s (opt-out annotation)", newPod.Namespace, newPod.Name)
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Validate resource changes for each container
        <span class="cov0" title="0">var validationErrors []string
        var validationWarnings []string

        for i, container := range newPod.Spec.Containers </span><span class="cov0" title="0">{
                // Compare with old container resources if available
                var oldResources corev1.ResourceRequirements
                if req.Operation == admissionv1.Update &amp;&amp; len(oldPod.Spec.Containers) &gt; i </span><span class="cov0" title="0">{
                        oldResources = oldPod.Spec.Containers[i].Resources
                }</span>

                // Skip if no resource change
                <span class="cov0" title="0">if ws.areResourcesEqual(oldResources, container.Resources) </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Validate the resource change
                <span class="cov0" title="0">validationResult := ws.validator.ValidateResourceChange(
                        context.Background(),
                        &amp;newPod,
                        container.Resources,
                        container.Name,
                )

                if !validationResult.IsValid() </span><span class="cov0" title="0">{
                        validationErrors = append(validationErrors, validationResult.Errors...)
                }</span>

                <span class="cov0" title="0">if validationResult.HasWarnings() </span><span class="cov0" title="0">{
                        validationWarnings = append(validationWarnings, validationResult.Warnings...)
                }</span>

                // Record metrics
                <span class="cov0" title="0">if ws.metrics != nil &amp;&amp; !validationResult.IsValid() </span><span class="cov0" title="0">{
                        ws.metrics.RecordResourceValidationError("admission_webhook", strings.Join(validationResult.Errors, "; "))
                }</span>
        }

        // Set response based on validation results
        <span class="cov0" title="0">if len(validationErrors) &gt; 0 </span><span class="cov0" title="0">{
                response.Allowed = false
                response.Result = &amp;metav1.Status{
                        Code:    http.StatusForbidden,
                        Message: fmt.Sprintf("Resource validation failed: %s", strings.Join(validationErrors, "; ")),
                }
        }</span> else<span class="cov0" title="0"> if len(validationWarnings) &gt; 0 </span><span class="cov0" title="0">{
                // Allow but include warnings
                response.Warnings = validationWarnings
                logger.Warn("Pod %s/%s has resource validation warnings: %s",
                        newPod.Namespace, newPod.Name, strings.Join(validationWarnings, "; "))
        }</span>

        <span class="cov0" title="0">return admissionv1.AdmissionReview{Response: response}</span>
}

// mutatePodResources applies automatic resource adjustments
func (ws *WebhookServer) mutatePodResources(review *admissionv1.AdmissionReview) admissionv1.AdmissionReview <span class="cov0" title="0">{
        req := review.Request
        response := &amp;admissionv1.AdmissionResponse{
                UID:     req.UID,
                Allowed: true,
        }

        // Only mutate pods
        if req.Kind.Kind != "Pod" </span><span class="cov0" title="0">{
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Skip if not enabled for this namespace
        <span class="cov0" title="0">if !ws.config.IsNamespaceIncluded(req.Namespace) </span><span class="cov0" title="0">{
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        <span class="cov0" title="0">var pod corev1.Pod
        if err := json.Unmarshal(req.Object.Raw, &amp;pod); err != nil </span><span class="cov0" title="0">{
                response.Allowed = false
                response.Result = &amp;metav1.Status{
                        Message: fmt.Sprintf("Failed to parse pod: %v", err),
                }
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Skip if pod has opt-out annotation
        <span class="cov0" title="0">if ws.shouldSkipMutation(&amp;pod) </span><span class="cov0" title="0">{
                return admissionv1.AdmissionReview{Response: response}
        }</span>

        // Check current QoS class before mutation
        <span class="cov0" title="0">currentQoS := ws.getQoSClass(&amp;pod)
        if currentQoS == corev1.PodQOSGuaranteed </span><span class="cov0" title="0">{
                logger.Debug("Pod %s/%s has Guaranteed QoS, will maintain during mutation", pod.Namespace, pod.Name)
        }</span>

        // Apply mutations
        <span class="cov0" title="0">patches := ws.generateResourcePatches(&amp;pod)
        if len(patches) &gt; 0 </span><span class="cov0" title="0">{
                patchBytes, err := json.Marshal(patches)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error("Failed to marshal patches: %v", err)
                        return admissionv1.AdmissionReview{Response: response}
                }</span>

                <span class="cov0" title="0">patchType := admissionv1.PatchTypeJSONPatch
                response.Patch = patchBytes
                response.PatchType = &amp;patchType

                logger.Info("Applied resource patches to pod %s/%s (QoS: %s)", pod.Namespace, pod.Name, currentQoS)</span>
        }

        <span class="cov0" title="0">return admissionv1.AdmissionReview{Response: response}</span>
}

// shouldSkipValidation checks if validation should be skipped for this pod
func (ws *WebhookServer) shouldSkipValidation(pod *corev1.Pod) bool <span class="cov0" title="0">{
        // Check for opt-out annotation
        if pod.Annotations != nil </span><span class="cov0" title="0">{
                if skip, exists := pod.Annotations["rightsizer.io/skip-validation"]; exists &amp;&amp; skip == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov0" title="0">if disable, exists := pod.Annotations["rightsizer.io/disable"]; exists &amp;&amp; disable == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Check for opt-out label
        <span class="cov0" title="0">if pod.Labels != nil </span><span class="cov0" title="0">{
                if skip, exists := pod.Labels["rightsizer.skip-validation"]; exists &amp;&amp; skip == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// shouldSkipMutation checks if mutation should be skipped for this pod
func (ws *WebhookServer) shouldSkipMutation(pod *corev1.Pod) bool <span class="cov0" title="0">{
        // Check for opt-out annotation
        if pod.Annotations != nil </span><span class="cov0" title="0">{
                if skip, exists := pod.Annotations["rightsizer.io/skip-mutation"]; exists &amp;&amp; skip == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
                <span class="cov0" title="0">if disable, exists := pod.Annotations["rightsizer.io/disable"]; exists &amp;&amp; disable == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Check for opt-out label
        <span class="cov0" title="0">if pod.Labels != nil </span><span class="cov0" title="0">{
                if skip, exists := pod.Labels["rightsizer.skip-mutation"]; exists &amp;&amp; skip == "true" </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// areResourcesEqual compares two resource requirements
func (ws *WebhookServer) areResourcesEqual(old, new corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        // Compare requests
        if !ws.areResourceListsEqual(old.Requests, new.Requests) </span><span class="cov0" title="0">{
                return false
        }</span>

        // Compare limits
        <span class="cov0" title="0">if !ws.areResourceListsEqual(old.Limits, new.Limits) </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">return true</span>
}

// areResourceListsEqual compares two resource lists
func (ws *WebhookServer) areResourceListsEqual(old, new corev1.ResourceList) bool <span class="cov0" title="0">{
        if len(old) != len(new) </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">for k, v := range old </span><span class="cov0" title="0">{
                if newV, exists := new[k]; !exists || !v.Equal(newV) </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        <span class="cov0" title="0">return true</span>
}

// generateResourcePatches generates JSON patches for resource optimization
func (ws *WebhookServer) generateResourcePatches(pod *corev1.Pod) []JSONPatch <span class="cov0" title="0">{
        var patches []JSONPatch

        // Determine if we should maintain Guaranteed QoS
        maintainGuaranteed := false
        if pod.Annotations != nil </span><span class="cov0" title="0">{
                if qos, exists := pod.Annotations["rightsizer.io/qos-class"]; exists &amp;&amp; qos == "Guaranteed" </span><span class="cov0" title="0">{
                        maintainGuaranteed = true
                }</span>
        }

        // Add default resource requests if missing
        <span class="cov0" title="0">for i, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                if container.Resources.Requests == nil </span><span class="cov0" title="0">{
                        cpuRequest := fmt.Sprintf("%dm", ws.config.MinCPURequest)
                        memRequest := fmt.Sprintf("%dMi", ws.config.MinMemoryRequest)

                        patches = append(patches, JSONPatch{
                                Op:   "add",
                                Path: fmt.Sprintf("/spec/containers/%d/resources/requests", i),
                                Value: map[string]string{
                                        "cpu":    cpuRequest,
                                        "memory": memRequest,
                                },
                        })

                        // If maintaining Guaranteed QoS, also add matching limits
                        if maintainGuaranteed </span><span class="cov0" title="0">{
                                patches = append(patches, JSONPatch{
                                        Op:   "add",
                                        Path: fmt.Sprintf("/spec/containers/%d/resources/limits", i),
                                        Value: map[string]string{
                                                "cpu":    cpuRequest,
                                                "memory": memRequest,
                                        },
                                })
                        }</span>
                } else<span class="cov0" title="0"> if maintainGuaranteed &amp;&amp; container.Resources.Limits == nil </span><span class="cov0" title="0">{
                        // If we have requests but no limits and need Guaranteed QoS, add matching limits
                        patches = append(patches, JSONPatch{
                                Op:    "add",
                                Path:  fmt.Sprintf("/spec/containers/%d/resources/limits", i),
                                Value: container.Resources.Requests,
                        })
                }</span>

                // Add labels for tracking
                <span class="cov0" title="0">if pod.Labels == nil </span><span class="cov0" title="0">{
                        patches = append(patches, JSONPatch{
                                Op:    "add",
                                Path:  "/metadata/labels",
                                Value: map[string]string{},
                        })
                }</span>

                <span class="cov0" title="0">patches = append(patches, JSONPatch{
                        Op:    "add",
                        Path:  "/metadata/labels/rightsizer.io~1managed",
                        Value: "true",
                })</span>
        }

        <span class="cov0" title="0">return patches</span>
}

// JSONPatch represents a JSON patch operation
type JSONPatch struct {
        Op    string      `json:"op"`
        Path  string      `json:"path"`
        Value interface{} `json:"value,omitempty"`
}

// getQoSClass determines the QoS class of a pod
func (ws *WebhookServer) getQoSClass(pod *corev1.Pod) corev1.PodQOSClass <span class="cov0" title="0">{
        requests := make(corev1.ResourceList)
        limits := make(corev1.ResourceList)
        zeroQuantity := resource.MustParse("0")
        isGuaranteed := true

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Accumulate requests
                for name, quantity := range container.Resources.Requests </span><span class="cov0" title="0">{
                        if value, exists := requests[name]; !exists </span><span class="cov0" title="0">{
                                requests[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                requests[name] = value
                        }</span>
                }

                // Accumulate limits
                <span class="cov0" title="0">for name, quantity := range container.Resources.Limits </span><span class="cov0" title="0">{
                        if value, exists := limits[name]; !exists </span><span class="cov0" title="0">{
                                limits[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                limits[name] = value
                        }</span>
                }
        }

        // Check if guaranteed - must have both CPU and memory requests/limits and they must be equal
        <span class="cov0" title="0">if len(requests) &lt; 2 || len(limits) &lt; 2 </span><span class="cov0" title="0">{
                isGuaranteed = false
        }</span> else<span class="cov0" title="0"> {
                // Check CPU and Memory specifically
                cpuReq, hasCPUReq := requests[corev1.ResourceCPU]
                cpuLim, hasCPULim := limits[corev1.ResourceCPU]
                memReq, hasMemReq := requests[corev1.ResourceMemory]
                memLim, hasMemLim := limits[corev1.ResourceMemory]

                if !hasCPUReq || !hasCPULim || !hasMemReq || !hasMemLim </span><span class="cov0" title="0">{
                        isGuaranteed = false
                }</span> else<span class="cov0" title="0"> if cpuReq.Cmp(cpuLim) != 0 || memReq.Cmp(memLim) != 0 </span><span class="cov0" title="0">{
                        isGuaranteed = false
                }</span>
        }

        <span class="cov0" title="0">if isGuaranteed </span><span class="cov0" title="0">{
                return corev1.PodQOSGuaranteed
        }</span>

        // Check if burstable (has some requests or limits)
        <span class="cov0" title="0">for _, req := range requests </span><span class="cov0" title="0">{
                if req.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">for _, limit := range limits </span><span class="cov0" title="0">{
                if limit.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">return corev1.PodQOSBestEffort</span>
}

// readRequestBody reads and validates the request body
func (ws *WebhookServer) readRequestBody(r *http.Request) ([]byte, error) <span class="cov0" title="0">{
        if r.Body == nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("request body is empty")
        }</span>
        <span class="cov0" title="0">defer r.Body.Close()

        if r.Header.Get("Content-Type") != "application/json" </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("expected Content-Type application/json")
        }</span>

        <span class="cov0" title="0">body := make([]byte, r.ContentLength)
        if _, err := r.Body.Read(body); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">return body, nil</span>
}

// sendResponse sends an admission review response
func (ws *WebhookServer) sendResponse(w http.ResponseWriter, response *admissionv1.AdmissionResponse) <span class="cov0" title="0">{
        review := admissionv1.AdmissionReview{
                TypeMeta: metav1.TypeMeta{
                        APIVersion: "admission.k8s.io/v1",
                        Kind:       "AdmissionReview",
                },
                Response: response,
        }

        respBytes, err := json.Marshal(review)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to marshal admission response: %v", err)
                http.Error(w, err.Error(), http.StatusInternalServerError)
                return
        }</span>

        <span class="cov0" title="0">w.Header().Set("Content-Type", "application/json")
        w.WriteHeader(http.StatusOK)
        w.Write(respBytes)</span>
}

// sendError sends an error response
func (ws *WebhookServer) sendError(w http.ResponseWriter, err error) <span class="cov0" title="0">{
        logger.Error("Admission webhook error: %v", err)
        http.Error(w, err.Error(), http.StatusInternalServerError)

        if ws.metrics != nil </span><span class="cov0" title="0">{
                ws.metrics.RecordProcessingError("", "", "admission_webhook")
        }</span>
}

// WebhookManager manages the lifecycle of admission webhooks
type WebhookManager struct {
        server *WebhookServer
        config WebhookConfig
}

// NewWebhookManager creates a new webhook manager
func NewWebhookManager(
        client client.Client,
        clientset *kubernetes.Clientset,
        validator *validation.ResourceValidator,
        cfg *config.Config,
        metrics *metrics.OperatorMetrics,
        webhookConfig WebhookConfig,
) *WebhookManager <span class="cov0" title="0">{
        return &amp;WebhookManager{
                server: NewWebhookServer(client, clientset, validator, cfg, metrics, webhookConfig),
                config: webhookConfig,
        }
}</span>

// Start starts the webhook manager
func (wm *WebhookManager) Start(ctx context.Context) error <span class="cov0" title="0">{
        errChan := make(chan error, 1)

        go func() </span><span class="cov0" title="0">{
                errChan &lt;- wm.server.Start(wm.config.CertPath, wm.config.KeyPath)
        }</span>()

        <span class="cov0" title="0">select </span>{
        case err := &lt;-errChan:<span class="cov0" title="0">
                return err</span>
        case &lt;-ctx.Done():<span class="cov0" title="0">
                return wm.server.Stop(context.Background())</span>
        }
}

// Stop stops the webhook manager
func (wm *WebhookManager) Stop(ctx context.Context) error <span class="cov0" title="0">{
        return wm.server.Stop(ctx)
}</span>
</pre>
		
		<pre class="file" id="file1" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package v1alpha1

import (
        corev1 "k8s.io/api/core/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:resource:scope=Cluster,shortName=rsc
// +kubebuilder:printcolumn:name="Enabled",type=boolean,JSONPath=`.spec.enabled`
// +kubebuilder:printcolumn:name="Mode",type=string,JSONPath=`.spec.defaultMode`
// +kubebuilder:printcolumn:name="Interval",type=string,JSONPath=`.spec.resizeInterval`
// +kubebuilder:printcolumn:name="Status",type=string,JSONPath=`.status.phase`
// +kubebuilder:printcolumn:name="Age",type=date,JSONPath=`.metadata.creationTimestamp`

// RightSizerConfig is the Schema for the rightsizerconfigs API
// This is a cluster-scoped resource that configures the global behavior of the right-sizer operator
type RightSizerConfig struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   RightSizerConfigSpec   `json:"spec,omitempty"`
        Status RightSizerConfigStatus `json:"status,omitempty"`
}

// RightSizerConfigSpec defines the desired state of RightSizerConfig
type RightSizerConfigSpec struct {
        // Enabled indicates if the right-sizer operator is enabled globally
        // +kubebuilder:default=true
        Enabled bool `json:"enabled,omitempty"`

        // DefaultMode sets the default sizing mode when not specified in policies
        // +kubebuilder:validation:Enum=aggressive;balanced;conservative;custom
        // +kubebuilder:default=balanced
        DefaultMode string `json:"defaultMode,omitempty"`

        // ResizeInterval defines how often to check and resize resources globally
        // +kubebuilder:default="1m"
        ResizeInterval string `json:"resizeInterval,omitempty"`

        // DryRun enables global dry-run mode
        // +kubebuilder:default=false
        DryRun bool `json:"dryRun,omitempty"`

        // DefaultResourceStrategy defines default resource calculation strategy
        DefaultResourceStrategy DefaultResourceStrategySpec `json:"defaultResourceStrategy,omitempty"`

        // GlobalConstraints defines global resource constraints
        GlobalConstraints GlobalConstraintsSpec `json:"globalConstraints,omitempty"`

        // MetricsConfig configures metrics collection
        MetricsConfig MetricsConfigSpec `json:"metricsConfig,omitempty"`

        // ObservabilityConfig configures observability features
        ObservabilityConfig ObservabilityConfigSpec `json:"observabilityConfig,omitempty"`

        // SecurityConfig configures security features
        SecurityConfig SecurityConfigSpec `json:"securityConfig,omitempty"`

        // OperatorConfig configures operator behavior
        OperatorConfig OperatorConfigSpec `json:"operatorConfig,omitempty"`

        // NamespaceConfig defines global namespace inclusion/exclusion
        NamespaceConfig NamespaceConfigSpec `json:"namespaceConfig,omitempty"`

        // NotificationConfig configures notifications
        NotificationConfig NotificationConfigSpec `json:"notificationConfig,omitempty"`

        // FeatureGates enables/disables specific features
        FeatureGates map[string]bool `json:"featureGates,omitempty"`
}

// DefaultResourceStrategySpec defines default resource calculation parameters
type DefaultResourceStrategySpec struct {
        // CPU default strategy
        CPU DefaultCPUStrategy `json:"cpu,omitempty"`

        // Memory default strategy
        Memory DefaultMemoryStrategy `json:"memory,omitempty"`

        // HistoryWindow default for how much historical data to consider
        // +kubebuilder:default="7d"
        HistoryWindow string `json:"historyWindow,omitempty"`

        // Percentile default to use for resource calculations
        // +kubebuilder:default=95
        // +kubebuilder:validation:Enum=50;90;95;99
        Percentile int32 `json:"percentile,omitempty"`

        // UpdateMode default for how updates should be applied
        // +kubebuilder:validation:Enum=immediate;rolling;scheduled
        // +kubebuilder:default=rolling
        UpdateMode string `json:"updateMode,omitempty"`
}

// DefaultCPUStrategy defines default CPU resource calculation
type DefaultCPUStrategy struct {
        // RequestMultiplier default for CPU requests
        // +kubebuilder:default=1.2
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        RequestMultiplier float64 `json:"requestMultiplier,omitempty"`

        // RequestAddition default in millicores
        // +kubebuilder:default=0
        // +kubebuilder:validation:Minimum=0
        RequestAddition int64 `json:"requestAddition,omitempty"`

        // LimitMultiplier default for CPU limits
        // +kubebuilder:default=2.0
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        LimitMultiplier float64 `json:"limitMultiplier,omitempty"`

        // LimitAddition default in millicores
        // +kubebuilder:default=0
        // +kubebuilder:validation:Minimum=0
        LimitAddition int64 `json:"limitAddition,omitempty"`

        // MinRequest default in millicores (e.g., "10m")
        // +kubebuilder:default="10m"
        MinRequest string `json:"minRequest,omitempty"`

        // MaxLimit default in millicores (e.g., "4000m")
        // +kubebuilder:default="4000m"
        MaxLimit string `json:"maxLimit,omitempty"`

        // ScaleUpThreshold is the CPU usage percentage (0-1) that triggers scale up
        // +kubebuilder:default=0.8
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=1.0
        ScaleUpThreshold float64 `json:"scaleUpThreshold,omitempty"`

        // ScaleDownThreshold is the CPU usage percentage (0-1) that triggers scale down
        // +kubebuilder:default=0.3
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=1.0
        ScaleDownThreshold float64 `json:"scaleDownThreshold,omitempty"`
}

// DefaultMemoryStrategy defines default Memory resource calculation
type DefaultMemoryStrategy struct {
        // RequestMultiplier default for memory requests
        // +kubebuilder:default=1.2
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        RequestMultiplier float64 `json:"requestMultiplier,omitempty"`

        // RequestAddition default in MB
        // +kubebuilder:default=0
        // +kubebuilder:validation:Minimum=0
        RequestAddition int64 `json:"requestAddition,omitempty"`

        // LimitMultiplier default for memory limits
        // +kubebuilder:default=2.0
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        LimitMultiplier float64 `json:"limitMultiplier,omitempty"`

        // LimitAddition default in MB
        // +kubebuilder:default=0
        // +kubebuilder:validation:Minimum=0
        LimitAddition int64 `json:"limitAddition,omitempty"`

        // MinRequest default in memory units (e.g., "64Mi")
        // +kubebuilder:default="64Mi"
        MinRequest string `json:"minRequest,omitempty"`

        // MaxLimit default in memory units (e.g., "8192Mi")
        // +kubebuilder:default="8192Mi"
        MaxLimit string `json:"maxLimit,omitempty"`

        // ScaleUpThreshold is the memory usage percentage (0-1) that triggers scale up
        // +kubebuilder:default=0.8
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=1.0
        ScaleUpThreshold float64 `json:"scaleUpThreshold,omitempty"`

        // ScaleDownThreshold is the memory usage percentage (0-1) that triggers scale down
        // +kubebuilder:default=0.3
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=1.0
        ScaleDownThreshold float64 `json:"scaleDownThreshold,omitempty"`
}

// GlobalConstraintsSpec defines global constraints for the operator
type GlobalConstraintsSpec struct {
        // MaxChangePercentage global limit for resource changes
        // +kubebuilder:default=50
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        MaxChangePercentage int32 `json:"maxChangePercentage,omitempty"`

        // MinChangeThreshold global minimum change threshold
        // +kubebuilder:default=5
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        MinChangeThreshold int32 `json:"minChangeThreshold,omitempty"`

        // CooldownPeriod global cooldown between adjustments
        // +kubebuilder:default="5m"
        CooldownPeriod string `json:"cooldownPeriod,omitempty"`

        // MaxConcurrentResizes limits concurrent resize operations
        // +kubebuilder:default=10
        // +kubebuilder:validation:Minimum=1
        MaxConcurrentResizes int32 `json:"maxConcurrentResizes,omitempty"`

        // RespectPDB globally ensures PodDisruptionBudgets are respected
        // +kubebuilder:default=true
        RespectPDB bool `json:"respectPDB,omitempty"`

        // RespectHPA globally ensures HorizontalPodAutoscalers are not conflicted
        // +kubebuilder:default=true
        RespectHPA bool `json:"respectHPA,omitempty"`

        // RespectVPA globally ensures VerticalPodAutoscalers are not conflicted
        // +kubebuilder:default=true
        RespectVPA bool `json:"respectVPA,omitempty"`
}

// MetricsConfigSpec configures metrics collection
type MetricsConfigSpec struct {
        // Provider defines the metrics provider to use
        // +kubebuilder:validation:Enum=metrics-server;prometheus;custom
        // +kubebuilder:default=metrics-server
        Provider string `json:"provider,omitempty"`

        // PrometheusEndpoint for Prometheus metrics
        PrometheusEndpoint string `json:"prometheusEndpoint,omitempty"`

        // MetricsServerEndpoint for custom metrics server
        MetricsServerEndpoint string `json:"metricsServerEndpoint,omitempty"`

        // ScrapeInterval for metrics collection
        // +kubebuilder:default="30s"
        ScrapeInterval string `json:"scrapeInterval,omitempty"`

        // RetentionPeriod for metrics history
        // +kubebuilder:default="30d"
        RetentionPeriod string `json:"retentionPeriod,omitempty"`

        // CustomQueries for custom metrics
        CustomQueries map[string]string `json:"customQueries,omitempty"`

        // EnableProfiling enables CPU and memory profiling
        // +kubebuilder:default=false
        EnableProfiling bool `json:"enableProfiling,omitempty"`
}

// ObservabilityConfigSpec configures observability features
type ObservabilityConfigSpec struct {
        // LogLevel for the operator
        // +kubebuilder:validation:Enum=debug;info;warn;error
        // +kubebuilder:default=info
        LogLevel string `json:"logLevel,omitempty"`

        // LogFormat for log output
        // +kubebuilder:validation:Enum=json;text
        // +kubebuilder:default=json
        LogFormat string `json:"logFormat,omitempty"`

        // EnableAuditLog enables audit logging
        // +kubebuilder:default=true
        EnableAuditLog bool `json:"enableAuditLog,omitempty"`

        // AuditLogPath for audit log files
        // +kubebuilder:default="/var/log/right-sizer/audit.log"
        AuditLogPath string `json:"auditLogPath,omitempty"`

        // EnableMetricsExport enables Prometheus metrics export
        // +kubebuilder:default=true
        EnableMetricsExport bool `json:"enableMetricsExport,omitempty"`

        // MetricsPort for Prometheus metrics
        // +kubebuilder:default=9090
        MetricsPort int32 `json:"metricsPort,omitempty"`

        // EnableTracing enables distributed tracing
        // +kubebuilder:default=false
        EnableTracing bool `json:"enableTracing,omitempty"`

        // TracingEndpoint for tracing collector
        TracingEndpoint string `json:"tracingEndpoint,omitempty"`

        // EnableEvents enables Kubernetes event generation
        // +kubebuilder:default=true
        EnableEvents bool `json:"enableEvents,omitempty"`
}

// SecurityConfigSpec configures security features
type SecurityConfigSpec struct {
        // EnableAdmissionController enables admission webhook
        // +kubebuilder:default=false
        EnableAdmissionController bool `json:"enableAdmissionController,omitempty"`

        // AdmissionWebhookPort for admission webhook
        // +kubebuilder:default=8443
        AdmissionWebhookPort int32 `json:"admissionWebhookPort,omitempty"`

        // RequireAnnotation requires explicit annotation for resizing
        // +kubebuilder:default=false
        RequireAnnotation bool `json:"requireAnnotation,omitempty"`

        // AnnotationKey to look for when RequireAnnotation is true
        // +kubebuilder:default="right-sizer.io/enabled"
        AnnotationKey string `json:"annotationKey,omitempty"`

        // EnableMutatingWebhook enables mutating admission webhook
        // +kubebuilder:default=false
        EnableMutatingWebhook bool `json:"enableMutatingWebhook,omitempty"`

        // EnableValidatingWebhook enables validating admission webhook
        // +kubebuilder:default=true
        EnableValidatingWebhook bool `json:"enableValidatingWebhook,omitempty"`

        // TLSConfig for webhook TLS configuration
        TLSConfig *WebhookTLSConfig `json:"tlsConfig,omitempty"`
}

// WebhookTLSConfig defines TLS configuration for webhooks
type WebhookTLSConfig struct {
        // CertSecretName containing TLS certificate
        CertSecretName string `json:"certSecretName,omitempty"`

        // CertPath to TLS certificate file
        // +kubebuilder:default="/etc/certs/tls.crt"
        CertPath string `json:"certPath,omitempty"`

        // KeyPath to TLS key file
        // +kubebuilder:default="/etc/certs/tls.key"
        KeyPath string `json:"keyPath,omitempty"`

        // CAPath to CA certificate file
        CAPath string `json:"caPath,omitempty"`

        // AutoGenerate certificates if not provided
        // +kubebuilder:default=true
        AutoGenerate bool `json:"autoGenerate,omitempty"`
}

// OperatorConfigSpec configures operator behavior
type OperatorConfigSpec struct {
        // LeaderElection enables leader election for HA
        // +kubebuilder:default=true
        LeaderElection bool `json:"leaderElection,omitempty"`

        // LeaderElectionNamespace for leader election
        // +kubebuilder:default="right-sizer-system"
        LeaderElectionNamespace string `json:"leaderElectionNamespace,omitempty"`

        // LeaderElectionID for leader election
        // +kubebuilder:default="right-sizer-leader"
        LeaderElectionID string `json:"leaderElectionID,omitempty"`

        // MaxRetries for failed operations
        // +kubebuilder:default=3
        // +kubebuilder:validation:Minimum=0
        MaxRetries int32 `json:"maxRetries,omitempty"`

        // RetryInterval between retry attempts
        // +kubebuilder:default="5s"
        RetryInterval string `json:"retryInterval,omitempty"`

        // EnableCircuitBreaker enables circuit breaker pattern
        // +kubebuilder:default=true
        EnableCircuitBreaker bool `json:"enableCircuitBreaker,omitempty"`

        // CircuitBreakerThreshold for circuit breaker
        // +kubebuilder:default=5
        // +kubebuilder:validation:Minimum=1
        CircuitBreakerThreshold int32 `json:"circuitBreakerThreshold,omitempty"`

        // ReconcileInterval for reconciliation loop
        // +kubebuilder:default="10m"
        ReconcileInterval string `json:"reconcileInterval,omitempty"`

        // WorkerThreads for concurrent processing
        // +kubebuilder:default=5
        // +kubebuilder:validation:Minimum=1
        // +kubebuilder:validation:Maximum=50
        WorkerThreads int32 `json:"workerThreads,omitempty"`

        // QPS (Queries Per Second) for Kubernetes API client rate limiting
        // +kubebuilder:default=20
        // +kubebuilder:validation:Minimum=1
        // +kubebuilder:validation:Maximum=1000
        QPS float32 `json:"qps,omitempty"`

        // Burst for Kubernetes API client rate limiting
        // +kubebuilder:default=30
        // +kubebuilder:validation:Minimum=1
        // +kubebuilder:validation:Maximum=1000
        Burst int32 `json:"burst,omitempty"`

        // MaxConcurrentReconciles per controller
        // +kubebuilder:default=3
        // +kubebuilder:validation:Minimum=1
        // +kubebuilder:validation:Maximum=20
        MaxConcurrentReconciles int32 `json:"maxConcurrentReconciles,omitempty"`
}

// NamespaceConfigSpec defines namespace inclusion/exclusion
type NamespaceConfigSpec struct {
        // IncludeNamespaces to monitor (empty means all)
        IncludeNamespaces []string `json:"includeNamespaces,omitempty"`

        // ExcludeNamespaces to exclude from monitoring
        ExcludeNamespaces []string `json:"excludeNamespaces,omitempty"`

        // SystemNamespaces that should never be modified
        SystemNamespaces []string `json:"systemNamespaces,omitempty"`

        // NamespaceLabels to select namespaces by labels
        NamespaceLabels map[string]string `json:"namespaceLabels,omitempty"`
}

// NotificationConfigSpec configures notifications
type NotificationConfigSpec struct {
        // EnableNotifications globally enables notifications
        // +kubebuilder:default=false
        EnableNotifications bool `json:"enableNotifications,omitempty"`

        // SlackConfig for Slack notifications
        SlackConfig *SlackNotificationConfig `json:"slackConfig,omitempty"`

        // EmailConfig for email notifications
        EmailConfig *EmailNotificationConfig `json:"emailConfig,omitempty"`

        // WebhookConfigs for generic webhook notifications
        WebhookConfigs []WebhookNotificationConfig `json:"webhookConfigs,omitempty"`

        // NotificationLevel minimum level for notifications
        // +kubebuilder:validation:Enum=debug;info;warning;error
        // +kubebuilder:default=warning
        NotificationLevel string `json:"notificationLevel,omitempty"`
}

// SlackNotificationConfig defines Slack notification settings
type SlackNotificationConfig struct {
        // WebhookURL for Slack webhook
        WebhookURL string `json:"webhookURL"`

        // Channel to send notifications to
        Channel string `json:"channel,omitempty"`

        // Username for bot
        // +kubebuilder:default="RightSizer"
        Username string `json:"username,omitempty"`

        // IconEmoji for bot avatar
        // +kubebuilder:default=":robot_face:"
        IconEmoji string `json:"iconEmoji,omitempty"`
}

// EmailNotificationConfig defines email notification settings
type EmailNotificationConfig struct {
        // SMTPServer address
        SMTPServer string `json:"smtpServer"`

        // SMTPPort for SMTP server
        // +kubebuilder:default=587
        SMTPPort int32 `json:"smtpPort,omitempty"`

        // From email address
        From string `json:"from"`

        // To email addresses
        To []string `json:"to"`

        // UseTLS for SMTP connection
        // +kubebuilder:default=true
        UseTLS bool `json:"useTLS,omitempty"`

        // AuthSecretRef for SMTP authentication
        AuthSecretRef *corev1.SecretKeySelector `json:"authSecretRef,omitempty"`
}

// WebhookNotificationConfig defines webhook notification settings
type WebhookNotificationConfig struct {
        // Name of this webhook configuration
        Name string `json:"name"`

        // URL of the webhook endpoint
        URL string `json:"url"`

        // Method HTTP method to use
        // +kubebuilder:validation:Enum=GET;POST;PUT
        // +kubebuilder:default=POST
        Method string `json:"method,omitempty"`

        // Headers to include in requests
        Headers map[string]string `json:"headers,omitempty"`

        // Timeout for webhook requests
        // +kubebuilder:default="30s"
        Timeout string `json:"timeout,omitempty"`

        // RetryCount for failed requests
        // +kubebuilder:default=3
        RetryCount int32 `json:"retryCount,omitempty"`
}

// RightSizerConfigStatus defines the observed state of RightSizerConfig
type RightSizerConfigStatus struct {
        // Phase of the configuration (Pending, Active, Failed)
        Phase string `json:"phase,omitempty"`

        // Conditions represent the latest available observations
        Conditions []metav1.Condition `json:"conditions,omitempty"`

        // LastAppliedTime when the configuration was last applied
        LastAppliedTime *metav1.Time `json:"lastAppliedTime,omitempty"`

        // ActivePolicies count of active policies
        ActivePolicies int32 `json:"activePolicies,omitempty"`

        // TotalResourcesMonitored being monitored
        TotalResourcesMonitored int32 `json:"totalResourcesMonitored,omitempty"`

        // TotalResourcesResized that have been resized
        TotalResourcesResized int32 `json:"totalResourcesResized,omitempty"`

        // OperatorVersion of the running operator
        OperatorVersion string `json:"operatorVersion,omitempty"`

        // ObservedGeneration for tracking spec changes
        ObservedGeneration int64 `json:"observedGeneration,omitempty"`

        // Message provides additional status information
        Message string `json:"message,omitempty"`

        // SystemHealth provides system health status
        SystemHealth *SystemHealthStatus `json:"systemHealth,omitempty"`
}

// SystemHealthStatus provides system health information
type SystemHealthStatus struct {
        // MetricsProviderHealthy indicates metrics provider health
        MetricsProviderHealthy bool `json:"metricsProviderHealthy,omitempty"`

        // WebhookHealthy indicates webhook health
        WebhookHealthy bool `json:"webhookHealthy,omitempty"`

        // LeaderElectionActive indicates if leader election is active
        LeaderElectionActive bool `json:"leaderElectionActive,omitempty"`

        // IsLeader indicates if this instance is the leader
        IsLeader bool `json:"isLeader,omitempty"`

        // LastHealthCheck timestamp
        LastHealthCheck *metav1.Time `json:"lastHealthCheck,omitempty"`

        // Errors current error count
        Errors int32 `json:"errors,omitempty"`

        // Warnings current warning count
        Warnings int32 `json:"warnings,omitempty"`
}

// +kubebuilder:object:root=true

// RightSizerConfigList contains a list of RightSizerConfig
type RightSizerConfigList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []RightSizerConfig `json:"items"`
}

func init() <span class="cov0" title="0">{
        SchemeBuilder.Register(&amp;RightSizerConfig{}, &amp;RightSizerConfigList{})
}</span>
</pre>
		
		<pre class="file" id="file2" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package v1alpha1

import (
        corev1 "k8s.io/api/core/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
)

// EDIT THIS FILE!  THIS IS SCAFFOLDING FOR YOU TO OWN!
// NOTE: json tags are required.  Any new fields you add must have json tags for the fields to be serialized.

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:resource:shortName=rsp
// +kubebuilder:printcolumn:name="Enabled",type=boolean,JSONPath=`.spec.enabled`
// +kubebuilder:printcolumn:name="Mode",type=string,JSONPath=`.spec.mode`
// +kubebuilder:printcolumn:name="Status",type=string,JSONPath=`.status.phase`
// +kubebuilder:printcolumn:name="Last Applied",type=date,JSONPath=`.status.lastAppliedTime`
// +kubebuilder:printcolumn:name="Age",type=date,JSONPath=`.metadata.creationTimestamp`

// RightSizerPolicy is the Schema for the rightsizerpolicies API
type RightSizerPolicy struct {
        metav1.TypeMeta   `json:",inline"`
        metav1.ObjectMeta `json:"metadata,omitempty"`

        Spec   RightSizerPolicySpec   `json:"spec,omitempty"`
        Status RightSizerPolicyStatus `json:"status,omitempty"`
}

// RightSizerPolicySpec defines the desired state of RightSizerPolicy
type RightSizerPolicySpec struct {
        // Enabled indicates if this policy is active
        // +kubebuilder:default=true
        Enabled bool `json:"enabled,omitempty"`

        // Priority determines the order of policy application (higher priority wins)
        // +kubebuilder:default=100
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=1000
        Priority int32 `json:"priority,omitempty"`

        // Mode defines the sizing mode for this policy
        // +kubebuilder:validation:Enum=aggressive;balanced;conservative;custom
        // +kubebuilder:default=balanced
        Mode string `json:"mode,omitempty"`

        // DryRun enables dry-run mode for this policy
        // +kubebuilder:default=false
        DryRun bool `json:"dryRun,omitempty"`

        // TargetRef defines which resources this policy applies to
        TargetRef TargetReference `json:"targetRef"`

        // ResourceStrategy defines how resources should be calculated
        ResourceStrategy ResourceStrategy `json:"resourceStrategy,omitempty"`

        // Schedule defines when this policy should be evaluated
        Schedule ScheduleSpec `json:"schedule,omitempty"`

        // Constraints defines resource constraints and limits
        Constraints ResourceConstraints `json:"constraints,omitempty"`

        // Webhooks defines webhook notifications for policy events
        Webhooks []WebhookSpec `json:"webhooks,omitempty"`

        // Annotations to add to resized resources
        ResourceAnnotations map[string]string `json:"resourceAnnotations,omitempty"`
}

// TargetReference defines which resources the policy applies to
type TargetReference struct {
        // Kind of resources to target (Deployment, StatefulSet, DaemonSet, Pod)
        // +kubebuilder:validation:Enum=Deployment;StatefulSet;DaemonSet;Pod;ReplicaSet;Job;CronJob
        Kind string `json:"kind,omitempty"`

        // APIVersion of the target resource
        // +kubebuilder:default="apps/v1"
        APIVersion string `json:"apiVersion,omitempty"`

        // Namespaces to include (empty means all namespaces)
        Namespaces []string `json:"namespaces,omitempty"`

        // ExcludeNamespaces to exclude from this policy
        ExcludeNamespaces []string `json:"excludeNamespaces,omitempty"`

        // LabelSelector for selecting resources
        LabelSelector *metav1.LabelSelector `json:"labelSelector,omitempty"`

        // AnnotationSelector for selecting resources based on annotations
        AnnotationSelector map[string]string `json:"annotationSelector,omitempty"`

        // Names of specific resources to target
        Names []string `json:"names,omitempty"`

        // ExcludeNames of specific resources to exclude
        ExcludeNames []string `json:"excludeNames,omitempty"`
}

// ResourceStrategy defines how resources should be calculated
type ResourceStrategy struct {
        // CPU request calculation strategy
        CPU CPUStrategy `json:"cpu,omitempty"`

        // Memory calculation strategy
        Memory MemoryStrategy `json:"memory,omitempty"`

        // MetricsSource defines where to get metrics from
        // +kubebuilder:validation:Enum=metrics-server;prometheus;custom
        // +kubebuilder:default=metrics-server
        MetricsSource string `json:"metricsSource,omitempty"`

        // PrometheusConfig for Prometheus metrics source
        PrometheusConfig *PrometheusConfig `json:"prometheusConfig,omitempty"`

        // HistoryWindow defines how much historical data to consider
        // +kubebuilder:default="7d"
        HistoryWindow string `json:"historyWindow,omitempty"`

        // Percentile to use for resource calculations (50, 90, 95, 99)
        // +kubebuilder:default=95
        // +kubebuilder:validation:Enum=50;90;95;99
        Percentile int32 `json:"percentile,omitempty"`

        // UpdateMode defines how updates should be applied
        // +kubebuilder:validation:Enum=immediate;rolling;scheduled
        // +kubebuilder:default=rolling
        UpdateMode string `json:"updateMode,omitempty"`
}

// CPUStrategy defines CPU resource calculation strategy
type CPUStrategy struct {
        // RequestMultiplier for CPU requests
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        RequestMultiplier *float64 `json:"requestMultiplier,omitempty"`

        // RequestAddition in millicores to add to CPU requests
        // +kubebuilder:validation:Minimum=0
        RequestAddition *int64 `json:"requestAddition,omitempty"`

        // LimitMultiplier for CPU limits
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        LimitMultiplier *float64 `json:"limitMultiplier,omitempty"`

        // LimitAddition in millicores to add to CPU limits
        // +kubebuilder:validation:Minimum=0
        LimitAddition *int64 `json:"limitAddition,omitempty"`

        // MinRequest in millicores
        // +kubebuilder:validation:Minimum=0
        MinRequest *int64 `json:"minRequest,omitempty"`

        // MaxLimit in millicores
        // +kubebuilder:validation:Minimum=0
        MaxLimit *int64 `json:"maxLimit,omitempty"`

        // TargetUtilization percentage (0-100)
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        TargetUtilization *int32 `json:"targetUtilization,omitempty"`
}

// MemoryStrategy defines Memory resource calculation strategy
type MemoryStrategy struct {
        // RequestMultiplier for memory requests
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        RequestMultiplier *float64 `json:"requestMultiplier,omitempty"`

        // RequestAddition in MB to add to memory requests
        // +kubebuilder:validation:Minimum=0
        RequestAddition *int64 `json:"requestAddition,omitempty"`

        // LimitMultiplier for memory limits
        // +kubebuilder:validation:Minimum=0.1
        // +kubebuilder:validation:Maximum=10
        LimitMultiplier *float64 `json:"limitMultiplier,omitempty"`

        // LimitAddition in MB to add to memory limits
        // +kubebuilder:validation:Minimum=0
        LimitAddition *int64 `json:"limitAddition,omitempty"`

        // MinRequest in MB
        // +kubebuilder:validation:Minimum=0
        MinRequest *int64 `json:"minRequest,omitempty"`

        // MaxLimit in MB
        // +kubebuilder:validation:Minimum=0
        MaxLimit *int64 `json:"maxLimit,omitempty"`

        // TargetUtilization percentage (0-100)
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        TargetUtilization *int32 `json:"targetUtilization,omitempty"`
}

// PrometheusConfig defines Prometheus configuration
type PrometheusConfig struct {
        // URL of Prometheus server
        URL string `json:"url"`

        // CPUQuery for fetching CPU metrics
        CPUQuery string `json:"cpuQuery,omitempty"`

        // MemoryQuery for fetching memory metrics
        MemoryQuery string `json:"memoryQuery,omitempty"`

        // Auth configuration for Prometheus
        Auth *PrometheusAuth `json:"auth,omitempty"`
}

// PrometheusAuth defines authentication for Prometheus
type PrometheusAuth struct {
        // BasicAuth configuration
        BasicAuth *BasicAuth `json:"basicAuth,omitempty"`

        // BearerToken for authentication
        BearerToken string `json:"bearerToken,omitempty"`

        // TLSConfig for TLS configuration
        TLSConfig *TLSConfig `json:"tlsConfig,omitempty"`
}

// BasicAuth defines basic authentication
type BasicAuth struct {
        // Username for basic auth
        Username string `json:"username"`

        // Password reference from secret
        PasswordSecretRef corev1.SecretKeySelector `json:"passwordSecretRef"`
}

// TLSConfig defines TLS configuration
type TLSConfig struct {
        // CAFile path or secret reference
        CASecretRef *corev1.SecretKeySelector `json:"caSecretRef,omitempty"`

        // InsecureSkipVerify disables TLS verification
        InsecureSkipVerify bool `json:"insecureSkipVerify,omitempty"`
}

// ScheduleSpec defines when the policy should be evaluated
type ScheduleSpec struct {
        // Interval between evaluations (e.g., "30s", "5m", "1h")
        // +kubebuilder:default="1m"
        Interval string `json:"interval,omitempty"`

        // CronSchedule for cron-based evaluation
        CronSchedule string `json:"cronSchedule,omitempty"`

        // TimeWindows when the policy is active
        TimeWindows []TimeWindow `json:"timeWindows,omitempty"`
}

// TimeWindow defines a time window when the policy is active
type TimeWindow struct {
        // Start time in format "HH:MM"
        Start string `json:"start"`

        // End time in format "HH:MM"
        End string `json:"end"`

        // DaysOfWeek when this window is active
        // +kubebuilder:validation:Enum=Monday;Tuesday;Wednesday;Thursday;Friday;Saturday;Sunday
        DaysOfWeek []string `json:"daysOfWeek,omitempty"`

        // Timezone for the time window
        // +kubebuilder:default="UTC"
        Timezone string `json:"timezone,omitempty"`
}

// ResourceConstraints defines constraints for resource adjustments
type ResourceConstraints struct {
        // MaxChangePercentage limits how much resources can change in one adjustment
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        MaxChangePercentage *int32 `json:"maxChangePercentage,omitempty"`

        // MinChangeThreshold below which changes are not applied (percentage)
        // +kubebuilder:validation:Minimum=0
        // +kubebuilder:validation:Maximum=100
        MinChangeThreshold *int32 `json:"minChangeThreshold,omitempty"`

        // CooldownPeriod between adjustments
        // +kubebuilder:default="5m"
        CooldownPeriod string `json:"cooldownPeriod,omitempty"`

        // RespectPDB ensures PodDisruptionBudgets are respected
        // +kubebuilder:default=true
        RespectPDB bool `json:"respectPDB,omitempty"`

        // RespectHPA ensures HorizontalPodAutoscalers are not conflicted
        // +kubebuilder:default=true
        RespectHPA bool `json:"respectHPA,omitempty"`

        // RespectVPA ensures VerticalPodAutoscalers are not conflicted
        // +kubebuilder:default=true
        RespectVPA bool `json:"respectVPA,omitempty"`
}

// WebhookSpec defines webhook notification configuration
type WebhookSpec struct {
        // URL of the webhook endpoint
        URL string `json:"url"`

        // Events to send notifications for
        // +kubebuilder:validation:Enum=resize;error;warning;info
        Events []string `json:"events"`

        // Headers to include in webhook requests
        Headers map[string]string `json:"headers,omitempty"`

        // RetryPolicy for failed webhook calls
        RetryPolicy *WebhookRetryPolicy `json:"retryPolicy,omitempty"`
}

// WebhookRetryPolicy defines retry policy for webhooks
type WebhookRetryPolicy struct {
        // MaxRetries for failed webhook calls
        // +kubebuilder:default=3
        MaxRetries int32 `json:"maxRetries,omitempty"`

        // RetryInterval between attempts
        // +kubebuilder:default="5s"
        RetryInterval string `json:"retryInterval,omitempty"`
}

// RightSizerPolicyStatus defines the observed state of RightSizerPolicy
type RightSizerPolicyStatus struct {
        // Phase of the policy (Pending, Active, Failed, Suspended)
        Phase string `json:"phase,omitempty"`

        // Conditions represent the latest available observations
        Conditions []metav1.Condition `json:"conditions,omitempty"`

        // LastAppliedTime when the policy was last applied
        LastAppliedTime *metav1.Time `json:"lastAppliedTime,omitempty"`

        // LastEvaluationTime when the policy was last evaluated
        LastEvaluationTime *metav1.Time `json:"lastEvaluationTime,omitempty"`

        // ResourcesAffected count of resources affected by this policy
        ResourcesAffected int32 `json:"resourcesAffected,omitempty"`

        // ResourcesResized count of resources actually resized
        ResourcesResized int32 `json:"resourcesResized,omitempty"`

        // TotalSavings estimated resource savings
        TotalSavings ResourceSavings `json:"totalSavings,omitempty"`

        // ObservedGeneration for tracking spec changes
        ObservedGeneration int64 `json:"observedGeneration,omitempty"`

        // Message provides additional status information
        Message string `json:"message,omitempty"`

        // Metrics provides current metrics summary
        Metrics *MetricsSummary `json:"metrics,omitempty"`
}

// ResourceSavings tracks resource savings
type ResourceSavings struct {
        // CPUSaved in millicores
        CPUSaved int64 `json:"cpuSaved,omitempty"`

        // MemorySaved in MB
        MemorySaved int64 `json:"memorySaved,omitempty"`

        // CostSaved estimated cost savings
        CostSaved string `json:"costSaved,omitempty"`
}

// MetricsSummary provides metrics summary
type MetricsSummary struct {
        // AverageCPUUtilization across affected resources
        AverageCPUUtilization int32 `json:"averageCPUUtilization,omitempty"`

        // AverageMemoryUtilization across affected resources
        AverageMemoryUtilization int32 `json:"averageMemoryUtilization,omitempty"`

        // TotalCPURequests in millicores
        TotalCPURequests int64 `json:"totalCPURequests,omitempty"`

        // TotalMemoryRequests in MB
        TotalMemoryRequests int64 `json:"totalMemoryRequests,omitempty"`

        // LastUpdated timestamp
        LastUpdated *metav1.Time `json:"lastUpdated,omitempty"`
}

// +kubebuilder:object:root=true

// RightSizerPolicyList contains a list of RightSizerPolicy
type RightSizerPolicyList struct {
        metav1.TypeMeta `json:",inline"`
        metav1.ListMeta `json:"metadata,omitempty"`
        Items           []RightSizerPolicy `json:"items"`
}

func init() <span class="cov0" title="0">{
        SchemeBuilder.Register(&amp;RightSizerPolicy{}, &amp;RightSizerPolicyList{})
}</span>
</pre>
		
		<pre class="file" id="file3" style="display: none">//go:build !ignore_autogenerated

// Code generated by controller-gen. DO NOT EDIT.

package v1alpha1

import (
        "k8s.io/api/core/v1"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        runtime "k8s.io/apimachinery/pkg/runtime"
)

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *BasicAuth) DeepCopyInto(out *BasicAuth) <span class="cov0" title="0">{
        *out = *in
        in.PasswordSecretRef.DeepCopyInto(&amp;out.PasswordSecretRef)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new BasicAuth.
func (in *BasicAuth) DeepCopy() *BasicAuth <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(BasicAuth)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *CPUStrategy) DeepCopyInto(out *CPUStrategy) <span class="cov0" title="0">{
        *out = *in
        if in.RequestMultiplier != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.RequestMultiplier, &amp;out.RequestMultiplier
                *out = new(float64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.RequestAddition != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.RequestAddition, &amp;out.RequestAddition
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.LimitMultiplier != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LimitMultiplier, &amp;out.LimitMultiplier
                *out = new(float64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.LimitAddition != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LimitAddition, &amp;out.LimitAddition
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.MinRequest != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MinRequest, &amp;out.MinRequest
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.MaxLimit != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MaxLimit, &amp;out.MaxLimit
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.TargetUtilization != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.TargetUtilization, &amp;out.TargetUtilization
                *out = new(int32)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new CPUStrategy.
func (in *CPUStrategy) DeepCopy() *CPUStrategy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(CPUStrategy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DefaultCPUStrategy) DeepCopyInto(out *DefaultCPUStrategy) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DefaultCPUStrategy.
func (in *DefaultCPUStrategy) DeepCopy() *DefaultCPUStrategy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(DefaultCPUStrategy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DefaultMemoryStrategy) DeepCopyInto(out *DefaultMemoryStrategy) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DefaultMemoryStrategy.
func (in *DefaultMemoryStrategy) DeepCopy() *DefaultMemoryStrategy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(DefaultMemoryStrategy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *DefaultResourceStrategySpec) DeepCopyInto(out *DefaultResourceStrategySpec) <span class="cov0" title="0">{
        *out = *in
        out.CPU = in.CPU
        out.Memory = in.Memory
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new DefaultResourceStrategySpec.
func (in *DefaultResourceStrategySpec) DeepCopy() *DefaultResourceStrategySpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(DefaultResourceStrategySpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *EmailNotificationConfig) DeepCopyInto(out *EmailNotificationConfig) <span class="cov0" title="0">{
        *out = *in
        if in.To != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.To, &amp;out.To
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.AuthSecretRef != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.AuthSecretRef, &amp;out.AuthSecretRef
                *out = new(v1.SecretKeySelector)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new EmailNotificationConfig.
func (in *EmailNotificationConfig) DeepCopy() *EmailNotificationConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(EmailNotificationConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *GlobalConstraintsSpec) DeepCopyInto(out *GlobalConstraintsSpec) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new GlobalConstraintsSpec.
func (in *GlobalConstraintsSpec) DeepCopy() *GlobalConstraintsSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(GlobalConstraintsSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MemoryStrategy) DeepCopyInto(out *MemoryStrategy) <span class="cov0" title="0">{
        *out = *in
        if in.RequestMultiplier != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.RequestMultiplier, &amp;out.RequestMultiplier
                *out = new(float64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.RequestAddition != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.RequestAddition, &amp;out.RequestAddition
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.LimitMultiplier != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LimitMultiplier, &amp;out.LimitMultiplier
                *out = new(float64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.LimitAddition != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LimitAddition, &amp;out.LimitAddition
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.MinRequest != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MinRequest, &amp;out.MinRequest
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.MaxLimit != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MaxLimit, &amp;out.MaxLimit
                *out = new(int64)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.TargetUtilization != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.TargetUtilization, &amp;out.TargetUtilization
                *out = new(int32)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MemoryStrategy.
func (in *MemoryStrategy) DeepCopy() *MemoryStrategy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(MemoryStrategy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsConfigSpec) DeepCopyInto(out *MetricsConfigSpec) <span class="cov0" title="0">{
        *out = *in
        if in.CustomQueries != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.CustomQueries, &amp;out.CustomQueries
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsConfigSpec.
func (in *MetricsConfigSpec) DeepCopy() *MetricsConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(MetricsConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *MetricsSummary) DeepCopyInto(out *MetricsSummary) <span class="cov0" title="0">{
        *out = *in
        if in.LastUpdated != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LastUpdated, &amp;out.LastUpdated
                *out = (*in).DeepCopy()
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new MetricsSummary.
func (in *MetricsSummary) DeepCopy() *MetricsSummary <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(MetricsSummary)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *NamespaceConfigSpec) DeepCopyInto(out *NamespaceConfigSpec) <span class="cov0" title="0">{
        *out = *in
        if in.IncludeNamespaces != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.IncludeNamespaces, &amp;out.IncludeNamespaces
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.ExcludeNamespaces != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.ExcludeNamespaces, &amp;out.ExcludeNamespaces
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.SystemNamespaces != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SystemNamespaces, &amp;out.SystemNamespaces
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.NamespaceLabels != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.NamespaceLabels, &amp;out.NamespaceLabels
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new NamespaceConfigSpec.
func (in *NamespaceConfigSpec) DeepCopy() *NamespaceConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(NamespaceConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *NotificationConfigSpec) DeepCopyInto(out *NotificationConfigSpec) <span class="cov0" title="0">{
        *out = *in
        if in.SlackConfig != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SlackConfig, &amp;out.SlackConfig
                *out = new(SlackNotificationConfig)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.EmailConfig != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.EmailConfig, &amp;out.EmailConfig
                *out = new(EmailNotificationConfig)
                (*in).DeepCopyInto(*out)
        }</span>
        <span class="cov0" title="0">if in.WebhookConfigs != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.WebhookConfigs, &amp;out.WebhookConfigs
                *out = make([]WebhookNotificationConfig, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new NotificationConfigSpec.
func (in *NotificationConfigSpec) DeepCopy() *NotificationConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(NotificationConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ObservabilityConfigSpec) DeepCopyInto(out *ObservabilityConfigSpec) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ObservabilityConfigSpec.
func (in *ObservabilityConfigSpec) DeepCopy() *ObservabilityConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ObservabilityConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *OperatorConfigSpec) DeepCopyInto(out *OperatorConfigSpec) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new OperatorConfigSpec.
func (in *OperatorConfigSpec) DeepCopy() *OperatorConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(OperatorConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PrometheusAuth) DeepCopyInto(out *PrometheusAuth) <span class="cov0" title="0">{
        *out = *in
        if in.BasicAuth != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.BasicAuth, &amp;out.BasicAuth
                *out = new(BasicAuth)
                (*in).DeepCopyInto(*out)
        }</span>
        <span class="cov0" title="0">if in.TLSConfig != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.TLSConfig, &amp;out.TLSConfig
                *out = new(TLSConfig)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PrometheusAuth.
func (in *PrometheusAuth) DeepCopy() *PrometheusAuth <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PrometheusAuth)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *PrometheusConfig) DeepCopyInto(out *PrometheusConfig) <span class="cov0" title="0">{
        *out = *in
        if in.Auth != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Auth, &amp;out.Auth
                *out = new(PrometheusAuth)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new PrometheusConfig.
func (in *PrometheusConfig) DeepCopy() *PrometheusConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(PrometheusConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ResourceConstraints) DeepCopyInto(out *ResourceConstraints) <span class="cov0" title="0">{
        *out = *in
        if in.MaxChangePercentage != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MaxChangePercentage, &amp;out.MaxChangePercentage
                *out = new(int32)
                **out = **in
        }</span>
        <span class="cov0" title="0">if in.MinChangeThreshold != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.MinChangeThreshold, &amp;out.MinChangeThreshold
                *out = new(int32)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ResourceConstraints.
func (in *ResourceConstraints) DeepCopy() *ResourceConstraints <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ResourceConstraints)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ResourceSavings) DeepCopyInto(out *ResourceSavings) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ResourceSavings.
func (in *ResourceSavings) DeepCopy() *ResourceSavings <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ResourceSavings)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ResourceStrategy) DeepCopyInto(out *ResourceStrategy) <span class="cov0" title="0">{
        *out = *in
        in.CPU.DeepCopyInto(&amp;out.CPU)
        in.Memory.DeepCopyInto(&amp;out.Memory)
        if in.PrometheusConfig != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.PrometheusConfig, &amp;out.PrometheusConfig
                *out = new(PrometheusConfig)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ResourceStrategy.
func (in *ResourceStrategy) DeepCopy() *ResourceStrategy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ResourceStrategy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerConfig) DeepCopyInto(out *RightSizerConfig) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerConfig.
func (in *RightSizerConfig) DeepCopy() *RightSizerConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *RightSizerConfig) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerConfigList) DeepCopyInto(out *RightSizerConfigList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]RightSizerConfig, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerConfigList.
func (in *RightSizerConfigList) DeepCopy() *RightSizerConfigList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerConfigList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *RightSizerConfigList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerConfigSpec) DeepCopyInto(out *RightSizerConfigSpec) <span class="cov0" title="0">{
        *out = *in
        out.DefaultResourceStrategy = in.DefaultResourceStrategy
        out.GlobalConstraints = in.GlobalConstraints
        in.MetricsConfig.DeepCopyInto(&amp;out.MetricsConfig)
        out.ObservabilityConfig = in.ObservabilityConfig
        in.SecurityConfig.DeepCopyInto(&amp;out.SecurityConfig)
        out.OperatorConfig = in.OperatorConfig
        in.NamespaceConfig.DeepCopyInto(&amp;out.NamespaceConfig)
        in.NotificationConfig.DeepCopyInto(&amp;out.NotificationConfig)
        if in.FeatureGates != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.FeatureGates, &amp;out.FeatureGates
                *out = make(map[string]bool, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerConfigSpec.
func (in *RightSizerConfigSpec) DeepCopy() *RightSizerConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerConfigStatus) DeepCopyInto(out *RightSizerConfigStatus) <span class="cov0" title="0">{
        *out = *in
        if in.Conditions != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Conditions, &amp;out.Conditions
                *out = make([]metav1.Condition, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov0" title="0">if in.LastAppliedTime != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LastAppliedTime, &amp;out.LastAppliedTime
                *out = (*in).DeepCopy()
        }</span>
        <span class="cov0" title="0">if in.SystemHealth != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.SystemHealth, &amp;out.SystemHealth
                *out = new(SystemHealthStatus)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerConfigStatus.
func (in *RightSizerConfigStatus) DeepCopy() *RightSizerConfigStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerConfigStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerPolicy) DeepCopyInto(out *RightSizerPolicy) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ObjectMeta.DeepCopyInto(&amp;out.ObjectMeta)
        in.Spec.DeepCopyInto(&amp;out.Spec)
        in.Status.DeepCopyInto(&amp;out.Status)
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerPolicy.
func (in *RightSizerPolicy) DeepCopy() *RightSizerPolicy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerPolicy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *RightSizerPolicy) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerPolicyList) DeepCopyInto(out *RightSizerPolicyList) <span class="cov0" title="0">{
        *out = *in
        out.TypeMeta = in.TypeMeta
        in.ListMeta.DeepCopyInto(&amp;out.ListMeta)
        if in.Items != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Items, &amp;out.Items
                *out = make([]RightSizerPolicy, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerPolicyList.
func (in *RightSizerPolicyList) DeepCopy() *RightSizerPolicyList <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerPolicyList)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyObject is an autogenerated deepcopy function, copying the receiver, creating a new runtime.Object.
func (in *RightSizerPolicyList) DeepCopyObject() runtime.Object <span class="cov0" title="0">{
        if c := in.DeepCopy(); c != nil </span><span class="cov0" title="0">{
                return c
        }</span>
        <span class="cov0" title="0">return nil</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerPolicySpec) DeepCopyInto(out *RightSizerPolicySpec) <span class="cov0" title="0">{
        *out = *in
        in.TargetRef.DeepCopyInto(&amp;out.TargetRef)
        in.ResourceStrategy.DeepCopyInto(&amp;out.ResourceStrategy)
        in.Schedule.DeepCopyInto(&amp;out.Schedule)
        in.Constraints.DeepCopyInto(&amp;out.Constraints)
        if in.Webhooks != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Webhooks, &amp;out.Webhooks
                *out = make([]WebhookSpec, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov0" title="0">if in.ResourceAnnotations != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.ResourceAnnotations, &amp;out.ResourceAnnotations
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerPolicySpec.
func (in *RightSizerPolicySpec) DeepCopy() *RightSizerPolicySpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerPolicySpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *RightSizerPolicyStatus) DeepCopyInto(out *RightSizerPolicyStatus) <span class="cov0" title="0">{
        *out = *in
        if in.Conditions != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Conditions, &amp;out.Conditions
                *out = make([]metav1.Condition, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
        <span class="cov0" title="0">if in.LastAppliedTime != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LastAppliedTime, &amp;out.LastAppliedTime
                *out = (*in).DeepCopy()
        }</span>
        <span class="cov0" title="0">if in.LastEvaluationTime != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LastEvaluationTime, &amp;out.LastEvaluationTime
                *out = (*in).DeepCopy()
        }</span>
        <span class="cov0" title="0">out.TotalSavings = in.TotalSavings
        if in.Metrics != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Metrics, &amp;out.Metrics
                *out = new(MetricsSummary)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new RightSizerPolicyStatus.
func (in *RightSizerPolicyStatus) DeepCopy() *RightSizerPolicyStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(RightSizerPolicyStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *ScheduleSpec) DeepCopyInto(out *ScheduleSpec) <span class="cov0" title="0">{
        *out = *in
        if in.TimeWindows != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.TimeWindows, &amp;out.TimeWindows
                *out = make([]TimeWindow, len(*in))
                for i := range *in </span><span class="cov0" title="0">{
                        (*in)[i].DeepCopyInto(&amp;(*out)[i])
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new ScheduleSpec.
func (in *ScheduleSpec) DeepCopy() *ScheduleSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(ScheduleSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *SecurityConfigSpec) DeepCopyInto(out *SecurityConfigSpec) <span class="cov0" title="0">{
        *out = *in
        if in.TLSConfig != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.TLSConfig, &amp;out.TLSConfig
                *out = new(WebhookTLSConfig)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new SecurityConfigSpec.
func (in *SecurityConfigSpec) DeepCopy() *SecurityConfigSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(SecurityConfigSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *SlackNotificationConfig) DeepCopyInto(out *SlackNotificationConfig) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new SlackNotificationConfig.
func (in *SlackNotificationConfig) DeepCopy() *SlackNotificationConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(SlackNotificationConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *SystemHealthStatus) DeepCopyInto(out *SystemHealthStatus) <span class="cov0" title="0">{
        *out = *in
        if in.LastHealthCheck != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LastHealthCheck, &amp;out.LastHealthCheck
                *out = (*in).DeepCopy()
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new SystemHealthStatus.
func (in *SystemHealthStatus) DeepCopy() *SystemHealthStatus <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(SystemHealthStatus)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TLSConfig) DeepCopyInto(out *TLSConfig) <span class="cov0" title="0">{
        *out = *in
        if in.CASecretRef != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.CASecretRef, &amp;out.CASecretRef
                *out = new(v1.SecretKeySelector)
                (*in).DeepCopyInto(*out)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TLSConfig.
func (in *TLSConfig) DeepCopy() *TLSConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TLSConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TargetReference) DeepCopyInto(out *TargetReference) <span class="cov0" title="0">{
        *out = *in
        if in.Namespaces != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Namespaces, &amp;out.Namespaces
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.ExcludeNamespaces != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.ExcludeNamespaces, &amp;out.ExcludeNamespaces
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.LabelSelector != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.LabelSelector, &amp;out.LabelSelector
                *out = new(metav1.LabelSelector)
                (*in).DeepCopyInto(*out)
        }</span>
        <span class="cov0" title="0">if in.AnnotationSelector != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.AnnotationSelector, &amp;out.AnnotationSelector
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
        <span class="cov0" title="0">if in.Names != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Names, &amp;out.Names
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.ExcludeNames != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.ExcludeNames, &amp;out.ExcludeNames
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TargetReference.
func (in *TargetReference) DeepCopy() *TargetReference <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TargetReference)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *TimeWindow) DeepCopyInto(out *TimeWindow) <span class="cov0" title="0">{
        *out = *in
        if in.DaysOfWeek != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.DaysOfWeek, &amp;out.DaysOfWeek
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new TimeWindow.
func (in *TimeWindow) DeepCopy() *TimeWindow <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(TimeWindow)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WebhookNotificationConfig) DeepCopyInto(out *WebhookNotificationConfig) <span class="cov0" title="0">{
        *out = *in
        if in.Headers != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Headers, &amp;out.Headers
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WebhookNotificationConfig.
func (in *WebhookNotificationConfig) DeepCopy() *WebhookNotificationConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WebhookNotificationConfig)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WebhookRetryPolicy) DeepCopyInto(out *WebhookRetryPolicy) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WebhookRetryPolicy.
func (in *WebhookRetryPolicy) DeepCopy() *WebhookRetryPolicy <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WebhookRetryPolicy)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WebhookSpec) DeepCopyInto(out *WebhookSpec) <span class="cov0" title="0">{
        *out = *in
        if in.Events != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Events, &amp;out.Events
                *out = make([]string, len(*in))
                copy(*out, *in)
        }</span>
        <span class="cov0" title="0">if in.Headers != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.Headers, &amp;out.Headers
                *out = make(map[string]string, len(*in))
                for key, val := range *in </span><span class="cov0" title="0">{
                        (*out)[key] = val
                }</span>
        }
        <span class="cov0" title="0">if in.RetryPolicy != nil </span><span class="cov0" title="0">{
                in, out := &amp;in.RetryPolicy, &amp;out.RetryPolicy
                *out = new(WebhookRetryPolicy)
                **out = **in
        }</span>
}

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WebhookSpec.
func (in *WebhookSpec) DeepCopy() *WebhookSpec <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WebhookSpec)
        in.DeepCopyInto(out)
        return out</span>
}

// DeepCopyInto is an autogenerated deepcopy function, copying the receiver, writing into out. in must be non-nil.
func (in *WebhookTLSConfig) DeepCopyInto(out *WebhookTLSConfig) <span class="cov0" title="0">{
        *out = *in
}</span>

// DeepCopy is an autogenerated deepcopy function, copying the receiver, creating a new WebhookTLSConfig.
func (in *WebhookTLSConfig) DeepCopy() *WebhookTLSConfig <span class="cov0" title="0">{
        if in == nil </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">out := new(WebhookTLSConfig)
        in.DeepCopyInto(out)
        return out</span>
}
</pre>
		
		<pre class="file" id="file4" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package audit

import (
        "context"
        "encoding/json"
        "fmt"
        "os"
        "path/filepath"
        "sync"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// AuditEvent represents a single audit event
type AuditEvent struct {
        Timestamp     time.Time                    `json:"timestamp"`
        EventID       string                       `json:"eventId"`
        EventType     string                       `json:"eventType"`
        Operation     string                       `json:"operation"`
        Namespace     string                       `json:"namespace"`
        PodName       string                       `json:"podName"`
        ContainerName string                       `json:"containerName"`
        User          string                       `json:"user"`
        Source        string                       `json:"source"`
        Reason        string                       `json:"reason"`
        OldResources  *corev1.ResourceRequirements `json:"oldResources,omitempty"`
        NewResources  *corev1.ResourceRequirements `json:"newResources,omitempty"`
        Annotations   map[string]string            `json:"annotations,omitempty"`
        Labels        map[string]string            `json:"labels,omitempty"`
        Status        string                       `json:"status"`
        Error         string                       `json:"error,omitempty"`
        Duration      time.Duration                `json:"duration,omitempty"`
        Metadata      map[string]interface{}       `json:"metadata,omitempty"`
}

// AuditLogger handles audit logging for resource changes
type AuditLogger struct {
        config         *config.Config
        metrics        *metrics.OperatorMetrics
        client         client.Client
        logFile        *os.File
        logChannel     chan AuditEvent
        stopChannel    chan struct{}
        wg             sync.WaitGroup
        mutex          sync.RWMutex
        eventIDCounter uint64
}

// AuditConfig holds audit logger configuration
type AuditConfig struct {
        LogPath        string
        MaxFileSize    int64
        MaxFiles       int
        BufferSize     int
        FlushInterval  time.Duration
        EnableFileLog  bool
        EnableEventLog bool
        EnableMetrics  bool
        RetentionDays  int
}

// DefaultAuditConfig returns default audit configuration
func DefaultAuditConfig() AuditConfig <span class="cov0" title="0">{
        return AuditConfig{
                LogPath:        "/tmp/right-sizer-audit.log", // Use /tmp which is typically writable in containers
                MaxFileSize:    100 * 1024 * 1024,            // 100MB
                MaxFiles:       10,
                BufferSize:     1000,
                FlushInterval:  5 * time.Second,
                EnableFileLog:  true,
                EnableEventLog: true,
                EnableMetrics:  true,
                RetentionDays:  30,
        }
}</span>

// NewAuditLogger creates a new audit logger
func NewAuditLogger(client client.Client, cfg *config.Config, metrics *metrics.OperatorMetrics, auditConfig AuditConfig) (*AuditLogger, error) <span class="cov0" title="0">{
        al := &amp;AuditLogger{
                config:      cfg,
                metrics:     metrics,
                client:      client,
                logChannel:  make(chan AuditEvent, auditConfig.BufferSize),
                stopChannel: make(chan struct{}),
        }

        // Create log directory if it doesn't exist
        if auditConfig.EnableFileLog </span><span class="cov0" title="0">{
                logDir := filepath.Dir(auditConfig.LogPath)
                if err := os.MkdirAll(logDir, 0755); err != nil </span><span class="cov0" title="0">{
                        return nil, fmt.Errorf("failed to create audit log directory: %v", err)
                }</span>

                // Open log file if file logging is enabled
                <span class="cov0" title="0">var logFile *os.File
                if auditConfig.EnableFileLog </span><span class="cov0" title="0">{
                        var err error
                        logFile, err = os.OpenFile(auditConfig.LogPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
                        if err != nil </span><span class="cov0" title="0">{
                                // If we can't open the file, continue without file logging
                                logger.Warn("Cannot open audit log file, continuing without file logging: %v", err)
                                auditConfig.EnableFileLog = false
                                logFile = nil
                        }</span>
                }
                <span class="cov0" title="0">al.logFile = logFile</span>
        }

        // Start background processor
        <span class="cov0" title="0">al.wg.Add(1)
        go al.processAuditEvents(auditConfig)

        logger.Info("Audit logger initialized with file logging: %v, event logging: %v",
                auditConfig.EnableFileLog, auditConfig.EnableEventLog)

        return al, nil</span>
}

// Close closes the audit logger and flushes remaining events
func (al *AuditLogger) Close() error <span class="cov0" title="0">{
        close(al.stopChannel)
        al.wg.Wait()

        if al.logFile != nil </span><span class="cov0" title="0">{
                return al.logFile.Close()
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// LogResourceChange logs a resource change event
func (al *AuditLogger) LogResourceChange(ctx context.Context, pod *corev1.Pod, containerName string, oldResources, newResources corev1.ResourceRequirements, operation, reason, status string, duration time.Duration, err error) <span class="cov0" title="0">{
        event := AuditEvent{
                Timestamp:     time.Now(),
                EventID:       al.generateEventID(),
                EventType:     "ResourceChange",
                Operation:     operation,
                Namespace:     pod.Namespace,
                PodName:       pod.Name,
                ContainerName: containerName,
                User:          "right-sizer-operator",
                Source:        "right-sizer",
                Reason:        reason,
                OldResources:  &amp;oldResources,
                NewResources:  &amp;newResources,
                Annotations:   pod.Annotations,
                Labels:        pod.Labels,
                Status:        status,
                Duration:      duration,
                Metadata: map[string]interface{}{
                        "podUID":   string(pod.UID),
                        "podPhase": string(pod.Status.Phase),
                        "nodeName": pod.Spec.NodeName,
                        "qosClass": string(getQoSClass(pod)),
                },
        }

        if err != nil </span><span class="cov0" title="0">{
                event.Error = err.Error()
        }</span>

        <span class="cov0" title="0">al.logEvent(event)</span>
}

// LogPolicyApplication logs a policy application event
func (al *AuditLogger) LogPolicyApplication(ctx context.Context, pod *corev1.Pod, containerName, policyName, result, reason string) <span class="cov0" title="0">{
        event := AuditEvent{
                Timestamp:     time.Now(),
                EventID:       al.generateEventID(),
                EventType:     "PolicyApplication",
                Operation:     "policy_evaluation",
                Namespace:     pod.Namespace,
                PodName:       pod.Name,
                ContainerName: containerName,
                User:          "right-sizer-operator",
                Source:        "policy-engine",
                Reason:        reason,
                Status:        result,
                Metadata: map[string]interface{}{
                        "policyName": policyName,
                        "podUID":     string(pod.UID),
                },
        }

        al.logEvent(event)
}</span>

// LogValidationResult logs a validation result event
func (al *AuditLogger) LogValidationResult(ctx context.Context, pod *corev1.Pod, containerName, validationType string, valid bool, errors, warnings []string) <span class="cov0" title="0">{
        status := "success"
        if !valid </span><span class="cov0" title="0">{
                status = "failure"
        }</span>

        <span class="cov0" title="0">event := AuditEvent{
                Timestamp:     time.Now(),
                EventID:       al.generateEventID(),
                EventType:     "ResourceValidation",
                Operation:     validationType,
                Namespace:     pod.Namespace,
                PodName:       pod.Name,
                ContainerName: containerName,
                User:          "right-sizer-operator",
                Source:        "resource-validator",
                Status:        status,
                Metadata: map[string]interface{}{
                        "validationType": validationType,
                        "errors":         errors,
                        "warnings":       warnings,
                        "podUID":         string(pod.UID),
                },
        }

        al.logEvent(event)</span>
}

// LogOperatorEvent logs general operator events
func (al *AuditLogger) LogOperatorEvent(eventType, operation, reason, status string, metadata map[string]interface{}) <span class="cov0" title="0">{
        event := AuditEvent{
                Timestamp: time.Now(),
                EventID:   al.generateEventID(),
                EventType: eventType,
                Operation: operation,
                User:      "right-sizer-operator",
                Source:    "operator",
                Reason:    reason,
                Status:    status,
                Metadata:  metadata,
        }

        al.logEvent(event)
}</span>

// LogSecurityEvent logs security-related events
func (al *AuditLogger) LogSecurityEvent(ctx context.Context, eventType, operation, namespace, user, reason, status string, metadata map[string]interface{}) <span class="cov0" title="0">{
        if metadata == nil </span><span class="cov0" title="0">{
                metadata = make(map[string]interface{})
        }</span>

        <span class="cov0" title="0">metadata["securityEvent"] = true
        metadata["userAgent"] = al.getUserAgent(ctx)

        event := AuditEvent{
                Timestamp: time.Now(),
                EventID:   al.generateEventID(),
                EventType: eventType,
                Operation: operation,
                Namespace: namespace,
                User:      user,
                Source:    "admission-controller",
                Reason:    reason,
                Status:    status,
                Metadata:  metadata,
        }

        al.logEvent(event)</span>
}

// logEvent sends an event to the processing channel
func (al *AuditLogger) logEvent(event AuditEvent) <span class="cov0" title="0">{
        select </span>{
        case al.logChannel &lt;- event:<span class="cov0" title="0"></span>
                // Event queued successfully
        default:<span class="cov0" title="0">
                // Channel is full, log warning
                logger.Warn("Audit log channel is full, dropping event %s", event.EventID)
                if al.metrics != nil </span><span class="cov0" title="0">{
                        al.metrics.RecordProcessingError("", "", "audit_buffer_full")
                }</span>
        }
}

// processAuditEvents processes audit events in the background
func (al *AuditLogger) processAuditEvents(config AuditConfig) <span class="cov0" title="0">{
        defer al.wg.Done()

        ticker := time.NewTicker(config.FlushInterval)
        defer ticker.Stop()

        var eventBuffer []AuditEvent

        for </span><span class="cov0" title="0">{
                select </span>{
                case event := &lt;-al.logChannel:<span class="cov0" title="0">
                        eventBuffer = append(eventBuffer, event)
                        al.processEvent(event, config)

                        // Flush buffer if it gets too large
                        if len(eventBuffer) &gt;= config.BufferSize/2 </span><span class="cov0" title="0">{
                                al.flushEvents(eventBuffer, config)
                                eventBuffer = eventBuffer[:0]
                        }</span>

                case &lt;-ticker.C:<span class="cov0" title="0">
                        // Periodic flush
                        if len(eventBuffer) &gt; 0 </span><span class="cov0" title="0">{
                                al.flushEvents(eventBuffer, config)
                                eventBuffer = eventBuffer[:0]
                        }</span>

                case &lt;-al.stopChannel:<span class="cov0" title="0">
                        // Flush remaining events before stopping
                        if len(eventBuffer) &gt; 0 </span><span class="cov0" title="0">{
                                al.flushEvents(eventBuffer, config)
                        }</span>
                        <span class="cov0" title="0">return</span>
                }
        }
}

// processEvent processes a single audit event
func (al *AuditLogger) processEvent(event AuditEvent, config AuditConfig) <span class="cov0" title="0">{
        // Write to file log
        if config.EnableFileLog &amp;&amp; al.logFile != nil </span><span class="cov0" title="0">{
                al.writeToFile(event)
        }</span>

        // Create Kubernetes event
        <span class="cov0" title="0">if config.EnableEventLog </span><span class="cov0" title="0">{
                al.createKubernetesEvent(event)
        }</span>

        // Update metrics
        <span class="cov0" title="0">if config.EnableMetrics &amp;&amp; al.metrics != nil </span><span class="cov0" title="0">{
                al.updateMetrics(event)
        }</span>
}

// writeToFile writes an event to the audit log file
func (al *AuditLogger) writeToFile(event AuditEvent) <span class="cov0" title="0">{
        al.mutex.Lock()
        defer al.mutex.Unlock()

        eventJSON, err := json.Marshal(event)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to marshal audit event: %v", err)
                return
        }</span>

        <span class="cov0" title="0">if _, err := al.logFile.WriteString(string(eventJSON) + "\n"); err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to write audit event to file: %v", err)
        }</span>
}

// createKubernetesEvent creates a Kubernetes event for the audit event
func (al *AuditLogger) createKubernetesEvent(event AuditEvent) <span class="cov0" title="0">{
        if al.client == nil || event.Namespace == "" || event.PodName == "" </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
        defer cancel()

        // Create event object
        kubeEvent := &amp;corev1.Event{
                ObjectMeta: metav1.ObjectMeta{
                        GenerateName: "right-sizer-audit-",
                        Namespace:    event.Namespace,
                },
                InvolvedObject: corev1.ObjectReference{
                        Kind:      "Pod",
                        Name:      event.PodName,
                        Namespace: event.Namespace,
                },
                Reason:  event.Reason,
                Message: al.formatEventMessage(event),
                Source: corev1.EventSource{
                        Component: "right-sizer",
                        Host:      os.Getenv("HOSTNAME"),
                },
                FirstTimestamp: metav1.Time{Time: event.Timestamp},
                LastTimestamp:  metav1.Time{Time: event.Timestamp},
                Count:          1,
                Type:           al.getEventType(event.Status),
        }

        if err := al.client.Create(ctx, kubeEvent); err != nil </span><span class="cov0" title="0">{
                logger.Debug("Failed to create Kubernetes event: %v", err)
        }</span>
}

// formatEventMessage formats the audit event into a human-readable message
func (al *AuditLogger) formatEventMessage(event AuditEvent) string <span class="cov0" title="0">{
        switch event.EventType </span>{
        case "ResourceChange":<span class="cov0" title="0">
                return fmt.Sprintf("%s: %s resources for container %s from %s to %s (reason: %s)",
                        event.Operation, event.Status, event.ContainerName,
                        al.formatResources(event.OldResources), al.formatResources(event.NewResources), event.Reason)</span>
        case "PolicyApplication":<span class="cov0" title="0">
                return fmt.Sprintf("Policy %s applied to container %s: %s",
                        event.Metadata["policyName"], event.ContainerName, event.Reason)</span>
        case "ResourceValidation":<span class="cov0" title="0">
                return fmt.Sprintf("Resource validation %s for container %s: %s",
                        event.Status, event.ContainerName, event.Reason)</span>
        default:<span class="cov0" title="0">
                return fmt.Sprintf("%s %s: %s", event.EventType, event.Operation, event.Reason)</span>
        }
}

// formatResources formats resource requirements for display
func (al *AuditLogger) formatResources(resources *corev1.ResourceRequirements) string <span class="cov0" title="0">{
        if resources == nil </span><span class="cov0" title="0">{
                return "none"
        }</span>

        <span class="cov0" title="0">var parts []string
        if resources.Requests != nil </span><span class="cov0" title="0">{
                if cpu, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        parts = append(parts, fmt.Sprintf("CPU req: %s", cpu.String()))
                }</span>
                <span class="cov0" title="0">if mem, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        parts = append(parts, fmt.Sprintf("Mem req: %s", mem.String()))
                }</span>
        }
        <span class="cov0" title="0">if resources.Limits != nil </span><span class="cov0" title="0">{
                if cpu, ok := resources.Limits[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        parts = append(parts, fmt.Sprintf("CPU lim: %s", cpu.String()))
                }</span>
                <span class="cov0" title="0">if mem, ok := resources.Limits[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        parts = append(parts, fmt.Sprintf("Mem lim: %s", mem.String()))
                }</span>
        }

        <span class="cov0" title="0">if len(parts) == 0 </span><span class="cov0" title="0">{
                return "none"
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("[%s]", fmt.Sprintf("%v", parts))</span>
}

// getEventType determines the Kubernetes event type based on status
func (al *AuditLogger) getEventType(status string) string <span class="cov0" title="0">{
        switch status </span>{
        case "success", "applied", "valid":<span class="cov0" title="0">
                return corev1.EventTypeNormal</span>
        case "failure", "error", "invalid":<span class="cov0" title="0">
                return corev1.EventTypeWarning</span>
        default:<span class="cov0" title="0">
                return corev1.EventTypeNormal</span>
        }
}

// updateMetrics updates audit-related metrics
func (al *AuditLogger) updateMetrics(event AuditEvent) <span class="cov0" title="0">{
        // Record audit events by type and status
        // This would require extending the metrics package with audit-specific metrics
        logger.Debug("Audit event recorded: %s/%s", event.EventType, event.Status)
}</span>

// flushEvents flushes a batch of events
func (al *AuditLogger) flushEvents(events []AuditEvent, config AuditConfig) <span class="cov0" title="0">{
        if al.logFile != nil </span><span class="cov0" title="0">{
                al.logFile.Sync()
        }</span>

        // Perform log rotation if needed
        <span class="cov0" title="0">if config.EnableFileLog </span><span class="cov0" title="0">{
                al.checkLogRotation(config)
        }</span>
}

// checkLogRotation checks if log rotation is needed
func (al *AuditLogger) checkLogRotation(config AuditConfig) <span class="cov0" title="0">{
        if al.logFile == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">stat, err := al.logFile.Stat()
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">if stat.Size() &gt;= config.MaxFileSize </span><span class="cov0" title="0">{
                al.rotateLogFile(config)
        }</span>
}

// rotateLogFile rotates the current log file
func (al *AuditLogger) rotateLogFile(config AuditConfig) <span class="cov0" title="0">{
        al.mutex.Lock()
        defer al.mutex.Unlock()

        if al.logFile != nil </span><span class="cov0" title="0">{
                al.logFile.Close()
        }</span>

        // Rename current log file
        <span class="cov0" title="0">timestamp := time.Now().Format("20060102-150405")
        oldPath := config.LogPath
        newPath := fmt.Sprintf("%s.%s", oldPath, timestamp)

        if err := os.Rename(oldPath, newPath); err != nil </span><span class="cov0" title="0">{
                logger.Warn("Failed to rotate audit log: %v", err)
        }</span>

        // Create new log file
        <span class="cov0" title="0">logFile, err := os.OpenFile(oldPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to create new audit log file: %v", err)
                return
        }</span>

        <span class="cov0" title="0">al.logFile = logFile
        logger.Info("Rotated audit log file to %s", newPath)

        // Clean up old log files
        al.cleanupOldLogs(config)</span>
}

// cleanupOldLogs removes old audit log files based on retention policy
func (al *AuditLogger) cleanupOldLogs(config AuditConfig) <span class="cov0" title="0">{
        logDir := filepath.Dir(config.LogPath)
        logBase := filepath.Base(config.LogPath)

        files, err := filepath.Glob(filepath.Join(logDir, logBase+".*"))
        if err != nil </span><span class="cov0" title="0">{
                return
        }</span>

        // Sort files by modification time and remove old ones
        <span class="cov0" title="0">cutoff := time.Now().AddDate(0, 0, -config.RetentionDays)

        for _, file := range files </span><span class="cov0" title="0">{
                stat, err := os.Stat(file)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">if stat.ModTime().Before(cutoff) </span><span class="cov0" title="0">{
                        if err := os.Remove(file); err != nil </span><span class="cov0" title="0">{
                                logger.Warn("Failed to remove old audit log %s: %v", file, err)
                        }</span> else<span class="cov0" title="0"> {
                                logger.Info("Removed old audit log %s", file)
                        }</span>
                }
        }
}

// generateEventID generates a unique event ID
func (al *AuditLogger) generateEventID() string <span class="cov0" title="0">{
        al.mutex.Lock()
        defer al.mutex.Unlock()

        al.eventIDCounter++
        return fmt.Sprintf("audit-%d-%d", time.Now().Unix(), al.eventIDCounter)
}</span>

// getUserAgent extracts user agent from context
func (al *AuditLogger) getUserAgent(ctx context.Context) string <span class="cov0" title="0">{
        // This would extract user agent from request context in a real implementation
        return "right-sizer-operator"
}</span>

// getQoSClass determines the QoS class of a pod
func getQoSClass(pod *corev1.Pod) corev1.PodQOSClass <span class="cov0" title="0">{
        requests := make(corev1.ResourceList)
        limits := make(corev1.ResourceList)
        zeroQuantity := resource.MustParse("0")
        isGuaranteed := true

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Accumulate requests
                for name, quantity := range container.Resources.Requests </span><span class="cov0" title="0">{
                        if value, exists := requests[name]; !exists </span><span class="cov0" title="0">{
                                requests[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                requests[name] = value
                        }</span>
                }

                // Accumulate limits
                <span class="cov0" title="0">for name, quantity := range container.Resources.Limits </span><span class="cov0" title="0">{
                        if value, exists := limits[name]; !exists </span><span class="cov0" title="0">{
                                limits[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                limits[name] = value
                        }</span>
                }
        }

        // Check if guaranteed
        <span class="cov0" title="0">if len(requests) == 0 || len(limits) == 0 </span><span class="cov0" title="0">{
                isGuaranteed = false
        }</span> else<span class="cov0" title="0"> {
                for name, req := range requests </span><span class="cov0" title="0">{
                        if limit, exists := limits[name]; !exists || limit.Cmp(req) != 0 </span><span class="cov0" title="0">{
                                isGuaranteed = false
                                break</span>
                        }
                }
        }

        <span class="cov0" title="0">if isGuaranteed </span><span class="cov0" title="0">{
                return corev1.PodQOSGuaranteed
        }</span>

        // Check if burstable (has some requests or limits)
        <span class="cov0" title="0">for _, req := range requests </span><span class="cov0" title="0">{
                if req.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">for _, limit := range limits </span><span class="cov0" title="0">{
                if limit.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">return corev1.PodQOSBestEffort</span>
}
</pre>
		
		<pre class="file" id="file5" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package config

import (
        "fmt"
        "strings"
        "sync"
        "time"
)

// Config holds all configuration for resource sizing
// This configuration is now loaded from CRDs instead of environment variables
// NotificationConfig holds notification settings
type NotificationConfig struct {
        EnableNotifications bool     // Enable sending notifications
        SlackWebhookURL     string   // Slack webhook URL for notifications
        EmailRecipients     []string // Email addresses to notify
        SMTPHost            string   // SMTP server host
        SMTPPort            int      // SMTP server port
        SMTPUsername        string   // SMTP username
        SMTPPassword        string   // SMTP password
}

type Config struct {
        mu sync.RWMutex

        // Request multipliers - how much to multiply usage to get requests
        CPURequestMultiplier    float64
        MemoryRequestMultiplier float64

        // Request additions - fixed amount to add to usage for requests
        CPURequestAddition    int64 // in millicores
        MemoryRequestAddition int64 // in MB

        // Limit multipliers - how much to multiply requests to get limits
        CPULimitMultiplier    float64
        MemoryLimitMultiplier float64

        // Limit additions - fixed amount to add to requests for limits
        CPULimitAddition    int64 // in millicores
        MemoryLimitAddition int64 // in MB

        // Maximum caps for resources
        MaxCPULimit    int64 // in millicores
        MaxMemoryLimit int64 // in MB

        // Minimum values for resources
        MinCPURequest    int64 // in millicores
        MinMemoryRequest int64 // in MB

        // Operational configuration
        ResizeInterval time.Duration // How often to check and resize resources
        LogLevel       string        // Log level: debug, info, warn, error
        MaxRetries     int           // Maximum retry attempts for operations
        RetryInterval  time.Duration // Interval between retries
        MetricsEnabled bool          // Enable Prometheus metrics
        MetricsPort    int           // Port for metrics endpoint

        // Rate limiting and concurrency control
        QPS                     float32 // Queries Per Second for K8s API client
        Burst                   int     // Burst capacity for K8s API client
        MaxConcurrentReconciles int     // Max concurrent reconciles per controller
        AuditEnabled            bool    // Enable audit logging for resource changes
        DryRun                  bool    // Only log recommendations without applying changes
        SafetyThreshold         float64 // Safety threshold for resource changes (0-1)

        // Batch processing configuration for API server protection
        BatchSize           int           // Number of pods to process per batch
        DelayBetweenBatches time.Duration // Delay between processing batches
        DelayBetweenPods    time.Duration // Delay between individual pod updates

        // Namespace filters
        NamespaceInclude []string // Namespaces to include
        NamespaceExclude []string // Namespaces to exclude

        // Advanced features
        HistoryDays         int      // Days of history to keep for trend analysis
        CustomMetrics       []string // Custom metrics to consider
        AdmissionController bool     // Enable admission controller for validation

        // Metrics provider configuration
        MetricsProvider       string // "metrics-server" or "prometheus"
        PrometheusURL         string // URL for Prometheus if used
        MetricsServerEndpoint string // Endpoint for metrics server

        // Feature flags
        EnableInPlaceResize bool // Enable in-place pod resizing (Kubernetes 1.33+)

        // QoS preservation settings
        PreserveGuaranteedQoS      bool // Preserve Guaranteed QoS class during resizing
        ForceGuaranteedForCritical bool // Force Guaranteed QoS for critical workloads
        QoSTransitionWarning       bool // Warn when QoS class would change

        // Scaling thresholds
        MemoryScaleUpThreshold   float64 // Memory usage percentage to trigger scale up (0-1)
        MemoryScaleDownThreshold float64 // Memory usage percentage to trigger scale down (0-1)
        CPUScaleUpThreshold      float64 // CPU usage percentage to trigger scale up (0-1)
        CPUScaleDownThreshold    float64 // CPU usage percentage to trigger scale down (0-1)

        // Notification configuration
        NotificationConfig *NotificationConfig // Notification settings

        // Configuration source tracking
        ConfigSource string // "default" or "crd"
}

// Global config instance with thread-safe access
var (
        Global     *Config
        globalLock sync.RWMutex
)

// GetDefaults returns a new Config with default values
func GetDefaults() *Config <span class="cov8" title="1">{
        return &amp;Config{
                // Default resource sizing values
                CPURequestMultiplier:    1.2,
                MemoryRequestMultiplier: 1.2,
                CPURequestAddition:      0,
                MemoryRequestAddition:   0,
                CPULimitMultiplier:      2.0,
                MemoryLimitMultiplier:   2.0,
                CPULimitAddition:        0,
                MemoryLimitAddition:     0,
                MaxCPULimit:             4000,
                MaxMemoryLimit:          8192,
                MinCPURequest:           10,
                MinMemoryRequest:        64,

                // Default QoS preservation settings
                PreserveGuaranteedQoS:      true,
                ForceGuaranteedForCritical: false,
                QoSTransitionWarning:       true,

                // Default operational settings
                ResizeInterval: 30 * time.Second,
                LogLevel:       "info",
                MaxRetries:     3,
                RetryInterval:  5 * time.Second,
                MetricsEnabled: true,
                MetricsPort:    9090,

                // Default rate limiting values
                QPS:                     20,
                Burst:                   30,
                MaxConcurrentReconciles: 3,
                AuditEnabled:            true,
                DryRun:                  false,
                SafetyThreshold:         0.5, // 50% change threshold

                // Default batch processing values
                BatchSize:           3,
                DelayBetweenBatches: 5 * time.Second,
                DelayBetweenPods:    500 * time.Millisecond,

                // Default advanced features
                HistoryDays:         7,
                AdmissionController: false,

                // Default metrics configuration
                MetricsProvider:       "metrics-server",
                MetricsServerEndpoint: "",
                PrometheusURL:         "http://prometheus:9090",

                // Default feature flags
                EnableInPlaceResize: false,

                // Default scaling thresholds
                MemoryScaleUpThreshold:   0.8, // Scale up when memory usage exceeds 80%
                MemoryScaleDownThreshold: 0.3, // Scale down when memory usage is below 30%
                CPUScaleUpThreshold:      0.8, // Scale up when CPU usage exceeds 80%
                CPUScaleDownThreshold:    0.3, // Scale down when CPU usage is below 30%

                // Default notification configuration
                NotificationConfig: &amp;NotificationConfig{
                        EnableNotifications: false,
                        SlackWebhookURL:     "",
                        EmailRecipients:     []string{},
                        SMTPHost:            "",
                        SMTPPort:            587,
                        SMTPUsername:        "",
                        SMTPPassword:        "",
                },

                // Mark as default configuration
                ConfigSource: "default",
        }
}</span>

// Load initializes the configuration with defaults
// CRD-based configuration will override these defaults when applied
func Load() *Config <span class="cov8" title="1">{
        globalLock.Lock()
        defer globalLock.Unlock()

        if Global == nil </span><span class="cov8" title="1">{
                Global = GetDefaults()
        }</span>
        <span class="cov8" title="1">return Global</span>
}

// Get returns the global config instance, loading it if necessary
func Get() *Config <span class="cov8" title="1">{
        globalLock.RLock()
        if Global == nil </span><span class="cov8" title="1">{
                globalLock.RUnlock()
                globalLock.Lock()
                if Global == nil </span><span class="cov8" title="1">{
                        Global = GetDefaults()
                }</span>
                <span class="cov8" title="1">globalLock.Unlock()
                globalLock.RLock()</span>
        }
        <span class="cov8" title="1">defer globalLock.RUnlock()
        return Global</span>
}

// UpdateFromCRD updates the configuration from a CRD specification
// This is called by the RightSizerConfig controller when a CRD is created or updated
func (c *Config) UpdateFromCRD(
        cpuRequestMultiplier, memoryRequestMultiplier float64,
        cpuRequestAddition, memoryRequestAddition int64,
        cpuLimitMultiplier, memoryLimitMultiplier float64,
        cpuLimitAddition, memoryLimitAddition int64,
        minCPURequest, minMemoryRequest int64,
        maxCPULimit, maxMemoryLimit int64,
        resizeInterval time.Duration,
        dryRun bool,
        namespaceInclude, namespaceExclude []string,
        logLevel string,
        metricsEnabled bool,
        metricsPort int,
        auditEnabled bool,
        maxRetries int,
        retryInterval time.Duration,
        metricsProvider, prometheusURL string,
        enableInPlaceResize bool,
        qps float32, burst, maxConcurrentReconciles int,
        memoryScaleUpThreshold, memoryScaleDownThreshold float64,
        cpuScaleUpThreshold, cpuScaleDownThreshold float64,
) <span class="cov8" title="1">{
        c.mu.Lock()
        defer c.mu.Unlock()

        // Update resource configuration
        if cpuRequestMultiplier &gt; 0 </span><span class="cov8" title="1">{
                c.CPURequestMultiplier = cpuRequestMultiplier
        }</span>
        <span class="cov8" title="1">if memoryRequestMultiplier &gt; 0 </span><span class="cov8" title="1">{
                c.MemoryRequestMultiplier = memoryRequestMultiplier
        }</span>
        <span class="cov8" title="1">c.CPURequestAddition = cpuRequestAddition
        c.MemoryRequestAddition = memoryRequestAddition

        if cpuLimitMultiplier &gt; 0 </span><span class="cov8" title="1">{
                c.CPULimitMultiplier = cpuLimitMultiplier
        }</span>
        <span class="cov8" title="1">if memoryLimitMultiplier &gt; 0 </span><span class="cov8" title="1">{
                c.MemoryLimitMultiplier = memoryLimitMultiplier
        }</span>
        <span class="cov8" title="1">c.CPULimitAddition = cpuLimitAddition
        c.MemoryLimitAddition = memoryLimitAddition

        if minCPURequest &gt; 0 </span><span class="cov8" title="1">{
                c.MinCPURequest = minCPURequest
        }</span>
        <span class="cov8" title="1">if minMemoryRequest &gt; 0 </span><span class="cov8" title="1">{
                c.MinMemoryRequest = minMemoryRequest
        }</span>
        <span class="cov8" title="1">if maxCPULimit &gt; 0 </span><span class="cov8" title="1">{
                c.MaxCPULimit = maxCPULimit
        }</span>
        <span class="cov8" title="1">if maxMemoryLimit &gt; 0 </span><span class="cov8" title="1">{
                c.MaxMemoryLimit = maxMemoryLimit
        }</span>

        // Update operational configuration
        <span class="cov8" title="1">if resizeInterval &gt; 0 </span><span class="cov8" title="1">{
                c.ResizeInterval = resizeInterval
        }</span>
        <span class="cov8" title="1">c.DryRun = dryRun

        // Update namespace filters
        if len(namespaceInclude) &gt; 0 </span><span class="cov8" title="1">{
                c.NamespaceInclude = namespaceInclude
        }</span>
        <span class="cov8" title="1">if len(namespaceExclude) &gt; 0 </span><span class="cov8" title="1">{
                c.NamespaceExclude = namespaceExclude
        }</span>

        // Update observability settings
        <span class="cov8" title="1">if logLevel != "" </span><span class="cov8" title="1">{
                c.LogLevel = logLevel
        }</span>
        <span class="cov8" title="1">c.MetricsEnabled = metricsEnabled
        if metricsPort &gt; 0 </span><span class="cov8" title="1">{
                c.MetricsPort = metricsPort
        }</span>
        <span class="cov8" title="1">c.AuditEnabled = auditEnabled

        // Update rate limiting configuration
        if qps &gt; 0 </span><span class="cov8" title="1">{
                c.QPS = qps
        }</span>
        <span class="cov8" title="1">if burst &gt; 0 </span><span class="cov8" title="1">{
                c.Burst = burst
        }</span>
        <span class="cov8" title="1">if maxConcurrentReconciles &gt; 0 </span><span class="cov8" title="1">{
                c.MaxConcurrentReconciles = maxConcurrentReconciles
        }</span>

        // Update metrics configuration
        <span class="cov8" title="1">if maxRetries &gt; 0 </span><span class="cov8" title="1">{
                c.MaxRetries = maxRetries
        }</span>
        <span class="cov8" title="1">if retryInterval &gt; 0 </span><span class="cov8" title="1">{
                c.RetryInterval = retryInterval
        }</span>

        // Update metrics provider configuration
        <span class="cov8" title="1">if metricsProvider != "" </span><span class="cov8" title="1">{
                c.MetricsProvider = metricsProvider
        }</span>
        <span class="cov8" title="1">if prometheusURL != "" </span><span class="cov8" title="1">{
                c.PrometheusURL = prometheusURL
        }</span>

        // Update feature flags
        <span class="cov8" title="1">c.EnableInPlaceResize = enableInPlaceResize

        // Update scaling thresholds
        if memoryScaleUpThreshold &gt; 0 &amp;&amp; memoryScaleUpThreshold &lt;= 1 </span><span class="cov8" title="1">{
                c.MemoryScaleUpThreshold = memoryScaleUpThreshold
        }</span>
        <span class="cov8" title="1">if memoryScaleDownThreshold &gt; 0 &amp;&amp; memoryScaleDownThreshold &lt;= 1 </span><span class="cov8" title="1">{
                c.MemoryScaleDownThreshold = memoryScaleDownThreshold
        }</span>
        <span class="cov8" title="1">if cpuScaleUpThreshold &gt; 0 &amp;&amp; cpuScaleUpThreshold &lt;= 1 </span><span class="cov8" title="1">{
                c.CPUScaleUpThreshold = cpuScaleUpThreshold
        }</span>
        <span class="cov8" title="1">if cpuScaleDownThreshold &gt; 0 &amp;&amp; cpuScaleDownThreshold &lt;= 1 </span><span class="cov8" title="1">{
                c.CPUScaleDownThreshold = cpuScaleDownThreshold
        }</span>

        // Mark configuration as coming from CRD
        <span class="cov8" title="1">c.ConfigSource = "crd"</span>
}

// ResetToDefaults resets the configuration to default values
func (c *Config) ResetToDefaults() <span class="cov8" title="1">{
        c.mu.Lock()
        defer c.mu.Unlock()

        defaults := GetDefaults()
        // Copy fields individually to avoid copying the mutex
        c.CPURequestMultiplier = defaults.CPURequestMultiplier
        c.MemoryRequestMultiplier = defaults.MemoryRequestMultiplier
        c.CPURequestAddition = defaults.CPURequestAddition
        c.MemoryRequestAddition = defaults.MemoryRequestAddition
        c.CPULimitMultiplier = defaults.CPULimitMultiplier
        c.MemoryLimitMultiplier = defaults.MemoryLimitMultiplier
        c.CPULimitAddition = defaults.CPULimitAddition
        c.MemoryLimitAddition = defaults.MemoryLimitAddition
        c.MinCPURequest = defaults.MinCPURequest
        c.MinMemoryRequest = defaults.MinMemoryRequest
        c.MaxCPULimit = defaults.MaxCPULimit
        c.MaxMemoryLimit = defaults.MaxMemoryLimit
        c.ResizeInterval = defaults.ResizeInterval
        c.LogLevel = defaults.LogLevel
        c.MaxRetries = defaults.MaxRetries
        c.RetryInterval = defaults.RetryInterval
        c.MetricsEnabled = defaults.MetricsEnabled
        c.MetricsPort = defaults.MetricsPort
        c.QPS = defaults.QPS
        c.Burst = defaults.Burst
        c.MaxConcurrentReconciles = defaults.MaxConcurrentReconciles
        c.AuditEnabled = defaults.AuditEnabled
        c.DryRun = defaults.DryRun
        c.SafetyThreshold = defaults.SafetyThreshold
        c.NamespaceInclude = defaults.NamespaceInclude
        c.NamespaceExclude = defaults.NamespaceExclude
        c.HistoryDays = defaults.HistoryDays
        c.CustomMetrics = defaults.CustomMetrics
        c.AdmissionController = defaults.AdmissionController
        c.MetricsProvider = defaults.MetricsProvider
        c.PrometheusURL = defaults.PrometheusURL
        c.MetricsServerEndpoint = defaults.MetricsServerEndpoint
        c.EnableInPlaceResize = defaults.EnableInPlaceResize
        c.MemoryScaleUpThreshold = defaults.MemoryScaleUpThreshold
        c.MemoryScaleDownThreshold = defaults.MemoryScaleDownThreshold
        c.CPUScaleUpThreshold = defaults.CPUScaleUpThreshold
        c.CPUScaleDownThreshold = defaults.CPUScaleDownThreshold
        c.NotificationConfig = defaults.NotificationConfig
        c.ConfigSource = defaults.ConfigSource
}</span>

// Validate checks the configuration for consistency and validity
func (c *Config) Validate() error <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()

        var errors []string

        // Validate multipliers
        if c.CPURequestMultiplier &lt;= 0 </span><span class="cov8" title="1">{
                errors = append(errors, "CPU request multiplier must be positive")
        }</span>
        <span class="cov8" title="1">if c.MemoryRequestMultiplier &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "memory request multiplier must be positive")
        }</span>
        <span class="cov8" title="1">if c.CPULimitMultiplier &lt;= 0 </span><span class="cov8" title="1">{
                errors = append(errors, "CPU limit multiplier must be positive")
        }</span>
        <span class="cov8" title="1">if c.MemoryLimitMultiplier &lt;= 0 </span><span class="cov8" title="1">{
                errors = append(errors, "memory limit multiplier must be positive")
        }</span>

        // Validate resource boundaries
        <span class="cov8" title="1">if c.MinCPURequest &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "minimum CPU request must be positive")
        }</span>
        <span class="cov8" title="1">if c.MinMemoryRequest &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "minimum memory request must be positive")
        }</span>
        <span class="cov8" title="1">if c.MaxCPULimit &lt;= c.MinCPURequest </span><span class="cov8" title="1">{
                errors = append(errors, "maximum CPU limit must be greater than minimum CPU request")
        }</span>
        <span class="cov8" title="1">if c.MaxMemoryLimit &lt;= c.MinMemoryRequest </span><span class="cov0" title="0">{
                errors = append(errors, "maximum memory limit must be greater than minimum memory request")
        }</span>

        // Validate intervals
        <span class="cov8" title="1">if c.ResizeInterval &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "resize interval must be positive")
        }</span>
        <span class="cov8" title="1">if c.RetryInterval &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "retry interval must be positive")
        }</span>

        // Validate operational settings
        <span class="cov8" title="1">if c.MaxRetries &lt; 0 </span><span class="cov0" title="0">{
                errors = append(errors, "max retries cannot be negative")
        }</span>
        <span class="cov8" title="1">if c.MetricsPort &lt;= 0 || c.MetricsPort &gt; 65535 </span><span class="cov0" title="0">{
                errors = append(errors, "metrics port must be between 1 and 65535")
        }</span>
        <span class="cov8" title="1">if c.SafetyThreshold &lt; 0 || c.SafetyThreshold &gt; 1 </span><span class="cov0" title="0">{
                errors = append(errors, "safety threshold must be between 0 and 1")
        }</span>
        <span class="cov8" title="1">if c.HistoryDays &lt;= 0 </span><span class="cov0" title="0">{
                errors = append(errors, "history days must be positive")
        }</span>

        // Validate log level
        <span class="cov8" title="1">validLevels := map[string]bool{
                "debug": true, "info": true, "warn": true, "error": true,
        }
        if !validLevels[c.LogLevel] </span><span class="cov8" title="1">{
                errors = append(errors, fmt.Sprintf("invalid log level: %s (must be debug, info, warn, or error)", c.LogLevel))
        }</span>

        // Validate metrics provider
        <span class="cov8" title="1">validProviders := map[string]bool{
                "metrics-server": true, "prometheus": true,
        }
        if !validProviders[c.MetricsProvider] </span><span class="cov8" title="1">{
                errors = append(errors, fmt.Sprintf("invalid metrics provider: %s (must be metrics-server or prometheus)", c.MetricsProvider))
        }</span>

        // Validate scaling thresholds
        <span class="cov8" title="1">if c.MemoryScaleUpThreshold &lt;= 0 || c.MemoryScaleUpThreshold &gt; 1 </span><span class="cov8" title="1">{
                errors = append(errors, "memory scale up threshold must be between 0 and 1")
        }</span>
        <span class="cov8" title="1">if c.MemoryScaleDownThreshold &lt;= 0 || c.MemoryScaleDownThreshold &gt; 1 </span><span class="cov8" title="1">{
                errors = append(errors, "memory scale down threshold must be between 0 and 1")
        }</span>
        <span class="cov8" title="1">if c.MemoryScaleDownThreshold &gt;= c.MemoryScaleUpThreshold </span><span class="cov8" title="1">{
                errors = append(errors, "memory scale down threshold must be less than scale up threshold")
        }</span>
        <span class="cov8" title="1">if c.CPUScaleUpThreshold &lt;= 0 || c.CPUScaleUpThreshold &gt; 1 </span><span class="cov8" title="1">{
                errors = append(errors, "CPU scale up threshold must be between 0 and 1")
        }</span>
        <span class="cov8" title="1">if c.CPUScaleDownThreshold &lt;= 0 || c.CPUScaleDownThreshold &gt; 1 </span><span class="cov8" title="1">{
                errors = append(errors, "CPU scale down threshold must be between 0 and 1")
        }</span>
        <span class="cov8" title="1">if c.CPUScaleDownThreshold &gt;= c.CPUScaleUpThreshold </span><span class="cov8" title="1">{
                errors = append(errors, "CPU scale down threshold must be less than scale up threshold")
        }</span>

        <span class="cov8" title="1">if len(errors) &gt; 0 </span><span class="cov8" title="1">{
                return fmt.Errorf("configuration validation errors: %s", strings.Join(errors, "; "))
        }</span>

        <span class="cov8" title="1">return nil</span>
}

// IsNamespaceIncluded checks if a namespace should be processed based on include/exclude filters
func (c *Config) IsNamespaceIncluded(namespace string) bool <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()

        // If include list is specified, namespace must be in it
        if len(c.NamespaceInclude) &gt; 0 </span><span class="cov8" title="1">{
                found := false
                for _, ns := range c.NamespaceInclude </span><span class="cov8" title="1">{
                        if ns == namespace </span><span class="cov8" title="1">{
                                found = true
                                break</span>
                        }
                }
                <span class="cov8" title="1">if !found </span><span class="cov8" title="1">{
                        return false
                }</span>
        }

        // If exclude list is specified, namespace must not be in it
        <span class="cov8" title="1">if len(c.NamespaceExclude) &gt; 0 </span><span class="cov8" title="1">{
                for _, ns := range c.NamespaceExclude </span><span class="cov8" title="1">{
                        if ns == namespace </span><span class="cov8" title="1">{
                                return false
                        }</span>
                }
        }

        <span class="cov8" title="1">return true</span>
}

// GetRetryConfig returns retry configuration for operations
func (c *Config) GetRetryConfig() (maxRetries int, interval time.Duration) <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()
        return c.MaxRetries, c.RetryInterval
}</span>

// IsChangeWithinSafetyThreshold checks if a resource change is within safe limits
func (c *Config) IsChangeWithinSafetyThreshold(current, new int64) bool <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()

        if current == 0 </span><span class="cov8" title="1">{
                return true // No existing resource, any change is allowed
        }</span>

        <span class="cov8" title="1">change := float64(new-current) / float64(current)
        if change &lt; 0 </span><span class="cov8" title="1">{
                change = -change // Use absolute value
        }</span>

        <span class="cov8" title="1">return change &lt;= c.SafetyThreshold</span>
}

// Clone creates a deep copy of the configuration
func (c *Config) Clone() *Config <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()

        clone := &amp;Config{
                CPURequestMultiplier:     c.CPURequestMultiplier,
                MemoryRequestMultiplier:  c.MemoryRequestMultiplier,
                CPURequestAddition:       c.CPURequestAddition,
                MemoryRequestAddition:    c.MemoryRequestAddition,
                CPULimitMultiplier:       c.CPULimitMultiplier,
                MemoryLimitMultiplier:    c.MemoryLimitMultiplier,
                CPULimitAddition:         c.CPULimitAddition,
                MemoryLimitAddition:      c.MemoryLimitAddition,
                MaxCPULimit:              c.MaxCPULimit,
                MaxMemoryLimit:           c.MaxMemoryLimit,
                MinCPURequest:            c.MinCPURequest,
                MinMemoryRequest:         c.MinMemoryRequest,
                ResizeInterval:           c.ResizeInterval,
                LogLevel:                 c.LogLevel,
                MaxRetries:               c.MaxRetries,
                RetryInterval:            c.RetryInterval,
                MetricsEnabled:           c.MetricsEnabled,
                MetricsPort:              c.MetricsPort,
                AuditEnabled:             c.AuditEnabled,
                QPS:                      c.QPS,
                Burst:                    c.Burst,
                MaxConcurrentReconciles:  c.MaxConcurrentReconciles,
                DryRun:                   c.DryRun,
                SafetyThreshold:          c.SafetyThreshold,
                HistoryDays:              c.HistoryDays,
                AdmissionController:      c.AdmissionController,
                MetricsProvider:          c.MetricsProvider,
                PrometheusURL:            c.PrometheusURL,
                MetricsServerEndpoint:    c.MetricsServerEndpoint,
                EnableInPlaceResize:      c.EnableInPlaceResize,
                MemoryScaleUpThreshold:   c.MemoryScaleUpThreshold,
                MemoryScaleDownThreshold: c.MemoryScaleDownThreshold,
                CPUScaleUpThreshold:      c.CPUScaleUpThreshold,
                CPUScaleDownThreshold:    c.CPUScaleDownThreshold,
                ConfigSource:             c.ConfigSource,
        }

        // Deep copy slices
        if len(c.NamespaceInclude) &gt; 0 </span><span class="cov8" title="1">{
                clone.NamespaceInclude = make([]string, len(c.NamespaceInclude))
                copy(clone.NamespaceInclude, c.NamespaceInclude)
        }</span>
        <span class="cov8" title="1">if len(c.NamespaceExclude) &gt; 0 </span><span class="cov8" title="1">{
                clone.NamespaceExclude = make([]string, len(c.NamespaceExclude))
                copy(clone.NamespaceExclude, c.NamespaceExclude)
        }</span>
        <span class="cov8" title="1">if len(c.CustomMetrics) &gt; 0 </span><span class="cov8" title="1">{
                clone.CustomMetrics = make([]string, len(c.CustomMetrics))
                copy(clone.CustomMetrics, c.CustomMetrics)
        }</span>

        // Deep copy notification config
        <span class="cov8" title="1">if c.NotificationConfig != nil </span><span class="cov8" title="1">{
                clone.NotificationConfig = &amp;NotificationConfig{
                        EnableNotifications: c.NotificationConfig.EnableNotifications,
                        SlackWebhookURL:     c.NotificationConfig.SlackWebhookURL,
                        SMTPHost:            c.NotificationConfig.SMTPHost,
                        SMTPPort:            c.NotificationConfig.SMTPPort,
                        SMTPUsername:        c.NotificationConfig.SMTPUsername,
                        SMTPPassword:        c.NotificationConfig.SMTPPassword,
                }
                if len(c.NotificationConfig.EmailRecipients) &gt; 0 </span><span class="cov0" title="0">{
                        clone.NotificationConfig.EmailRecipients = make([]string, len(c.NotificationConfig.EmailRecipients))
                        copy(clone.NotificationConfig.EmailRecipients, c.NotificationConfig.EmailRecipients)
                }</span>
        }

        <span class="cov8" title="1">return clone</span>
}

// GetSafeValue safely retrieves a configuration value with read lock
func (c *Config) GetSafeValue(getter func(*Config) interface{}) interface{} <span class="cov8" title="1">{
        c.mu.RLock()
        defer c.mu.RUnlock()
        return getter(c)
}</span>
</pre>
		
		<pre class="file" id="file6" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package controllers

import (
        "context"
        "encoding/json"
        "fmt"
        "log"
        "strings"
        "sync"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/types"
        "k8s.io/client-go/kubernetes"
        "k8s.io/client-go/rest"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/manager"
)

// ResizeDecisionCache represents a cached resize decision for a pod container
type ResizeDecisionCache struct {
        ContainerKey string // namespace/podname/containername
        OldCPU       string
        NewCPU       string
        OldMemory    string
        NewMemory    string
        LastSeen     time.Time
}

// ScalingDecision represents the scaling action to take
type ScalingDecision int

const (
        ScaleNone ScalingDecision = iota
        ScaleUp
        ScaleDown
)

// ResourceScalingDecision tracks scaling decisions for individual resources
type ResourceScalingDecision struct {
        CPU    ScalingDecision
        Memory ScalingDecision
}

// AdaptiveRightSizer performs resource optimization with support for both
// in-place updates (when available) and deployment updates as fallback
type AdaptiveRightSizer struct {
        Client          client.Client
        ClientSet       *kubernetes.Clientset
        RestConfig      *rest.Config
        MetricsProvider metrics.Provider
        Interval        time.Duration
        InPlaceEnabled  bool       // Will be auto-detected
        DryRun          bool       // If true, only log recommendations without applying
        updateMutex     sync.Mutex // Prevents concurrent update operations
        isRunning       bool       // Tracks if a rightsizing operation is in progress
        runningMutex    sync.Mutex // Protects the isRunning flag
        resizeCache     map[string]*ResizeDecisionCache
        cacheMutex      sync.RWMutex
        cacheExpiry     time.Duration // How long to keep cache entries
}

// ResourceUpdate represents a pending resource update
type ResourceUpdate struct {
        Namespace      string
        Name           string
        ResourceType   string // Pod only now
        ContainerName  string
        ContainerIndex int
        OldResources   corev1.ResourceRequirements
        NewResources   corev1.ResourceRequirements
        Reason         string
}

// shouldLogResizeDecision checks if we should log this resize decision based on cache
func (r *AdaptiveRightSizer) shouldLogResizeDecision(namespace, podName, containerName, oldCPU, newCPU, oldMemory, newMemory string) bool <span class="cov0" title="0">{
        containerKey := fmt.Sprintf("%s/%s/%s", namespace, podName, containerName)

        r.cacheMutex.RLock()
        cached, exists := r.resizeCache[containerKey]
        r.cacheMutex.RUnlock()

        if !exists </span><span class="cov0" title="0">{
                // First time seeing this decision, cache it and allow logging
                r.cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory)
                return true
        }</span>

        // Check if decision has changed or cache has expired
        <span class="cov0" title="0">now := time.Now()
        if now.Sub(cached.LastSeen) &gt; r.cacheExpiry ||
                cached.OldCPU != oldCPU || cached.NewCPU != newCPU ||
                cached.OldMemory != oldMemory || cached.NewMemory != newMemory </span><span class="cov0" title="0">{
                // Decision changed or expired, update cache and allow logging
                r.cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory)
                return true
        }</span>

        // Same decision within cache period, suppress logging
        <span class="cov0" title="0">return false</span>
}

// cacheResizeDecision stores or updates a resize decision in the cache
func (r *AdaptiveRightSizer) cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory string) <span class="cov0" title="0">{
        r.cacheMutex.Lock()
        defer r.cacheMutex.Unlock()

        r.resizeCache[containerKey] = &amp;ResizeDecisionCache{
                ContainerKey: containerKey,
                OldCPU:       oldCPU,
                NewCPU:       newCPU,
                OldMemory:    oldMemory,
                NewMemory:    newMemory,
                LastSeen:     time.Now(),
        }
}</span>

// cleanExpiredCacheEntries removes expired cache entries
func (r *AdaptiveRightSizer) cleanExpiredCacheEntries() <span class="cov0" title="0">{
        r.cacheMutex.Lock()
        defer r.cacheMutex.Unlock()

        now := time.Now()
        for key, cached := range r.resizeCache </span><span class="cov0" title="0">{
                if now.Sub(cached.LastSeen) &gt; r.cacheExpiry </span><span class="cov0" title="0">{
                        delete(r.resizeCache, key)
                }</span>
        }
}

// Start begins the adaptive rightsizing loop
func (r *AdaptiveRightSizer) Start(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(r.Interval)
        defer ticker.Stop()

        // Test for in-place resize capability
        r.InPlaceEnabled = r.testInPlaceCapability(ctx)

        if r.InPlaceEnabled </span><span class="cov0" title="0">{
                logger.Info("✅ In-place pod resizing is available - pods can be resized without restarts")
        }</span> else<span class="cov0" title="0"> {
                logger.Warn("⚠️  In-place pod resizing not available - will use rolling updates")
        }</span>

        <span class="cov0" title="0">logger.Info("Starting adaptive right-sizer with %v interval (DryRun: %v)", r.Interval, r.DryRun)

        // Run immediately on start
        r.performRightSizing(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        r.performRightSizing(ctx)
                        // Clean expired cache entries periodically
                        r.cleanExpiredCacheEntries()</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        log.Println("Stopping adaptive right-sizer")
                        return nil</span>
                }
        }
}

// testInPlaceCapability checks if in-place resize is supported
func (r *AdaptiveRightSizer) testInPlaceCapability(ctx context.Context) bool <span class="cov0" title="0">{
        // Check if the resize subresource is available by checking server version
        // In-place pod resize is available in Kubernetes 1.27+ (alpha), 1.29+ (beta), 1.31+ (stable)

        if r.ClientSet == nil </span><span class="cov0" title="0">{
                logger.Warn("ClientSet not available, cannot test for in-place resize capability")
                return false
        }</span>

        // Get server version
        <span class="cov0" title="0">serverVersion, err := r.ClientSet.Discovery().ServerVersion()
        if err != nil </span><span class="cov0" title="0">{
                logger.Warn("Failed to get server version: %v", err)
                return false
        }</span>

        // Parse the version
        <span class="cov0" title="0">major := serverVersion.Major
        minor := serverVersion.Minor

        // Remove any non-numeric suffix from minor version (e.g., "33+" -&gt; "33")
        minorNum := 0
        fmt.Sscanf(minor, "%d", &amp;minorNum)

        // Check if version supports in-place resize (K8s 1.27+)
        if major == "1" &amp;&amp; minorNum &gt;= 27 </span><span class="cov0" title="0">{
                logger.Info("Kubernetes version %s.%s supports in-place pod resizing", major, minor)

                // Additional check: try to access the resize subresource
                // This confirms the feature is actually available
                _, err := r.ClientSet.CoreV1().RESTClient().Get().
                        Resource("pods").
                        SubResource("resize").
                        DoRaw(ctx)

                // We expect an error here (no pod specified), but if the subresource
                // doesn't exist, we'll get a different error
                if err != nil &amp;&amp; strings.Contains(err.Error(), "not found") &amp;&amp;
                        strings.Contains(err.Error(), "resize") </span><span class="cov0" title="0">{
                        logger.Warn("Resize subresource not found despite version support")
                        return false
                }</span>

                <span class="cov0" title="0">return true</span>
        }

        <span class="cov0" title="0">logger.Info("Kubernetes version %s.%s does not support in-place pod resizing (requires 1.27+)", major, minor)
        return false</span>
}

// performRightSizing processes all pods for optimization using in-place resize
func (r *AdaptiveRightSizer) performRightSizing(ctx context.Context) <span class="cov0" title="0">{
        startTime := time.Now()

        // Check if a rightsizing operation is already in progress
        r.runningMutex.Lock()
        if r.isRunning </span><span class="cov0" title="0">{
                r.runningMutex.Unlock()
                log.Printf("⏭️  Skipping rightsizing run - previous run still in progress")
                return
        }</span>
        <span class="cov0" title="0">r.isRunning = true
        r.runningMutex.Unlock()

        // Ensure we clear the running flag when done
        defer func() </span><span class="cov0" title="0">{
                r.runningMutex.Lock()
                r.isRunning = false
                r.runningMutex.Unlock()

                // Log summary of the rightsizing run
                duration := time.Since(startTime)
                log.Printf("✅ Rightsizing run completed in %v", duration)
                if duration &gt; r.Interval </span><span class="cov0" title="0">{
                        log.Printf("⚠️  WARNING: Run took longer (%v) than the configured interval (%v)", duration, r.Interval)
                }</span>
        }()

        <span class="cov0" title="0">updates := []ResourceUpdate{}

        // Analyze ALL pods directly (including those from deployments, statefulsets, etc)
        // We will update pods directly using in-place resize, not their controllers
        pods, err := r.analyzeAllPods(ctx)
        if err != nil </span><span class="cov0" title="0">{
                log.Printf("Error analyzing pods: %v", err)
        }</span> else<span class="cov0" title="0"> {
                updates = append(updates, pods...)
        }</span>

        // Apply updates using in-place resize
        <span class="cov0" title="0">r.applyUpdates(ctx, updates)</span>
}

// analyzeAllPods analyzes all pods in the cluster for resource optimization
func (r *AdaptiveRightSizer) analyzeAllPods(ctx context.Context) ([]ResourceUpdate, error) <span class="cov0" title="0">{
        var podList corev1.PodList
        if err := r.Client.List(ctx, &amp;podList); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">updates := []ResourceUpdate{}

        // Limit the number of pods to process in a single cycle to prevent overload
        const maxPodsPerCycle = 50
        podsProcessed := 0

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                // Limit pods processed per cycle
                if podsProcessed &gt;= maxPodsPerCycle </span><span class="cov0" title="0">{
                        log.Printf("📊 Reached maximum pods per cycle (%d), will process remaining pods in next cycle", maxPodsPerCycle)
                        break</span>
                }
                // Skip pods that are not running
                <span class="cov0" title="0">if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Check namespace filters first
                <span class="cov0" title="0">if !r.shouldProcessNamespace(pod.Namespace) </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">if r.isSystemWorkload(pod.Namespace, pod.Name) </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Skip pods with skip annotation
                <span class="cov0" title="0">if pod.Annotations != nil </span><span class="cov0" title="0">{
                        if skip, ok := pod.Annotations["rightsizer.io/skip"]; ok &amp;&amp; skip == "true" </span><span class="cov0" title="0">{
                                continue</span>
                        }
                }

                // Get metrics for this specific pod
                <span class="cov0" title="0">podMetrics, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        log.Printf("Failed to get metrics for pod %s/%s: %v", pod.Namespace, pod.Name, err)
                        continue</span>
                }

                // Check each container in the pod
                <span class="cov0" title="0">for i, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                        // Check scaling thresholds first
                        scalingDecision := r.checkScalingThresholds(podMetrics, container.Resources)

                        // Skip if CPU should not be updated but memory should be reduced
                        if scalingDecision.CPU == ScaleNone &amp;&amp; scalingDecision.Memory == ScaleDown </span><span class="cov0" title="0">{
                                logger.Info("⏭️  Skipping resize for pod %s/%s container %s: CPU doesn't need update and memory would be reduced",
                                        pod.Namespace, pod.Name, container.Name)
                                continue</span>
                        }

                        // Skip if both resources don't need changes
                        <span class="cov0" title="0">if scalingDecision.CPU == ScaleNone &amp;&amp; scalingDecision.Memory == ScaleNone </span><span class="cov0" title="0">{
                                continue</span>
                        }

                        // Calculate optimal resources based on actual usage and scaling decision
                        // Note: metrics-server provides pod-level metrics, not per-container
                        // So we'll use the pod metrics for all containers
                        <span class="cov0" title="0">newResources := r.calculateOptimalResourcesWithDecision(podMetrics, scalingDecision)

                        if r.needsAdjustmentWithDecision(container.Resources, newResources, scalingDecision) </span><span class="cov0" title="0">{
                                // Log the actual resource changes that will be made
                                oldCPUReq := container.Resources.Requests[corev1.ResourceCPU]
                                oldMemReq := container.Resources.Requests[corev1.ResourceMemory]
                                newCPUReq := newResources.Requests[corev1.ResourceCPU]
                                newMemReq := newResources.Requests[corev1.ResourceMemory]

                                // Get current usage for detailed logging
                                cpuLimit := container.Resources.Limits.Cpu().AsApproximateFloat64() * 1000
                                memLimit := float64(container.Resources.Limits.Memory().Value()) / (1024 * 1024)
                                cpuUsagePercent := 0.0
                                memUsagePercent := 0.0
                                if cpuLimit &gt; 0 </span><span class="cov0" title="0">{
                                        cpuUsagePercent = (podMetrics.CPUMilli / cpuLimit) * 100
                                }</span>
                                <span class="cov0" title="0">if memLimit &gt; 0 </span><span class="cov0" title="0">{
                                        memUsagePercent = (podMetrics.MemMB / memLimit) * 100
                                }</span>

                                // Check cache before logging to prevent repetitive messages
                                <span class="cov0" title="0">if r.shouldLogResizeDecision(pod.Namespace, pod.Name, container.Name,
                                        oldCPUReq.String(), newCPUReq.String(), oldMemReq.String(), newMemReq.String()) </span><span class="cov0" title="0">{

                                        logger.Info("🔍 Scaling analysis - CPU: %s (usage: %.0fm/%.0fm, %.1f%%), Memory: %s (usage: %.0fMi/%.0fMi, %.1f%%)",
                                                scalingDecisionString(scalingDecision.CPU), podMetrics.CPUMilli, cpuLimit, cpuUsagePercent,
                                                scalingDecisionString(scalingDecision.Memory), podMetrics.MemMB, memLimit, memUsagePercent)
                                        logger.Info("📈 Container %s/%s/%s will be resized - CPU: %s→%s, Memory: %s→%s",
                                                pod.Namespace, pod.Name, container.Name,
                                                oldCPUReq.String(), newCPUReq.String(),
                                                oldMemReq.String(), newMemReq.String())
                                }</span>
                                <span class="cov0" title="0">updates = append(updates, ResourceUpdate{
                                        Namespace:      pod.Namespace,
                                        Name:           pod.Name,
                                        ResourceType:   "Pod",
                                        ContainerName:  container.Name,
                                        ContainerIndex: i,
                                        OldResources:   container.Resources,
                                        NewResources:   newResources,
                                        Reason:         r.getAdjustmentReasonWithDecision(container.Resources, newResources, scalingDecision),
                                })</span>
                        }
                }

                <span class="cov0" title="0">podsProcessed++</span>
        }

        <span class="cov0" title="0">return updates, nil</span>
}

// analyzeStandalonePods analyzes standalone pods (deprecated - all pods are now analyzed)
func (r *AdaptiveRightSizer) analyzeStandalonePods(ctx context.Context) ([]ResourceUpdate, error) <span class="cov0" title="0">{
        // This function is deprecated as we now analyze all pods in analyzeAllPods
        return []ResourceUpdate{}, nil

}</span>

// applyUpdates applies the calculated resource updates with batching and rate limiting
func (r *AdaptiveRightSizer) applyUpdates(ctx context.Context, updates []ResourceUpdate) <span class="cov0" title="0">{
        if len(updates) == 0 </span><span class="cov0" title="0">{
                return
        }</span>

        // Only log if there are actual updates to apply
        <span class="cov0" title="0">if len(updates) &gt; 0 </span><span class="cov0" title="0">{
                log.Printf("📊 Found %d resources needing adjustment", len(updates))
        }</span>

        // Protect API server from too many updates at once
        <span class="cov0" title="0">const maxUpdatesPerRun = 50 // Maximum updates to process in a single run
        if len(updates) &gt; maxUpdatesPerRun </span><span class="cov0" title="0">{
                log.Printf("⚠️  Too many updates pending (%d &gt; %d). Processing first %d to protect API server",
                        len(updates), maxUpdatesPerRun, maxUpdatesPerRun)
                log.Printf("   Remaining updates will be processed in the next run")
                updates = updates[:maxUpdatesPerRun]
        }</span>

        // Configuration for batching to prevent API server overload
        <span class="cov0" title="0">cfg := config.Get()
        batchSize := cfg.BatchSize
        delayBetweenBatches := cfg.DelayBetweenBatches
        delayBetweenPods := cfg.DelayBetweenPods

        // Use defaults if not configured
        if batchSize &lt;= 0 </span><span class="cov0" title="0">{
                batchSize = 3
        }</span>
        <span class="cov0" title="0">if delayBetweenBatches &lt;= 0 </span><span class="cov0" title="0">{
                delayBetweenBatches = 5 * time.Second
        }</span>
        <span class="cov0" title="0">if delayBetweenPods &lt;= 0 </span><span class="cov0" title="0">{
                delayBetweenPods = 500 * time.Millisecond
        }</span>

        // Log all updates first if in dry-run mode
        <span class="cov0" title="0">if r.DryRun </span><span class="cov0" title="0">{
                for _, update := range updates </span><span class="cov0" title="0">{
                        r.logUpdate(update, true)
                }</span>
                <span class="cov0" title="0">return</span>
        }

        // Log all updates that will be applied
        <span class="cov0" title="0">for _, update := range updates </span><span class="cov0" title="0">{
                r.logUpdate(update, false)
        }</span>

        // Apply pod updates in batches with rate limiting
        <span class="cov0" title="0">podUpdates := []ResourceUpdate{}
        for _, update := range updates </span><span class="cov0" title="0">{
                if update.ResourceType == "Pod" </span><span class="cov0" title="0">{
                        podUpdates = append(podUpdates, update)
                }</span>
        }

        <span class="cov0" title="0">if len(podUpdates) == 0 </span><span class="cov0" title="0">{
                return
        }</span>

        // Process updates in batches
        <span class="cov0" title="0">totalBatches := (len(podUpdates) + batchSize - 1) / batchSize
        // Only log batch info if we have actual updates
        if !r.DryRun </span><span class="cov0" title="0">{
                log.Printf("🔄 Processing %d pod updates in %d batches (batch size: %d)",
                        len(podUpdates), totalBatches, batchSize)
        }</span>

        <span class="cov0" title="0">for i := 0; i &lt; len(podUpdates); i += batchSize </span><span class="cov0" title="0">{
                // Calculate batch boundaries
                end := i + batchSize
                if end &gt; len(podUpdates) </span><span class="cov0" title="0">{
                        end = len(podUpdates)
                }</span>

                <span class="cov0" title="0">batchNum := (i / batchSize) + 1
                batch := podUpdates[i:end]

                // Only log batch progress for actual updates
                if !r.DryRun &amp;&amp; len(batch) &gt; 0 </span><span class="cov0" title="0">{
                        log.Printf("📦 Processing batch %d/%d (%d pods)", batchNum, totalBatches, len(batch))
                }</span>

                // Process pods in current batch
                <span class="cov0" title="0">for j, update := range batch </span><span class="cov0" title="0">{
                        // Check context cancellation
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                log.Printf("⚠️  Context cancelled, stopping pod updates")
                                return</span>
                        default:<span class="cov0" title="0"></span>
                        }

                        <span class="cov0" title="0">actualChanges, err := r.updatePodInPlace(ctx, update)
                        if err != nil </span><span class="cov0" title="0">{
                                log.Printf("❌ Error updating pod %s/%s: %v", update.Namespace, update.Name, err)
                        }</span> else<span class="cov0" title="0"> if actualChanges != "" &amp;&amp; !strings.Contains(actualChanges, "Skipped") &amp;&amp; !strings.Contains(actualChanges, "already at target") </span><span class="cov0" title="0">{
                                log.Printf("✅ %s", actualChanges)
                        }</span>

                        // Add small delay between pods within a batch to avoid rapid-fire API calls
                        <span class="cov0" title="0">if j &lt; len(batch)-1 </span><span class="cov0" title="0">{
                                time.Sleep(delayBetweenPods)
                        }</span>
                }

                // Add delay between batches (except after the last batch)
                <span class="cov0" title="0">if i+batchSize &lt; len(podUpdates) </span><span class="cov0" title="0">{
                        log.Printf("⏳ Waiting %v before next batch to avoid API server overload", delayBetweenBatches)
                        time.Sleep(delayBetweenBatches)
                }</span>
        }

        // Only log completion if we actually did something
        <span class="cov0" title="0">successCount := 0
        for range podUpdates </span><span class="cov0" title="0">{
                // Count only successful updates (this is a simplification, would need tracking)
                successCount++
        }</span>
        <span class="cov0" title="0">if successCount &gt; 0 &amp;&amp; !r.DryRun </span><span class="cov0" title="0">{
                log.Printf("✅ Completed processing pod updates")
        }</span>
}

// updatePodInPlace attempts to update pod resources in-place with mutex protection
// Returns a description of what was actually changed
func (r *AdaptiveRightSizer) updatePodInPlace(ctx context.Context, update ResourceUpdate) (string, error) <span class="cov0" title="0">{
        // Use mutex to prevent concurrent API calls that could overwhelm the server
        r.updateMutex.Lock()
        defer r.updateMutex.Unlock()

        // Get the current pod
        var pod corev1.Pod
        if err := r.Client.Get(ctx, types.NamespacedName{
                Namespace: update.Namespace,
                Name:      update.Name,
        }, &amp;pod); err != nil </span><span class="cov0" title="0">{
                return "", err
        }</span>

        // Find the container index and check current resources
        <span class="cov0" title="0">var currentResources *corev1.ResourceRequirements
        containerIndex := -1
        for i, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                if container.Name == update.ContainerName </span><span class="cov0" title="0">{
                        currentResources = &amp;container.Resources
                        containerIndex = i
                        break</span>
                }
        }

        <span class="cov0" title="0">if currentResources == nil || containerIndex == -1 </span><span class="cov0" title="0">{
                return "", fmt.Errorf("container %s not found in pod", update.ContainerName)
        }</span>

        // Check the current QoS class
        <span class="cov0" title="0">cfg := config.Get()
        currentQoS := getQoSClass(&amp;pod)
        isGuaranteed := currentQoS == corev1.PodQOSGuaranteed

        // If pod is Guaranteed and config says to preserve it, ensure we maintain the QoS class
        if isGuaranteed &amp;&amp; cfg.PreserveGuaranteedQoS </span><span class="cov0" title="0">{
                // For Guaranteed pods, requests must equal limits
                update.NewResources.Limits = make(corev1.ResourceList)
                for k, v := range update.NewResources.Requests </span><span class="cov0" title="0">{
                        update.NewResources.Limits[k] = v.DeepCopy()
                }</span>
                // Only log QoS maintenance if we're actually making changes
                <span class="cov0" title="0">if len(update.NewResources.Requests) &gt; 0 </span><span class="cov0" title="0">{
                        log.Printf("🔒 Maintaining Guaranteed QoS for pod %s/%s (requests = limits)", update.Namespace, update.Name)
                }</span>
        } else<span class="cov0" title="0"> if isGuaranteed &amp;&amp; !cfg.PreserveGuaranteedQoS &amp;&amp; cfg.QoSTransitionWarning </span><span class="cov0" title="0">{
                // Warn if QoS class will change
                log.Printf("⚠️  QoS class for pod %s/%s may change from Guaranteed", update.Namespace, update.Name)
        }</span>

        // Check if memory limit is being decreased (not allowed for in-place resize)
        <span class="cov0" title="0">currentMemLimit := currentResources.Limits.Memory()
        newMemLimit := update.NewResources.Limits.Memory()
        currentMemRequest := currentResources.Requests.Memory()
        newMemRequest := update.NewResources.Requests.Memory()

        memoryLimitDecreased := currentMemLimit != nil &amp;&amp; newMemLimit != nil &amp;&amp; currentMemLimit.Cmp(*newMemLimit) &gt; 0
        memoryRequestDecreased := currentMemRequest != nil &amp;&amp; newMemRequest != nil &amp;&amp; currentMemRequest.Cmp(*newMemRequest) &gt; 0

        cpuOnly := false
        if memoryLimitDecreased || memoryRequestDecreased </span><span class="cov0" title="0">{
                // Check if CPU is actually changing by comparing current pod resources with desired
                currentCPURequest := currentResources.Requests.Cpu()
                newCPURequest := update.NewResources.Requests.Cpu()
                currentCPULimit := currentResources.Limits.Cpu()
                newCPULimit := update.NewResources.Limits.Cpu()

                cpuRequestChanging := false
                if currentCPURequest != nil &amp;&amp; newCPURequest != nil </span><span class="cov0" title="0">{
                        cpuRequestChanging = currentCPURequest.Cmp(*newCPURequest) != 0
                }</span> else<span class="cov0" title="0"> if (currentCPURequest == nil) != (newCPURequest == nil) </span><span class="cov0" title="0">{
                        cpuRequestChanging = true
                }</span>

                <span class="cov0" title="0">cpuLimitChanging := false
                if currentCPULimit != nil &amp;&amp; newCPULimit != nil </span><span class="cov0" title="0">{
                        cpuLimitChanging = currentCPULimit.Cmp(*newCPULimit) != 0
                }</span> else<span class="cov0" title="0"> if (currentCPULimit == nil) != (newCPULimit == nil) </span><span class="cov0" title="0">{
                        cpuLimitChanging = true
                }</span>

                <span class="cov0" title="0">if !cpuRequestChanging &amp;&amp; !cpuLimitChanging </span><span class="cov0" title="0">{
                        // Neither CPU nor memory can be changed - skip this update entirely
                        return "", nil // Return empty string to suppress logging
                }</span>

                // Memory is being decreased - keep current memory values but update CPU
                <span class="cov0" title="0">log.Printf("⚠️  Cannot decrease memory for pod %s/%s", update.Namespace, update.Name)
                if memoryLimitDecreased </span><span class="cov0" title="0">{
                        log.Printf("   Memory limit: current=%s, desired=%s (decrease not allowed)", currentMemLimit.String(), newMemLimit.String())
                }</span>
                <span class="cov0" title="0">if memoryRequestDecreased </span><span class="cov0" title="0">{
                        log.Printf("   Memory request: current=%s, desired=%s (decrease not allowed)", currentMemRequest.String(), newMemRequest.String())
                }</span>
                <span class="cov0" title="0">log.Printf("   💡 Applying CPU changes only (memory decreases require pod restart)")

                // Keep current memory values, but use new CPU values
                if currentMemLimit != nil </span><span class="cov0" title="0">{
                        update.NewResources.Limits[corev1.ResourceMemory] = currentMemLimit.DeepCopy()
                }</span>
                <span class="cov0" title="0">if currentMemRequest != nil </span><span class="cov0" title="0">{
                        update.NewResources.Requests[corev1.ResourceMemory] = currentMemRequest.DeepCopy()
                }</span>

                // If Guaranteed and preserving QoS, ensure requests still equal limits for memory
                <span class="cov0" title="0">if isGuaranteed &amp;&amp; cfg.PreserveGuaranteedQoS &amp;&amp; currentMemLimit != nil </span><span class="cov0" title="0">{
                        update.NewResources.Requests[corev1.ResourceMemory] = currentMemLimit.DeepCopy()
                }</span>

                <span class="cov0" title="0">cpuOnly = true</span>
        }

        // Before creating the patch, do a final check if anything is actually changing
        <span class="cov0" title="0">actuallyChanging := false

        // Check requests
        if update.NewResources.Requests != nil </span><span class="cov0" title="0">{
                for resName, newVal := range update.NewResources.Requests </span><span class="cov0" title="0">{
                        if currentVal, exists := currentResources.Requests[resName]; exists </span><span class="cov0" title="0">{
                                if !currentVal.Equal(newVal) </span><span class="cov0" title="0">{
                                        actuallyChanging = true
                                        break</span>
                                }
                        } else<span class="cov0" title="0"> {
                                actuallyChanging = true
                                break</span>
                        }
                }
        }

        // Check limits if we haven't found a change yet
        <span class="cov0" title="0">if !actuallyChanging &amp;&amp; update.NewResources.Limits != nil </span><span class="cov0" title="0">{
                for resName, newVal := range update.NewResources.Limits </span><span class="cov0" title="0">{
                        if currentVal, exists := currentResources.Limits[resName]; exists </span><span class="cov0" title="0">{
                                if !currentVal.Equal(newVal) </span><span class="cov0" title="0">{
                                        actuallyChanging = true
                                        break</span>
                                }
                        } else<span class="cov0" title="0"> {
                                actuallyChanging = true
                                break</span>
                        }
                }
        }

        // If nothing is actually changing, skip the update
        <span class="cov0" title="0">if !actuallyChanging </span><span class="cov0" title="0">{
                return "", nil // Return empty string to suppress logging
        }</span>

        // Create JSON patch for the resize operation
        // Using JSON patch is more reliable for resize subresource
        <span class="cov0" title="0">type JSONPatchOp struct {
                Op    string      `json:"op"`
                Path  string      `json:"path"`
                Value interface{} `json:"value"`
        }

        var patchOps []JSONPatchOp

        // Ensure safe resource patch - never try to remove existing resources
        safeResources := ensureSafeResourcePatchAdaptive(*currentResources, update.NewResources)

        // Patch requests only if they exist and are different
        if safeResources.Requests != nil &amp;&amp; len(safeResources.Requests) &gt; 0 </span><span class="cov0" title="0">{
                patchOps = append(patchOps, JSONPatchOp{
                        Op:    "replace",
                        Path:  fmt.Sprintf("/spec/containers/%d/resources/requests", containerIndex),
                        Value: safeResources.Requests,
                })
        }</span>

        // Patch limits only if they exist and are different
        <span class="cov0" title="0">if safeResources.Limits != nil &amp;&amp; len(safeResources.Limits) &gt; 0 </span><span class="cov0" title="0">{
                patchOps = append(patchOps, JSONPatchOp{
                        Op:    "replace",
                        Path:  fmt.Sprintf("/spec/containers/%d/resources/limits", containerIndex),
                        Value: safeResources.Limits,
                })
        }</span>

        // Marshal the patch
        <span class="cov0" title="0">patchData, err := json.Marshal(patchOps)
        if err != nil </span><span class="cov0" title="0">{
                return "", fmt.Errorf("failed to marshal resize patch: %w", err)
        }</span>

        // Use the Kubernetes client-go to patch with the resize subresource
        // Using JSONPatch type for more precise control
        <span class="cov0" title="0">_, err = r.ClientSet.CoreV1().Pods(update.Namespace).Patch(
                ctx,
                update.Name,
                types.JSONPatchType,
                patchData,
                metav1.PatchOptions{},
                "resize", // This is the crucial part - specifying the resize subresource
        )

        if err != nil </span><span class="cov0" title="0">{
                // Check for specific memory decrease error
                if strings.Contains(err.Error(), "memory limits cannot be decreased") ||
                        strings.Contains(err.Error(), "Forbidden: pod updates may not change fields") ||
                        strings.Contains(err.Error(), "resize is not supported") </span><span class="cov0" title="0">{
                        log.Printf("⚠️  Cannot resize pod %s/%s: %v", update.Namespace, update.Name, err)
                        log.Printf("   💡 Pod may need RestartPolicy or in-place resize may not be supported")
                        // Return empty string to not count this as an error
                        return "Skipped resize (not supported or forbidden)", nil
                }</span>
                <span class="cov0" title="0">return "", fmt.Errorf("failed to resize pod: %w", err)</span>
        }

        // Build success message based on what was actually changed
        <span class="cov0" title="0">var successMsg string
        if cpuOnly </span><span class="cov0" title="0">{
                newCpuReq := update.NewResources.Requests[corev1.ResourceCPU]
                currentCpuReq := currentResources.Requests[corev1.ResourceCPU]
                successMsg = fmt.Sprintf("Successfully resized pod %s/%s (CPU only: %s→%s, memory decrease skipped)",
                        update.Namespace, update.Name, currentCpuReq.String(), newCpuReq.String())
        }</span> else<span class="cov0" title="0"> {
                newCpuReq := update.NewResources.Requests[corev1.ResourceCPU]
                newMemReq := update.NewResources.Requests[corev1.ResourceMemory]
                currentCpuReq := currentResources.Requests[corev1.ResourceCPU]
                currentMemReq := currentResources.Requests[corev1.ResourceMemory]
                successMsg = fmt.Sprintf("Successfully resized pod %s/%s (CPU: %s→%s, Memory: %s→%s)",
                        update.Namespace, update.Name, currentCpuReq.String(), newCpuReq.String(), currentMemReq.String(), newMemReq.String())
        }</span>

        <span class="cov0" title="0">return successMsg, nil</span>
}

// Helper functions

func (r *AdaptiveRightSizer) getPodsForWorkload(ctx context.Context, namespace string, labels map[string]string) ([]corev1.Pod, error) <span class="cov0" title="0">{
        var podList corev1.PodList
        if err := r.Client.List(ctx, &amp;podList,
                client.InNamespace(namespace),
                client.MatchingLabels(labels)); err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">runningPods := []corev1.Pod{}
        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase == corev1.PodRunning </span><span class="cov0" title="0">{
                        runningPods = append(runningPods, pod)
                }</span>
        }
        <span class="cov0" title="0">return runningPods, nil</span>
}

func (r *AdaptiveRightSizer) calculateAverageMetrics(pods []corev1.Pod) *metrics.Metrics <span class="cov0" title="0">{
        if len(pods) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">totalCPU := 0.0
        totalMem := 0.0
        validPods := 0

        for _, pod := range pods </span><span class="cov0" title="0">{
                m, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }
                <span class="cov0" title="0">totalCPU += m.CPUMilli
                totalMem += m.MemMB
                validPods++</span>
        }

        <span class="cov0" title="0">if validPods == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">return &amp;metrics.Metrics{
                CPUMilli: totalCPU / float64(validPods),
                MemMB:    totalMem / float64(validPods),
        }</span>
}

func (r *AdaptiveRightSizer) calculateOptimalResources(usage metrics.Metrics) corev1.ResourceRequirements <span class="cov0" title="0">{
        cfg := config.Get()

        // Add buffer for requests using configurable multipliers and additions
        cpuRequest := int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        memRequest := int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition

        // Ensure minimum values
        if cpuRequest &lt; cfg.MinCPURequest </span><span class="cov0" title="0">{
                cpuRequest = cfg.MinCPURequest
        }</span>
        <span class="cov0" title="0">if memRequest &lt; cfg.MinMemoryRequest </span><span class="cov0" title="0">{
                memRequest = cfg.MinMemoryRequest
        }</span>

        // Calculate limits based on requests with multipliers and additions
        <span class="cov0" title="0">cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        // Apply maximum caps
        if cpuLimit &gt; cfg.MaxCPULimit </span><span class="cov0" title="0">{
                cpuLimit = cfg.MaxCPULimit
        }</span>
        <span class="cov0" title="0">if memLimit &gt; cfg.MaxMemoryLimit </span><span class="cov0" title="0">{
                memLimit = cfg.MaxMemoryLimit
        }</span>

        <span class="cov0" title="0">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// checkScalingThresholds determines if scaling is needed based on resource usage thresholds
func (r *AdaptiveRightSizer) checkScalingThresholds(usage metrics.Metrics, current corev1.ResourceRequirements) ResourceScalingDecision <span class="cov0" title="0">{
        cfg := config.Get()

        // Get current limits (or requests if limits not set)
        var cpuLimit, memLimit float64

        if limit, exists := current.Limits[corev1.ResourceCPU]; exists &amp;&amp; !limit.IsZero() </span><span class="cov0" title="0">{
                cpuLimit = float64(limit.MilliValue())
        }</span> else<span class="cov0" title="0"> if req, exists := current.Requests[corev1.ResourceCPU]; exists &amp;&amp; !req.IsZero() </span><span class="cov0" title="0">{
                cpuLimit = float64(req.MilliValue())
        }</span>

        <span class="cov0" title="0">if limit, exists := current.Limits[corev1.ResourceMemory]; exists &amp;&amp; !limit.IsZero() </span><span class="cov0" title="0">{
                memLimit = float64(limit.Value()) / (1024 * 1024) // Convert to MB
        }</span> else<span class="cov0" title="0"> if req, exists := current.Requests[corev1.ResourceMemory]; exists &amp;&amp; !req.IsZero() </span><span class="cov0" title="0">{
                memLimit = float64(req.Value()) / (1024 * 1024)
        }</span>

        // If no resources set, default to scale up
        <span class="cov0" title="0">if cpuLimit == 0 &amp;&amp; memLimit == 0 </span><span class="cov0" title="0">{
                return ResourceScalingDecision{CPU: ScaleUp, Memory: ScaleUp}
        }</span>

        // Calculate usage percentages
        <span class="cov0" title="0">cpuUsagePercent := float64(0)
        memUsagePercent := float64(0)

        if cpuLimit &gt; 0 </span><span class="cov0" title="0">{
                cpuUsagePercent = usage.CPUMilli / cpuLimit
        }</span>
        <span class="cov0" title="0">if memLimit &gt; 0 </span><span class="cov0" title="0">{
                memUsagePercent = usage.MemMB / memLimit
        }</span>

        // Determine scaling decision for each resource independently
        <span class="cov0" title="0">cpuDecision := ScaleNone
        memoryDecision := ScaleNone

        // Check CPU scaling
        if cpuUsagePercent &gt; cfg.CPUScaleUpThreshold </span><span class="cov0" title="0">{
                cpuDecision = ScaleUp
        }</span> else<span class="cov0" title="0"> if cpuUsagePercent &lt; cfg.CPUScaleDownThreshold </span><span class="cov0" title="0">{
                cpuDecision = ScaleDown
        }</span>

        // Check Memory scaling
        <span class="cov0" title="0">if memUsagePercent &gt; cfg.MemoryScaleUpThreshold </span><span class="cov0" title="0">{
                memoryDecision = ScaleUp
        }</span> else<span class="cov0" title="0"> if memUsagePercent &lt; cfg.MemoryScaleDownThreshold </span><span class="cov0" title="0">{
                memoryDecision = ScaleDown
        }</span>

        // Don't log here to avoid duplication - logging happens in analyzeAllPods when resize is actually needed

        <span class="cov0" title="0">return ResourceScalingDecision{CPU: cpuDecision, Memory: memoryDecision}</span>
}

// Helper function to convert ScalingDecision to string
func scalingDecisionString(d ScalingDecision) string <span class="cov0" title="0">{
        switch d </span>{
        case ScaleUp:<span class="cov0" title="0">
                return "scale up"</span>
        case ScaleDown:<span class="cov0" title="0">
                return "scale down"</span>
        default:<span class="cov0" title="0">
                return "no change"</span>
        }
}

// calculateOptimalResourcesWithDecision calculates resources based on scaling decision
func (r *AdaptiveRightSizer) calculateOptimalResourcesWithDecision(usage metrics.Metrics, decision ResourceScalingDecision) corev1.ResourceRequirements <span class="cov0" title="0">{
        cfg := config.Get()

        var cpuRequest, memRequest int64

        // CPU calculation based on decision
        if decision.CPU == ScaleUp </span><span class="cov0" title="0">{
                cpuRequest = int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        }</span> else<span class="cov0" title="0"> if decision.CPU == ScaleDown </span><span class="cov0" title="0">{
                cpuRequest = int64(usage.CPUMilli*1.1) + cfg.CPURequestAddition // Use reduced multiplier
        }</span> else<span class="cov0" title="0"> {
                cpuRequest = int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        }</span>

        // Memory calculation based on decision
        <span class="cov0" title="0">if decision.Memory == ScaleUp </span><span class="cov0" title="0">{
                memRequest = int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition
        }</span> else<span class="cov0" title="0"> if decision.Memory == ScaleDown </span><span class="cov0" title="0">{
                memRequest = int64(usage.MemMB*1.1) + cfg.MemoryRequestAddition // Use reduced multiplier
        }</span> else<span class="cov0" title="0"> {
                memRequest = int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition
        }</span>

        // Ensure minimum values
        <span class="cov0" title="0">if cpuRequest &lt; cfg.MinCPURequest </span><span class="cov0" title="0">{
                cpuRequest = cfg.MinCPURequest
        }</span>
        <span class="cov0" title="0">if memRequest &lt; cfg.MinMemoryRequest </span><span class="cov0" title="0">{
                memRequest = cfg.MinMemoryRequest // Already in MB
        }</span>

        // Calculate limits
        <span class="cov0" title="0">cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        // Apply maximum caps
        if cpuLimit &gt; cfg.MaxCPULimit </span><span class="cov0" title="0">{
                cpuLimit = cfg.MaxCPULimit
        }</span>
        <span class="cov0" title="0">if memLimit &gt; cfg.MaxMemoryLimit </span><span class="cov0" title="0">{ // MaxMemoryLimit is already in MB
                memLimit = cfg.MaxMemoryLimit
        }</span>

        // Ensure memory limit is never 0 or less than request
        <span class="cov0" title="0">if memLimit &lt;= 0 </span><span class="cov0" title="0">{
                memLimit = memRequest * 2 // Default to 2x the request if limit calculation fails
        }</span>
        <span class="cov0" title="0">if memLimit &lt; memRequest </span><span class="cov0" title="0">{
                memLimit = memRequest // Limit should never be less than request
        }</span>
        <span class="cov0" title="0">if memLimit &lt;= 0 </span><span class="cov0" title="0">{
                memLimit = 256 // Fallback to 256MB if still 0
        }</span>

        // Ensure CPU limit is never less than request
        <span class="cov0" title="0">if cpuLimit &lt; cpuRequest </span><span class="cov0" title="0">{
                cpuLimit = cpuRequest
        }</span>

        // Check if we should maintain Guaranteed QoS based on config and multiplier settings
        // This is a common pattern for workloads that need predictable performance
        <span class="cov0" title="0">maintainGuaranteed := cfg.PreserveGuaranteedQoS &amp;&amp;
                (cfg.CPULimitMultiplier == 1.0 &amp;&amp; cfg.CPULimitAddition == 0 &amp;&amp;
                        cfg.MemoryLimitMultiplier == 1.0 &amp;&amp; cfg.MemoryLimitAddition == 0)

        // Also maintain Guaranteed if explicitly configured for critical workloads
        if cfg.ForceGuaranteedForCritical || maintainGuaranteed </span><span class="cov0" title="0">{
                // For Guaranteed QoS, requests must equal limits
                cpuLimit = cpuRequest
                memLimit = memRequest
                if cfg.QoSTransitionWarning </span><span class="cov0" title="0">{
                        log.Printf("📌 Maintaining Guaranteed QoS pattern (requests = limits)")
                }</span>
        }

        <span class="cov0" title="0">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// needsAdjustmentWithDecision checks if adjustment is needed based on scaling decision
func (r *AdaptiveRightSizer) needsAdjustmentWithDecision(current, new corev1.ResourceRequirements, decision ResourceScalingDecision) bool <span class="cov0" title="0">{
        // If we already determined no scaling is needed, skip
        if decision.CPU == ScaleNone &amp;&amp; decision.Memory == ScaleNone </span><span class="cov0" title="0">{
                return false
        }</span>

        // Get current values
        <span class="cov0" title="0">currentCPU := current.Requests[corev1.ResourceCPU]
        currentMem := current.Requests[corev1.ResourceMemory]
        newCPU := new.Requests[corev1.ResourceCPU]
        newMem := new.Requests[corev1.ResourceMemory]

        // Skip if not set
        if currentCPU.IsZero() || currentMem.IsZero() </span><span class="cov0" title="0">{
                return true
        }</span>

        // Calculate percentage difference
        <span class="cov0" title="0">cpuDiff := float64(newCPU.MilliValue()-currentCPU.MilliValue()) / float64(currentCPU.MilliValue()) * 100
        memDiff := float64(newMem.Value()-currentMem.Value()) / float64(currentMem.Value()) * 100

        // Adjust if difference &gt; 10% (lower threshold since we already checked scaling thresholds)
        threshold := 10.0
        return (cpuDiff &gt; threshold || cpuDiff &lt; -threshold) ||
                (memDiff &gt; threshold || memDiff &lt; -threshold)</span>
}

// getAdjustmentReasonWithDecision provides reason based on scaling decision
func (r *AdaptiveRightSizer) getAdjustmentReasonWithDecision(current, new corev1.ResourceRequirements, decision ResourceScalingDecision) string <span class="cov0" title="0">{
        currentCPU := current.Requests[corev1.ResourceCPU]
        currentMem := current.Requests[corev1.ResourceMemory]
        newCPU := new.Requests[corev1.ResourceCPU]
        newMem := new.Requests[corev1.ResourceMemory]

        reasons := []string{}

        if decision.CPU == ScaleUp </span><span class="cov0" title="0">{
                reasons = append(reasons, fmt.Sprintf("CPU scale up from %s to %s", currentCPU.String(), newCPU.String()))
        }</span> else<span class="cov0" title="0"> if decision.CPU == ScaleDown </span><span class="cov0" title="0">{
                reasons = append(reasons, fmt.Sprintf("CPU scale down from %s to %s", currentCPU.String(), newCPU.String()))
        }</span>

        <span class="cov0" title="0">if decision.Memory == ScaleUp </span><span class="cov0" title="0">{
                reasons = append(reasons, fmt.Sprintf("Memory scale up from %s to %s", formatMemory(currentMem), formatMemory(newMem)))
        }</span> else<span class="cov0" title="0"> if decision.Memory == ScaleDown </span><span class="cov0" title="0">{
                reasons = append(reasons, fmt.Sprintf("Memory scale down from %s to %s", formatMemory(currentMem), formatMemory(newMem)))
        }</span>

        <span class="cov0" title="0">if len(reasons) == 0 </span><span class="cov0" title="0">{
                return "Resource optimization"
        }</span>

        <span class="cov0" title="0">return strings.Join(reasons, ", ")</span>
}

// formatMemory formats memory quantity for display
func formatMemory(q resource.Quantity) string <span class="cov0" title="0">{
        // Convert to Mi for better readability
        valueInBytes := q.Value()
        valueInMi := valueInBytes / (1024 * 1024)
        return fmt.Sprintf("%dMi", valueInMi)
}</span>

func (r *AdaptiveRightSizer) needsAdjustment(current, new corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        // Get current values
        currentCPU := current.Requests[corev1.ResourceCPU]
        currentMem := current.Requests[corev1.ResourceMemory]
        newCPU := new.Requests[corev1.ResourceCPU]
        newMem := new.Requests[corev1.ResourceMemory]

        // Skip if not set
        if currentCPU.IsZero() || currentMem.IsZero() </span><span class="cov0" title="0">{
                return true
        }</span>

        // Calculate percentage difference
        <span class="cov0" title="0">cpuDiff := float64(newCPU.MilliValue()-currentCPU.MilliValue()) / float64(currentCPU.MilliValue()) * 100
        memDiff := float64(newMem.Value()-currentMem.Value()) / float64(currentMem.Value()) * 100

        // Adjust if difference &gt; 15%
        threshold := 15.0
        return (cpuDiff &gt; threshold || cpuDiff &lt; -threshold) ||
                (memDiff &gt; threshold || memDiff &lt; -threshold)</span>
}

func (r *AdaptiveRightSizer) getAdjustmentReason(current, new corev1.ResourceRequirements) string <span class="cov0" title="0">{
        currentCPU := current.Requests[corev1.ResourceCPU]
        currentMem := current.Requests[corev1.ResourceMemory]
        newCPU := new.Requests[corev1.ResourceCPU]
        newMem := new.Requests[corev1.ResourceMemory]

        cpuChange := "no change"
        if newCPU.MilliValue() &gt; currentCPU.MilliValue() </span><span class="cov0" title="0">{
                cpuChange = fmt.Sprintf("increase from %s to %s", currentCPU.String(), newCPU.String())
        }</span> else<span class="cov0" title="0"> if newCPU.MilliValue() &lt; currentCPU.MilliValue() </span><span class="cov0" title="0">{
                cpuChange = fmt.Sprintf("decrease from %s to %s", currentCPU.String(), newCPU.String())
        }</span>

        <span class="cov0" title="0">memChange := "no change"
        if newMem.Value() &gt; currentMem.Value() </span><span class="cov0" title="0">{
                memChange = fmt.Sprintf("increase from %s to %s", currentMem.String(), newMem.String())
        }</span> else<span class="cov0" title="0"> if newMem.Value() &lt; currentMem.Value() </span><span class="cov0" title="0">{
                memChange = fmt.Sprintf("decrease from %s to %s", currentMem.String(), newMem.String())
        }</span>

        <span class="cov0" title="0">return fmt.Sprintf("CPU %s, Memory %s", cpuChange, memChange)</span>
}

func (r *AdaptiveRightSizer) isSystemWorkload(namespace, name string) bool <span class="cov0" title="0">{
        systemNamespaces := []string{"kube-system", "kube-public", "kube-node-lease"}
        for _, ns := range systemNamespaces </span><span class="cov0" title="0">{
                if namespace == ns </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Skip the right-sizer itself
        <span class="cov0" title="0">if name == "right-sizer" </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov0" title="0">return false</span>
}

func (r *AdaptiveRightSizer) logUpdate(update ResourceUpdate, dryRun bool) <span class="cov0" title="0">{
        mode := ""
        if dryRun </span><span class="cov0" title="0">{
                mode = "[DRY RUN] "
        }</span>

        <span class="cov0" title="0">cpuReq := update.NewResources.Requests[corev1.ResourceCPU]
        memReq := update.NewResources.Requests[corev1.ResourceMemory]
        oldCpuReq := update.OldResources.Requests[corev1.ResourceCPU]
        oldMemReq := update.OldResources.Requests[corev1.ResourceMemory]

        log.Printf("%s%s %s/%s/%s - Planned resize: CPU: %s→%s, Memory: %s→%s",
                mode,
                update.ResourceType,
                update.Namespace,
                update.Name,
                update.ContainerName,
                oldCpuReq.String(),
                cpuReq.String(),
                oldMemReq.String(),
                memReq.String())
        return</span>
}

// shouldProcessNamespace checks if a namespace should be processed based on include/exclude lists
func (r *AdaptiveRightSizer) shouldProcessNamespace(namespace string) bool <span class="cov0" title="0">{
        cfg := config.Get()

        // Check exclude list first (takes precedence)
        for _, excludeNs := range cfg.NamespaceExclude </span><span class="cov0" title="0">{
                if namespace == excludeNs </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // If include list is empty, process all non-excluded namespaces
        <span class="cov0" title="0">if len(cfg.NamespaceInclude) == 0 </span><span class="cov0" title="0">{
                return true
        }</span>

        // Check if namespace is in include list
        <span class="cov0" title="0">for _, includeNs := range cfg.NamespaceInclude </span><span class="cov0" title="0">{
                if namespace == includeNs </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// getQoSClass determines the QoS class of a pod
func getQoSClass(pod *corev1.Pod) corev1.PodQOSClass <span class="cov0" title="0">{
        requests := make(corev1.ResourceList)
        limits := make(corev1.ResourceList)
        zeroQuantity := resource.MustParse("0")
        isGuaranteed := true

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Accumulate requests
                for name, quantity := range container.Resources.Requests </span><span class="cov0" title="0">{
                        if value, exists := requests[name]; !exists </span><span class="cov0" title="0">{
                                requests[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                requests[name] = value
                        }</span>
                }

                // Accumulate limits
                <span class="cov0" title="0">for name, quantity := range container.Resources.Limits </span><span class="cov0" title="0">{
                        if value, exists := limits[name]; !exists </span><span class="cov0" title="0">{
                                limits[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                limits[name] = value
                        }</span>
                }
        }

        // Check if guaranteed - must have both CPU and memory requests/limits and they must be equal
        <span class="cov0" title="0">if len(requests) &lt; 2 || len(limits) &lt; 2 </span><span class="cov0" title="0">{
                isGuaranteed = false
        }</span> else<span class="cov0" title="0"> {
                // Check CPU and Memory specifically
                cpuReq, hasCPUReq := requests[corev1.ResourceCPU]
                cpuLim, hasCPULim := limits[corev1.ResourceCPU]
                memReq, hasMemReq := requests[corev1.ResourceMemory]
                memLim, hasMemLim := limits[corev1.ResourceMemory]

                if !hasCPUReq || !hasCPULim || !hasMemReq || !hasMemLim </span><span class="cov0" title="0">{
                        isGuaranteed = false
                }</span> else<span class="cov0" title="0"> if cpuReq.Cmp(cpuLim) != 0 || memReq.Cmp(memLim) != 0 </span><span class="cov0" title="0">{
                        isGuaranteed = false
                }</span>
        }

        <span class="cov0" title="0">if isGuaranteed </span><span class="cov0" title="0">{
                return corev1.PodQOSGuaranteed
        }</span>

        // Check if burstable (has some requests or limits)
        <span class="cov0" title="0">for _, req := range requests </span><span class="cov0" title="0">{
                if req.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">for _, limit := range limits </span><span class="cov0" title="0">{
                if limit.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">return corev1.PodQOSBestEffort</span>
}

// SetupAdaptiveRightSizer creates and starts the adaptive rightsizer
func SetupAdaptiveRightSizer(mgr manager.Manager, provider metrics.Provider, dryRun bool) error <span class="cov0" title="0">{
        cfg := config.Get()

        // Get the rest config from the manager
        restConfig := mgr.GetConfig()

        // Create a clientset for using the resize subresource
        clientSet, err := kubernetes.NewForConfig(restConfig)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create kubernetes clientset: %w", err)
        }</span>

        <span class="cov0" title="0">rightsizer := &amp;AdaptiveRightSizer{
                Client:          mgr.GetClient(),
                ClientSet:       clientSet,
                RestConfig:      restConfig,
                MetricsProvider: provider,
                Interval:        cfg.ResizeInterval,
                DryRun:          dryRun,
                resizeCache:     make(map[string]*ResizeDecisionCache),
                cacheExpiry:     5 * time.Minute, // Cache entries for 5 minutes
        }

        // Start the rightsizer
        go func() </span><span class="cov0" title="0">{
                if err := mgr.Add(manager.RunnableFunc(func(ctx context.Context) error </span><span class="cov0" title="0">{
                        return rightsizer.Start(ctx)
                }</span>)); err != nil <span class="cov0" title="0">{
                        log.Printf("Failed to add adaptive rightsizer to manager: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">return nil</span>
}

// ensureSafeResourcePatchAdaptive ensures the patch never tries to remove or add resource fields
// Only existing resource types in the current pod can be modified
// This is the adaptive rightsizer version of the safety function
func ensureSafeResourcePatchAdaptive(current, desired corev1.ResourceRequirements) corev1.ResourceRequirements <span class="cov0" title="0">{
        logger.Info("🛡️  Ensuring safe resource patch (adaptive)...")

        result := corev1.ResourceRequirements{}

        // Handle requests - preserve ALL existing resource types
        if current.Requests != nil &amp;&amp; len(current.Requests) &gt; 0 </span><span class="cov0" title="0">{
                result.Requests = make(corev1.ResourceList)

                // First, copy ALL existing requests to preserve non-mutable resource types
                for resType, resVal := range current.Requests </span><span class="cov0" title="0">{
                        result.Requests[resType] = resVal.DeepCopy()
                        // Log preservation of non-CPU/memory resources
                        if resType != corev1.ResourceCPU &amp;&amp; resType != corev1.ResourceMemory </span><span class="cov0" title="0">{
                                logger.Info("   🔒 Preserving immutable resource request %s: %s", resType, formatResource(resVal))
                        }</span>
                }

                // Then update only CPU if it exists in current and desired specifies it
                <span class="cov0" title="0">if cpuReq, exists := current.Requests[corev1.ResourceCPU]; exists </span><span class="cov0" title="0">{
                        if desiredCPU, desiredExists := desired.Requests[corev1.ResourceCPU]; desiredExists </span><span class="cov0" title="0">{
                                result.Requests[corev1.ResourceCPU] = desiredCPU
                                logger.Info("   ✅ Updating existing CPU request: %s -&gt; %s", formatResource(cpuReq), formatResource(desiredCPU))
                        }</span> else<span class="cov0" title="0"> {
                                logger.Info("   🔄 Preserving existing CPU request: %s", formatResource(cpuReq))
                        }</span>
                }

                // Update Memory request if it exists in current and desired specifies it
                <span class="cov0" title="0">if memReq, exists := current.Requests[corev1.ResourceMemory]; exists </span><span class="cov0" title="0">{
                        if desiredMem, desiredExists := desired.Requests[corev1.ResourceMemory]; desiredExists </span><span class="cov0" title="0">{
                                result.Requests[corev1.ResourceMemory] = desiredMem
                                logger.Info("   ✅ Updating existing Memory request: %s -&gt; %s", formatMemory(memReq), formatMemory(desiredMem))
                        }</span> else<span class="cov0" title="0"> {
                                logger.Info("   🔄 Preserving existing Memory request: %s", formatMemory(memReq))
                        }</span>
                }
        }

        // Handle limits - preserve ALL existing resource types
        <span class="cov0" title="0">if current.Limits != nil &amp;&amp; len(current.Limits) &gt; 0 </span><span class="cov0" title="0">{
                result.Limits = make(corev1.ResourceList)

                // First, copy ALL existing limits to preserve non-mutable resource types
                for resType, resVal := range current.Limits </span><span class="cov0" title="0">{
                        result.Limits[resType] = resVal.DeepCopy()
                        // Log preservation of non-CPU/memory resources
                        if resType != corev1.ResourceCPU &amp;&amp; resType != corev1.ResourceMemory </span><span class="cov0" title="0">{
                                logger.Info("   🔒 Preserving immutable resource limit %s: %s", resType, formatResource(resVal))
                        }</span>
                }

                // Then update only CPU if it exists in current and desired specifies it
                <span class="cov0" title="0">if cpuLim, exists := current.Limits[corev1.ResourceCPU]; exists </span><span class="cov0" title="0">{
                        if desiredCPU, desiredExists := desired.Limits[corev1.ResourceCPU]; desiredExists </span><span class="cov0" title="0">{
                                result.Limits[corev1.ResourceCPU] = desiredCPU
                                logger.Info("   ✅ Updating existing CPU limit: %s -&gt; %s", formatResource(cpuLim), formatResource(desiredCPU))
                        }</span> else<span class="cov0" title="0"> {
                                logger.Info("   🔄 Preserving existing CPU limit: %s", formatResource(cpuLim))
                        }</span>
                }

                // Update Memory limit if it exists in current and desired specifies it
                <span class="cov0" title="0">if memLim, exists := current.Limits[corev1.ResourceMemory]; exists </span><span class="cov0" title="0">{
                        if desiredMem, desiredExists := desired.Limits[corev1.ResourceMemory]; desiredExists </span><span class="cov0" title="0">{
                                result.Limits[corev1.ResourceMemory] = desiredMem
                                logger.Info("   ✅ Updating existing Memory limit: %s -&gt; %s", formatMemory(memLim), formatMemory(desiredMem))
                        }</span> else<span class="cov0" title="0"> {
                                logger.Info("   🔄 Preserving existing Memory limit: %s", formatMemory(memLim))
                        }</span>
                }
        }

        // Log what we're NOT including to help debug
        <span class="cov0" title="0">if desired.Requests != nil </span><span class="cov0" title="0">{
                for resType, resVal := range desired.Requests </span><span class="cov0" title="0">{
                        if _, exists := current.Requests[resType]; !exists </span><span class="cov0" title="0">{
                                logger.Info("   ⚠️  Skipping new request type %s: %s (not in current pod)", resType, formatResource(resVal))
                        }</span>
                }
        }
        <span class="cov0" title="0">if desired.Limits != nil </span><span class="cov0" title="0">{
                for resType, resVal := range desired.Limits </span><span class="cov0" title="0">{
                        if _, exists := current.Limits[resType]; !exists </span><span class="cov0" title="0">{
                                logger.Info("   ⚠️  Skipping new limit type %s: %s (not in current pod)", resType, formatResource(resVal))
                        }</span>
                }
        }

        <span class="cov0" title="0">logger.Info("✅ Safe resource patch completed (adaptive)")
        return result</span>
}
</pre>
		
		<pre class="file" id="file7" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package controllers

import (
        "context"
        "log"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        appsv1 "k8s.io/api/apps/v1"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/manager"
)

// DeploymentRightSizer adjusts deployment resources based on pod metrics
type DeploymentRightSizer struct {
        Client          client.Client
        MetricsProvider metrics.Provider
        Interval        time.Duration
}

// Start begins the continuous monitoring and adjustment loop
func (r *DeploymentRightSizer) Start(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(r.Interval)
        defer ticker.Stop()

        logger.Info("Starting deployment right-sizer with %v interval", r.Interval)

        // Run immediately on start
        r.rightSizeDeployments(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        r.rightSizeDeployments(ctx)</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        log.Println("Stopping deployment right-sizer")
                        return nil</span>
                }
        }
}

// rightSizeDeployments processes all deployments in the cluster
func (r *DeploymentRightSizer) rightSizeDeployments(ctx context.Context) <span class="cov0" title="0">{
        var deployList appsv1.DeploymentList
        if err := r.Client.List(ctx, &amp;deployList); err != nil </span><span class="cov0" title="0">{
                logger.Error("Error listing deployments: %v", err)
                return
        }</span>

        <span class="cov0" title="0">log.Printf("Processing %d deployments for right-sizing", len(deployList.Items))

        for _, deploy := range deployList.Items </span><span class="cov0" title="0">{
                // Skip system deployments
                if isSystemDeployment(&amp;deploy) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">if err := r.rightSizeDeployment(ctx, &amp;deploy); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Error right-sizing deployment %s/%s: %v",
                                deploy.Namespace, deploy.Name, err)
                }</span>
        }

        // Also process StatefulSets
        <span class="cov0" title="0">var stsList appsv1.StatefulSetList
        if err := r.Client.List(ctx, &amp;stsList); err != nil </span><span class="cov0" title="0">{
                log.Printf("Error listing statefulsets: %v", err)
                return
        }</span>

        <span class="cov0" title="0">log.Printf("Processing %d statefulsets for right-sizing", len(stsList.Items))

        for _, sts := range stsList.Items </span><span class="cov0" title="0">{
                if isSystemStatefulSet(&amp;sts) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">if err := r.rightSizeStatefulSet(ctx, &amp;sts); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Error right-sizing statefulset %s/%s: %v",
                                sts.Namespace, sts.Name, err)
                }</span>
        }
}

// rightSizeDeployment adjusts resources for a single deployment
func (r *DeploymentRightSizer) rightSizeDeployment(ctx context.Context, deploy *appsv1.Deployment) error <span class="cov0" title="0">{
        // Get pods for this deployment
        var podList corev1.PodList
        labels := client.MatchingLabels(deploy.Spec.Selector.MatchLabels)
        if err := r.Client.List(ctx, &amp;podList, labels, client.InNamespace(deploy.Namespace)); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if len(podList.Items) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Calculate average metrics across all pods
        <span class="cov0" title="0">totalCPU := 0.0
        totalMem := 0.0
        validPods := 0

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">totalCPU += usage.CPUMilli
                totalMem += usage.MemMB
                validPods++</span>
        }

        <span class="cov0" title="0">if validPods == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">avgCPU := totalCPU / float64(validPods)
        avgMem := totalMem / float64(validPods)

        // Calculate new resources based on average usage
        newResources := r.calculateOptimalResources(metrics.Metrics{
                CPUMilli: avgCPU,
                MemMB:    avgMem,
        })

        // Check if adjustment is needed
        if !r.needsAdjustment(&amp;deploy.Spec.Template.Spec, newResources) </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">cpuReq := newResources.Requests[corev1.ResourceCPU]
        memReq := newResources.Requests[corev1.ResourceMemory]
        log.Printf("Adjusting deployment %s/%s - Avg CPU: %.0fm-&gt;%s, Avg Memory: %.0fMi-&gt;%s",
                deploy.Namespace, deploy.Name,
                avgCPU, cpuReq.String(),
                avgMem, memReq.String())

        // Update all containers in the deployment
        for i := range deploy.Spec.Template.Spec.Containers </span><span class="cov0" title="0">{
                deploy.Spec.Template.Spec.Containers[i].Resources = newResources
        }</span>

        // Add annotation to track last update
        <span class="cov0" title="0">if deploy.Spec.Template.Annotations == nil </span><span class="cov0" title="0">{
                deploy.Spec.Template.Annotations = make(map[string]string)
        }</span>
        <span class="cov0" title="0">deploy.Spec.Template.Annotations["right-sizer/last-update"] = time.Now().Format(time.RFC3339)

        // Update the deployment (this will trigger a rolling update)
        return r.Client.Update(ctx, deploy)</span>
}

// rightSizeStatefulSet adjusts resources for a single statefulset
func (r *DeploymentRightSizer) rightSizeStatefulSet(ctx context.Context, sts *appsv1.StatefulSet) error <span class="cov0" title="0">{
        // Get pods for this statefulset
        var podList corev1.PodList
        labels := client.MatchingLabels(sts.Spec.Selector.MatchLabels)
        if err := r.Client.List(ctx, &amp;podList, labels, client.InNamespace(sts.Namespace)); err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">if len(podList.Items) == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Calculate average metrics across all pods
        <span class="cov0" title="0">totalCPU := 0.0
        totalMem := 0.0
        validPods := 0

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">totalCPU += usage.CPUMilli
                totalMem += usage.MemMB
                validPods++</span>
        }

        <span class="cov0" title="0">if validPods == 0 </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">avgCPU := totalCPU / float64(validPods)
        avgMem := totalMem / float64(validPods)

        // Calculate new resources based on average usage
        newResources := r.calculateOptimalResources(metrics.Metrics{
                CPUMilli: avgCPU,
                MemMB:    avgMem,
        })

        // Check if adjustment is needed
        if !r.needsAdjustment(&amp;sts.Spec.Template.Spec, newResources) </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">cpuReq := newResources.Requests[corev1.ResourceCPU]
        memReq := newResources.Requests[corev1.ResourceMemory]
        log.Printf("Adjusting statefulset %s/%s - Avg CPU: %.0fm-&gt;%s, Avg Memory: %.0fMi-&gt;%s",
                sts.Namespace, sts.Name,
                avgCPU, cpuReq.String(),
                avgMem, memReq.String())

        // Update all containers in the statefulset
        for i := range sts.Spec.Template.Spec.Containers </span><span class="cov0" title="0">{
                sts.Spec.Template.Spec.Containers[i].Resources = newResources
        }</span>

        // Add annotation to track last update
        <span class="cov0" title="0">if sts.Spec.Template.Annotations == nil </span><span class="cov0" title="0">{
                sts.Spec.Template.Annotations = make(map[string]string)
        }</span>
        <span class="cov0" title="0">sts.Spec.Template.Annotations["right-sizer/last-update"] = time.Now().Format(time.RFC3339)

        // Update the statefulset (this will trigger a rolling update)
        return r.Client.Update(ctx, sts)</span>
}

// calculateOptimalResources determines optimal resource allocation
func (r *DeploymentRightSizer) calculateOptimalResources(usage metrics.Metrics) corev1.ResourceRequirements <span class="cov0" title="0">{
        cfg := config.Get()

        // Add buffer for requests using configurable multipliers and additions
        cpuRequest := int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        memRequest := int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition

        // Ensure minimum values
        if cpuRequest &lt; cfg.MinCPURequest </span><span class="cov0" title="0">{
                cpuRequest = cfg.MinCPURequest
        }</span>
        <span class="cov0" title="0">if memRequest &lt; cfg.MinMemoryRequest </span><span class="cov0" title="0">{
                memRequest = cfg.MinMemoryRequest
        }</span>

        // Calculate limits based on requests with multipliers and additions
        <span class="cov0" title="0">cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        // Apply maximum caps
        if cpuLimit &gt; cfg.MaxCPULimit </span><span class="cov0" title="0">{
                cpuLimit = cfg.MaxCPULimit
        }</span>
        <span class="cov0" title="0">if memLimit &gt; cfg.MaxMemoryLimit </span><span class="cov0" title="0">{
                memLimit = cfg.MaxMemoryLimit
        }</span>

        <span class="cov0" title="0">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// needsAdjustment checks if pod template resources need updating
func (r *DeploymentRightSizer) needsAdjustment(podSpec *corev1.PodSpec, newResources corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        if len(podSpec.Containers) == 0 </span><span class="cov0" title="0">{
                return false
        }</span>

        // Check first container (main container)
        <span class="cov0" title="0">container := podSpec.Containers[0]

        // Get current CPU and memory requests
        currentCPU := container.Resources.Requests[corev1.ResourceCPU]
        currentMem := container.Resources.Requests[corev1.ResourceMemory]
        newCPU := newResources.Requests[corev1.ResourceCPU]
        newMem := newResources.Requests[corev1.ResourceMemory]

        // Skip if current resources are not set
        if currentCPU.IsZero() || currentMem.IsZero() </span><span class="cov0" title="0">{
                return true
        }</span>

        // Calculate percentage difference
        <span class="cov0" title="0">cpuDiff := float64(newCPU.MilliValue()-currentCPU.MilliValue()) / float64(currentCPU.MilliValue()) * 100
        memDiff := float64(newMem.Value()-currentMem.Value()) / float64(currentMem.Value()) * 100

        // Only adjust if difference is more than 10%
        threshold := 10.0
        return (cpuDiff &gt; threshold || cpuDiff &lt; -threshold) || (memDiff &gt; threshold || memDiff &lt; -threshold)</span>
}

// isSystemDeployment checks if a deployment is a system/infrastructure deployment
func isSystemDeployment(deploy *appsv1.Deployment) bool <span class="cov0" title="0">{
        systemNamespaces := []string{"kube-system", "kube-public", "kube-node-lease"}
        for _, ns := range systemNamespaces </span><span class="cov0" title="0">{
                if deploy.Namespace == ns </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Skip the right-sizer itself
        <span class="cov0" title="0">if deploy.Name == "right-sizer" </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov0" title="0">return false</span>
}

// isSystemStatefulSet checks if a statefulset is a system/infrastructure statefulset
func isSystemStatefulSet(sts *appsv1.StatefulSet) bool <span class="cov0" title="0">{
        systemNamespaces := []string{"kube-system", "kube-public", "kube-node-lease"}
        for _, ns := range systemNamespaces </span><span class="cov0" title="0">{
                if sts.Namespace == ns </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// SetupDeploymentRightSizer creates and starts the deployment rightsizer
func SetupDeploymentRightSizer(mgr manager.Manager, provider metrics.Provider) error <span class="cov0" title="0">{
        cfg := config.Get()
        rightsizer := &amp;DeploymentRightSizer{
                Client:          mgr.GetClient(),
                MetricsProvider: provider,
                Interval:        cfg.ResizeInterval,
        }

        // Start the rightsizer in a goroutine
        go func() </span><span class="cov0" title="0">{
                if err := mgr.Add(manager.RunnableFunc(func(ctx context.Context) error </span><span class="cov0" title="0">{
                        return rightsizer.Start(ctx)
                }</span>)); err != nil <span class="cov0" title="0">{
                        log.Printf("Failed to add deployment rightsizer to manager: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file8" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package controllers

import (
        "context"
        "time"

        "right-sizer/audit"
        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"
        "right-sizer/policy"
        "right-sizer/retry"
        "right-sizer/validation"

        "k8s.io/client-go/kubernetes"
        "sigs.k8s.io/controller-runtime/pkg/manager"
)

// EnhancedInPlaceRightSizer is an enhanced version with all features
type EnhancedInPlaceRightSizer struct {
        InPlaceRightSizer
        ResourceValidator *validation.ResourceValidator
        PolicyEngine      *policy.PolicyEngine
        AuditLogger       *audit.AuditLogger
        OperatorMetrics   *metrics.OperatorMetrics
        RetryHandler      *retry.RetryWithCircuitBreaker
        Config            *config.Config
}

// EnhancedAdaptiveRightSizer is an enhanced version with all features
type EnhancedAdaptiveRightSizer struct {
        // Base adaptive rightsizer would be embedded here
        // For this example, we'll use a similar structure
        Client            manager.Manager
        MetricsProvider   metrics.Provider
        ResourceValidator *validation.ResourceValidator
        PolicyEngine      *policy.PolicyEngine
        AuditLogger       *audit.AuditLogger
        OperatorMetrics   *metrics.OperatorMetrics
        RetryHandler      *retry.RetryWithCircuitBreaker
        Config            *config.Config
        Interval          time.Duration
        DryRun            bool
}

// SetupEnhancedInPlaceRightSizer sets up the enhanced in-place rightsizer with all features
func SetupEnhancedInPlaceRightSizer(
        mgr manager.Manager,
        provider metrics.Provider,
        validator *validation.ResourceValidator,
        policyEngine *policy.PolicyEngine,
        auditLogger *audit.AuditLogger,
        operatorMetrics *metrics.OperatorMetrics,
        retryHandler *retry.RetryWithCircuitBreaker,
) error <span class="cov0" title="0">{
        cfg := config.Get()

        // Get REST config
        restConfig := mgr.GetConfig()

        // Create clientset
        clientset, err := kubernetes.NewForConfig(restConfig)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Create enhanced in-place rightsizer
        <span class="cov0" title="0">enhancedRightSizer := &amp;EnhancedInPlaceRightSizer{
                InPlaceRightSizer: InPlaceRightSizer{
                        Client:          mgr.GetClient(),
                        ClientSet:       clientset,
                        RestConfig:      restConfig,
                        MetricsProvider: provider,
                        Interval:        cfg.ResizeInterval,
                        resizeCache:     make(map[string]*ResizeDecisionCache),
                        cacheExpiry:     5 * time.Minute, // Cache entries for 5 minutes
                },
                ResourceValidator: validator,
                PolicyEngine:      policyEngine,
                AuditLogger:       auditLogger,
                OperatorMetrics:   operatorMetrics,
                RetryHandler:      retryHandler,
                Config:            cfg,
        }

        // Start the enhanced rightsizer
        go func() </span><span class="cov0" title="0">{
                ctx := context.Background()
                if err := enhancedRightSizer.StartEnhanced(ctx); err != nil </span><span class="cov0" title="0">{
                        logger.Error("Enhanced InPlaceRightSizer error: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">logger.Info("✅ Enhanced InPlaceRightSizer setup completed")
        return nil</span>
}

// SetupEnhancedAdaptiveRightSizer sets up the enhanced adaptive rightsizer with all features
func SetupEnhancedAdaptiveRightSizer(
        mgr manager.Manager,
        provider metrics.Provider,
        validator *validation.ResourceValidator,
        policyEngine *policy.PolicyEngine,
        auditLogger *audit.AuditLogger,
        operatorMetrics *metrics.OperatorMetrics,
        retryHandler *retry.RetryWithCircuitBreaker,
        dryRun bool,
) error <span class="cov0" title="0">{
        cfg := config.Get()

        // Create enhanced adaptive rightsizer
        enhancedRightSizer := &amp;EnhancedAdaptiveRightSizer{
                Client:            mgr,
                MetricsProvider:   provider,
                ResourceValidator: validator,
                PolicyEngine:      policyEngine,
                AuditLogger:       auditLogger,
                OperatorMetrics:   operatorMetrics,
                RetryHandler:      retryHandler,
                Config:            cfg,
                Interval:          cfg.ResizeInterval,
                DryRun:            dryRun,
        }

        // Start the enhanced rightsizer
        go func() </span><span class="cov0" title="0">{
                ctx := context.Background()
                if err := enhancedRightSizer.StartEnhanced(ctx); err != nil </span><span class="cov0" title="0">{
                        logger.Error("Enhanced AdaptiveRightSizer error: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">logger.Info("✅ Enhanced AdaptiveRightSizer setup completed")
        return nil</span>
}

// StartEnhanced starts the enhanced in-place rightsizer with all features
func (e *EnhancedInPlaceRightSizer) StartEnhanced(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(e.Interval)
        defer ticker.Stop()

        logger.Info("🚀 Starting enhanced in-place right-sizer with %v interval", e.Interval)
        logger.Info("🔧 Enhanced features:")
        logger.Info("   📊 Metrics: %v", e.OperatorMetrics != nil)
        logger.Info("   🔍 Validation: %v", e.ResourceValidator != nil)
        logger.Info("   🏛️  Policies: %v", e.PolicyEngine != nil)
        logger.Info("   📋 Audit: %v", e.AuditLogger != nil)
        logger.Info("   🔁 Retry/CB: %v", e.RetryHandler != nil)

        // Run immediately on start
        e.rightSizeAllPodsEnhanced(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        e.rightSizeAllPodsEnhanced(ctx)</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        logger.Info("🛑 Stopping enhanced in-place right-sizer")
                        return nil</span>
                }
        }
}

// StartEnhanced starts the enhanced adaptive rightsizer with all features
func (e *EnhancedAdaptiveRightSizer) StartEnhanced(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(e.Interval)
        defer ticker.Stop()

        logger.Info("🚀 Starting enhanced adaptive right-sizer with %v interval", e.Interval)
        logger.Info("🔧 Enhanced features:")
        logger.Info("   📊 Metrics: %v", e.OperatorMetrics != nil)
        logger.Info("   🔍 Validation: %v", e.ResourceValidator != nil)
        logger.Info("   🏛️  Policies: %v", e.PolicyEngine != nil)
        logger.Info("   📋 Audit: %v", e.AuditLogger != nil)
        logger.Info("   🔁 Retry/CB: %v", e.RetryHandler != nil)
        logger.Info("   🔬 Dry Run: %v", e.DryRun)

        // Run immediately on start
        e.rightSizeAllPodsEnhanced(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        e.rightSizeAllPodsEnhanced(ctx)</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        logger.Info("🛑 Stopping enhanced adaptive right-sizer")
                        return nil</span>
                }
        }
}

// rightSizeAllPodsEnhanced processes all pods with enhanced features
func (e *EnhancedInPlaceRightSizer) rightSizeAllPodsEnhanced(ctx context.Context) <span class="cov0" title="0">{
        timer := metrics.NewTimer()
        defer func() </span><span class="cov0" title="0">{
                if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                        e.OperatorMetrics.RecordProcessingDuration("enhanced_inplace_cycle", timer.Duration())
                }</span>
        }()

        // Use retry handler for the operation
        <span class="cov0" title="0">operation := "right_size_all_pods"
        err := e.RetryHandler.ExecuteWithContext(ctx, operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return e.rightSizeAllPodsWithEnhancements(ctx)
        }</span>)

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                logger.Error("❌ Enhanced right-sizing cycle failed: %v", err)
                if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                        e.OperatorMetrics.RecordProcessingError("", "", "enhanced_cycle_failure")
                }</span>
        }
}

// rightSizeAllPodsEnhanced processes all pods with enhanced features (adaptive version)
func (e *EnhancedAdaptiveRightSizer) rightSizeAllPodsEnhanced(ctx context.Context) <span class="cov0" title="0">{
        timer := metrics.NewTimer()
        defer func() </span><span class="cov0" title="0">{
                if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                        e.OperatorMetrics.RecordProcessingDuration("enhanced_adaptive_cycle", timer.Duration())
                }</span>
        }()

        // Use retry handler for the operation
        <span class="cov0" title="0">operation := "right_size_all_pods_adaptive"
        err := e.RetryHandler.ExecuteWithContext(ctx, operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return e.rightSizeAllPodsWithEnhancements(ctx)
        }</span>)

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                logger.Error("❌ Enhanced adaptive right-sizing cycle failed: %v", err)
                if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                        e.OperatorMetrics.RecordProcessingError("", "", "enhanced_adaptive_cycle_failure")
                }</span>
        }
}

// rightSizeAllPodsWithEnhancements contains the core logic with all enhancements
func (e *EnhancedInPlaceRightSizer) rightSizeAllPodsWithEnhancements(ctx context.Context) error <span class="cov0" title="0">{
        // This would contain the enhanced pod processing logic
        // For brevity, showing the pattern of integration
        logger.Info("🔄 Processing pods with enhanced features...")

        // Record metrics
        if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                e.OperatorMetrics.RecordPodProcessed()
        }</span>

        // The actual implementation would:
        // 1. List all pods using the base InPlaceRightSizer logic
        // 2. For each pod, apply policy evaluation
        // 3. Validate resource changes
        // 4. Apply changes with retry logic
        // 5. Log audit events
        // 6. Update metrics

        <span class="cov0" title="0">return nil</span>
}

// rightSizeAllPodsWithEnhancements contains the core logic with all enhancements (adaptive version)
func (e *EnhancedAdaptiveRightSizer) rightSizeAllPodsWithEnhancements(ctx context.Context) error <span class="cov0" title="0">{
        // This would contain the enhanced pod processing logic for adaptive rightsizer
        logger.Info("🔄 Processing pods with enhanced adaptive features...")

        // Record metrics
        if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                e.OperatorMetrics.RecordPodProcessed()
        }</span>

        // The actual implementation would be similar to in-place but with
        // different resizing strategies for older Kubernetes versions

        <span class="cov0" title="0">return nil</span>
}

// ProcessPodWithEnhancements processes a single pod with all enhancement features
func (e *EnhancedInPlaceRightSizer) ProcessPodWithEnhancements(ctx context.Context, podName, namespace string) error <span class="cov0" title="0">{
        timer := metrics.NewTimer()
        defer func() </span><span class="cov0" title="0">{
                if e.OperatorMetrics != nil </span><span class="cov0" title="0">{
                        e.OperatorMetrics.RecordProcessingDuration("enhanced_pod_processing", timer.Duration())
                }</span>
        }()

        <span class="cov0" title="0">logger.Debug("🔍 Processing pod %s/%s with enhancements", namespace, podName)

        // This would implement the full enhanced processing pipeline:
        // 1. Get pod and current metrics
        // 2. Apply policy engine rules
        // 3. Calculate optimal resources
        // 4. Validate changes
        // 5. Apply changes with retry
        // 6. Log audit events
        // 7. Update metrics

        return nil</span>
}

// ValidateAndApplyResourceChange validates and applies resource changes with all safety checks
func (e *EnhancedInPlaceRightSizer) ValidateAndApplyResourceChange(
        ctx context.Context,
        podName, namespace, containerName string,
        newResources map[string]interface{},
) error <span class="cov0" title="0">{
        logger.Debug("🔍 Validating and applying resource change for %s/%s container %s",
                namespace, podName, containerName)

        // Implementation would:
        // 1. Use ResourceValidator to validate the change
        // 2. Check safety thresholds
        // 3. Apply change using retry handler
        // 4. Log audit event
        // 5. Update metrics

        return nil
}</span>
</pre>
		
		<pre class="file" id="file9" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package controllers

import (
        "context"
        "encoding/json"
        "fmt"
        "log"
        "strings"
        "sync"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"
        "right-sizer/validation"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/types"
        "k8s.io/client-go/kubernetes"
        "k8s.io/client-go/rest"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/manager"
)

// InPlaceRightSizer performs in-place resource adjustments without pod restarts using Kubernetes 1.33+ resize subresource
// This version ONLY updates pods directly, not deployments or other controllers
type InPlaceRightSizer struct {
        Client          client.Client
        ClientSet       *kubernetes.Clientset
        RestConfig      *rest.Config
        MetricsProvider metrics.Provider
        Interval        time.Duration
        Validator       *validation.ResourceValidator
        resizeCache     map[string]*ResizeDecisionCache
        cacheMutex      sync.RWMutex
        cacheExpiry     time.Duration // How long to keep cache entries
}

// PodResizePatch represents the patch structure for the resize subresource
type PodResizePatch struct {
        Spec PodSpecPatch `json:"spec"`
}

// PodSpecPatch contains the containers to be resized
type PodSpecPatch struct {
        Containers []ContainerResourcesPatch `json:"containers"`
}

// ContainerResourcesPatch represents container resources to patch
type ContainerResourcesPatch struct {
        Name      string                      `json:"name"`
        Resources corev1.ResourceRequirements `json:"resources"`
}

// ScalingDecision and ResourceScalingDecision types are defined in adaptive_rightsizer.go

// shouldLogResizeDecision checks if we should log this resize decision based on cache
func (r *InPlaceRightSizer) shouldLogResizeDecision(namespace, podName, containerName, oldCPU, newCPU, oldMemory, newMemory string) bool <span class="cov0" title="0">{
        containerKey := fmt.Sprintf("%s/%s/%s", namespace, podName, containerName)

        r.cacheMutex.RLock()
        cached, exists := r.resizeCache[containerKey]
        r.cacheMutex.RUnlock()

        if !exists </span><span class="cov0" title="0">{
                // First time seeing this decision, cache it and allow logging
                r.cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory)
                return true
        }</span>

        // Check if decision has changed or cache has expired
        <span class="cov0" title="0">now := time.Now()
        if now.Sub(cached.LastSeen) &gt; r.cacheExpiry ||
                cached.OldCPU != oldCPU || cached.NewCPU != newCPU ||
                cached.OldMemory != oldMemory || cached.NewMemory != newMemory </span><span class="cov0" title="0">{
                // Decision changed or expired, update cache and allow logging
                r.cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory)
                return true
        }</span>

        // Same decision within cache period, suppress logging
        <span class="cov0" title="0">return false</span>
}

// cacheResizeDecision stores or updates a resize decision in the cache
func (r *InPlaceRightSizer) cacheResizeDecision(containerKey, oldCPU, newCPU, oldMemory, newMemory string) <span class="cov0" title="0">{
        r.cacheMutex.Lock()
        defer r.cacheMutex.Unlock()

        r.resizeCache[containerKey] = &amp;ResizeDecisionCache{
                ContainerKey: containerKey,
                OldCPU:       oldCPU,
                NewCPU:       newCPU,
                OldMemory:    oldMemory,
                NewMemory:    newMemory,
                LastSeen:     time.Now(),
        }
}</span>

// cleanExpiredCacheEntries removes expired cache entries
func (r *InPlaceRightSizer) cleanExpiredCacheEntries() <span class="cov0" title="0">{
        r.cacheMutex.Lock()
        defer r.cacheMutex.Unlock()

        now := time.Now()
        for key, cached := range r.resizeCache </span><span class="cov0" title="0">{
                if now.Sub(cached.LastSeen) &gt; r.cacheExpiry </span><span class="cov0" title="0">{
                        delete(r.resizeCache, key)
                }</span>
        }
}

// Start begins the continuous monitoring and adjustment loop
func (r *InPlaceRightSizer) Start(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(r.Interval)
        defer ticker.Stop()

        logger.Info("Starting in-place right-sizer with %v interval", r.Interval)
        log.Printf("🚀 Starting in-place right-sizer with %v interval (Kubernetes 1.33+ resize subresource)", r.Interval)
        log.Printf("📝 Note: This operator ONLY updates pod resources directly")

        // Run immediately on start
        r.rightSizeAllPods(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        r.rightSizeAllPods(ctx)
                        // Clean expired cache entries periodically
                        r.cleanExpiredCacheEntries()</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        log.Println("Stopping in-place right-sizer")
                        return nil</span>
                }
        }
}

// rightSizeAllPods processes all pods in the cluster
func (r *InPlaceRightSizer) rightSizeAllPods(ctx context.Context) <span class="cov0" title="0">{
        var podList corev1.PodList
        if err := r.Client.List(ctx, &amp;podList); err != nil </span><span class="cov0" title="0">{
                log.Printf("❌ Error listing pods: %v", err)
                return
        }</span>

        <span class="cov0" title="0">log.Printf("🔍 Analyzing %d pods for right-sizing...", len(podList.Items))

        resizedCount := 0
        skippedCount := 0
        errorCount := 0
        nodeConstraintSkips := 0

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                // Skip pods that are not running
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        skippedCount++
                        continue</span>
                }

                // Skip system pods
                <span class="cov0" title="0">if isSystemPod(&amp;pod) </span><span class="cov0" title="0">{
                        skippedCount++
                        continue</span>
                }

                // Check namespace filters
                <span class="cov0" title="0">if !r.shouldProcessNamespace(pod.Namespace) </span><span class="cov0" title="0">{
                        skippedCount++
                        continue</span>
                }

                // Skip pods that don't support in-place resize
                <span class="cov0" title="0">if !r.supportsInPlaceResize(&amp;pod) </span><span class="cov0" title="0">{
                        log.Printf("⚠️  Pod %s/%s does not support in-place resize, skipping", pod.Namespace, pod.Name)
                        skippedCount++
                        continue</span>
                }

                // Try to right-size the pod
                <span class="cov0" title="0">resized, err := r.rightSizePod(ctx, &amp;pod)
                if err != nil </span><span class="cov0" title="0">{
                        // Check if error is due to node resource constraints
                        if strings.Contains(err.Error(), "exceeds available node capacity") ||
                                strings.Contains(err.Error(), "exceeds node allocatable capacity") </span><span class="cov0" title="0">{
                                nodeConstraintSkips++
                                log.Printf("📍 Skipped pod %s/%s due to node resource constraints", pod.Namespace, pod.Name)
                        }</span> else<span class="cov0" title="0"> if !strings.Contains(err.Error(), "resize failed") </span><span class="cov0" title="0">{
                                log.Printf("❌ Error right-sizing pod %s/%s: %v", pod.Namespace, pod.Name, err)
                                errorCount++
                        }</span>
                } else<span class="cov0" title="0"> if resized </span><span class="cov0" title="0">{
                        resizedCount++
                }</span>
        }

        <span class="cov0" title="0">log.Printf("📊 Right-sizing complete: %d resized, %d skipped (%d due to node constraints), %d errors",
                resizedCount, skippedCount, nodeConstraintSkips, errorCount)</span>
}

// supportsInPlaceResize checks if a pod can be resized in-place
func (r *InPlaceRightSizer) supportsInPlaceResize(pod *corev1.Pod) bool <span class="cov0" title="0">{
        // Skip if pod has owner references (managed by deployment, statefulset, etc)
        // We only want to resize standalone pods or pods we're certain won't be recreated
        // Comment this out if you want to resize all pods regardless of ownership
        /*
                if len(pod.OwnerReferences) &gt; 0 {
                        for _, owner := range pod.OwnerReferences {
                                if owner.Controller != nil &amp;&amp; *owner.Controller {
                                        // This pod is controlled by something else, skip it
                                        return false
                                }
                        }
                }
        */

        // For pods without explicit resize policy, check if they have resources defined
        hasResources := false
        hasNotRequiredPolicy := false

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Check if container has resources defined
                if !container.Resources.Requests.Cpu().IsZero() || !container.Resources.Requests.Memory().IsZero() </span><span class="cov0" title="0">{
                        hasResources = true
                }</span>

                // Check resize policy
                <span class="cov0" title="0">if container.ResizePolicy != nil </span><span class="cov0" title="0">{
                        for _, policy := range container.ResizePolicy </span><span class="cov0" title="0">{
                                if policy.RestartPolicy == corev1.NotRequired </span><span class="cov0" title="0">{
                                        hasNotRequiredPolicy = true
                                        break</span>
                                }
                        }
                }
        }

        // Only attempt resize if:
        // 1. Pod has resources defined (otherwise nothing to resize)
        // 2. Either has NotRequired policy OR no policy (K8s 1.33+ supports resize by default)
        <span class="cov0" title="0">if !hasResources </span><span class="cov0" title="0">{
                return false
        }</span>

        // If explicit NotRequired policy is set, definitely support resize
        <span class="cov0" title="0">if hasNotRequiredPolicy </span><span class="cov0" title="0">{
                return true
        }</span>

        // For K8s 1.33+, pods without explicit policy can still be resized for increases
        // We'll handle decrease restrictions in the resize logic
        <span class="cov0" title="0">return true</span>
}

// rightSizePod adjusts resources for a single pod
func (r *InPlaceRightSizer) rightSizePod(ctx context.Context, pod *corev1.Pod) (bool, error) <span class="cov0" title="0">{
        // Fetch current metrics
        usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
        if err != nil </span><span class="cov0" title="0">{
                // If metrics are not available, skip this pod
                return false, nil
        }</span>

        // Check if scaling is needed based on thresholds
        <span class="cov0" title="0">scalingDecision := r.checkScalingThresholds(usage, pod)

        // Skip if both resources don't need changes
        if scalingDecision.CPU == ScaleNone &amp;&amp; scalingDecision.Memory == ScaleNone </span><span class="cov0" title="0">{
                return false, nil
        }</span>

        // Skip if CPU should not be updated but memory should be reduced
        // This prevents unnecessary pod disruptions when only memory reduction is needed
        <span class="cov0" title="0">if scalingDecision.CPU == ScaleNone &amp;&amp; scalingDecision.Memory == ScaleDown </span><span class="cov0" title="0">{
                log.Printf("⏭️  Skipping resize for pod %s/%s: CPU doesn't need update and memory would be reduced",
                        pod.Namespace, pod.Name)
                return false, nil
        }</span>

        // Calculate new resources based on usage and scaling decision
        <span class="cov0" title="0">newResourcesMap := r.calculateOptimalResourcesForContainers(usage, pod, scalingDecision)

        // Check if adjustment is needed
        needsUpdate, _ := r.needsAdjustmentWithDetails(pod, newResourcesMap)
        if !needsUpdate </span><span class="cov0" title="0">{
                return false, nil
        }</span>

        // Log the actual resource changes that will be made
        <span class="cov0" title="0">for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                if newResources, exists := newResourcesMap[container.Name]; exists </span><span class="cov0" title="0">{
                        oldCPUReq := container.Resources.Requests[corev1.ResourceCPU]
                        oldMemReq := container.Resources.Requests[corev1.ResourceMemory]
                        newCPUReq := newResources.Requests[corev1.ResourceCPU]
                        newMemReq := newResources.Requests[corev1.ResourceMemory]

                        if !oldCPUReq.Equal(newCPUReq) || !oldMemReq.Equal(newMemReq) </span><span class="cov0" title="0">{
                                // Get current usage for detailed logging
                                cpuLimit := container.Resources.Limits.Cpu().AsApproximateFloat64() * 1000
                                memLimit := float64(container.Resources.Limits.Memory().Value()) / (1024 * 1024)
                                cpuUsagePercent := 0.0
                                memUsagePercent := 0.0
                                if cpuLimit &gt; 0 </span><span class="cov0" title="0">{
                                        cpuUsagePercent = (usage.CPUMilli / cpuLimit) * 100
                                }</span>
                                <span class="cov0" title="0">if memLimit &gt; 0 </span><span class="cov0" title="0">{
                                        memUsagePercent = (usage.MemMB / memLimit) * 100
                                }</span>

                                // Check cache before logging to prevent repetitive messages
                                <span class="cov0" title="0">if r.shouldLogResizeDecision(pod.Namespace, pod.Name, container.Name,
                                        oldCPUReq.String(), newCPUReq.String(), oldMemReq.String(), newMemReq.String()) </span><span class="cov0" title="0">{

                                        log.Printf("🔍 Scaling analysis - CPU: %s (usage: %.0fm/%.0fm, %.1f%%), Memory: %s (usage: %.0fMi/%.0fMi, %.1f%%)",
                                                scalingDecisionString(scalingDecision.CPU), usage.CPUMilli, cpuLimit, cpuUsagePercent,
                                                scalingDecisionString(scalingDecision.Memory), usage.MemMB, memLimit, memUsagePercent)
                                        log.Printf("📈 Container %s/%s/%s will be resized - CPU: %s→%s, Memory: %s→%s",
                                                pod.Namespace, pod.Name, container.Name,
                                                oldCPUReq.String(), newCPUReq.String(),
                                                oldMemReq.String(), newMemReq.String())
                                }</span>
                        }
                }
        }

        // Apply in-place update using resize subresource (removed duplicate logging)

        // Apply in-place update using resize subresource
        <span class="cov0" title="0">err = r.applyInPlaceResize(ctx, pod, newResourcesMap)
        if err != nil </span><span class="cov0" title="0">{
                return false, err
        }</span>

        <span class="cov0" title="0">log.Printf("✅ Successfully resized pod %s/%s using resize subresource (no restart)", pod.Namespace, pod.Name)
        return true, nil</span>
}

// ResourceChange holds before/after resource values
type ResourceChange struct {
        CurrentCPU string
        NewCPU     string
        CurrentMem string
        NewMem     string
}

// checkScalingThresholds determines if scaling is needed based on resource usage thresholds
func (r *InPlaceRightSizer) checkScalingThresholds(usage metrics.Metrics, pod *corev1.Pod) ResourceScalingDecision <span class="cov8" title="1">{
        cfg := config.Get()

        // Calculate total current limits for the pod
        var totalCPULimit float64
        var totalMemLimit float64

        for _, container := range pod.Spec.Containers </span><span class="cov8" title="1">{
                if cpuLimit, exists := container.Resources.Limits[corev1.ResourceCPU]; exists &amp;&amp; !cpuLimit.IsZero() </span><span class="cov8" title="1">{
                        totalCPULimit += float64(cpuLimit.MilliValue())
                }</span>
                <span class="cov8" title="1">if memLimit, exists := container.Resources.Limits[corev1.ResourceMemory]; exists &amp;&amp; !memLimit.IsZero() </span><span class="cov8" title="1">{
                        totalMemLimit += float64(memLimit.Value()) / (1024 * 1024) // Convert to MB
                }</span>
        }

        // If no limits are set, use requests as baseline
        <span class="cov8" title="1">if totalCPULimit == 0 || totalMemLimit == 0 </span><span class="cov8" title="1">{
                for _, container := range pod.Spec.Containers </span><span class="cov8" title="1">{
                        if totalCPULimit == 0 </span><span class="cov8" title="1">{
                                if cpuReq, exists := container.Resources.Requests[corev1.ResourceCPU]; exists &amp;&amp; !cpuReq.IsZero() </span><span class="cov8" title="1">{
                                        totalCPULimit += float64(cpuReq.MilliValue())
                                }</span>
                        }
                        <span class="cov8" title="1">if totalMemLimit == 0 </span><span class="cov8" title="1">{
                                if memReq, exists := container.Resources.Requests[corev1.ResourceMemory]; exists &amp;&amp; !memReq.IsZero() </span><span class="cov8" title="1">{
                                        totalMemLimit += float64(memReq.Value()) / (1024 * 1024)
                                }</span>
                        }
                }
        }

        // If still no resources set, default to scale up
        <span class="cov8" title="1">if totalCPULimit == 0 &amp;&amp; totalMemLimit == 0 </span><span class="cov8" title="1">{
                return ResourceScalingDecision{CPU: ScaleUp, Memory: ScaleUp}
        }</span>

        // Calculate usage percentages
        <span class="cov8" title="1">cpuUsagePercent := float64(0)
        memUsagePercent := float64(0)

        if totalCPULimit &gt; 0 </span><span class="cov8" title="1">{
                cpuUsagePercent = usage.CPUMilli / totalCPULimit
        }</span>
        <span class="cov8" title="1">if totalMemLimit &gt; 0 </span><span class="cov8" title="1">{
                memUsagePercent = usage.MemMB / totalMemLimit
        }</span>

        // Determine scaling decision for each resource independently
        <span class="cov8" title="1">cpuDecision := ScaleNone
        memoryDecision := ScaleNone

        // Check CPU scaling
        if cpuUsagePercent &gt; cfg.CPUScaleUpThreshold </span><span class="cov8" title="1">{
                cpuDecision = ScaleUp
        }</span> else<span class="cov8" title="1"> if cpuUsagePercent &lt; cfg.CPUScaleDownThreshold </span><span class="cov8" title="1">{
                cpuDecision = ScaleDown
        }</span>

        // Check Memory scaling
        <span class="cov8" title="1">if memUsagePercent &gt; cfg.MemoryScaleUpThreshold </span><span class="cov8" title="1">{
                memoryDecision = ScaleUp
        }</span> else<span class="cov8" title="1"> if memUsagePercent &lt; cfg.MemoryScaleDownThreshold </span><span class="cov8" title="1">{
                memoryDecision = ScaleDown
        }</span>

        // Don't log here to avoid duplication - logging happens in rightSizePod when resize is actually needed

        <span class="cov8" title="1">return ResourceScalingDecision{CPU: cpuDecision, Memory: memoryDecision}</span>
}

// scalingDecisionString is defined in adaptive_rightsizer.go

// calculateOptimalResourcesForContainers determines optimal resource allocation for all containers
func (r *InPlaceRightSizer) calculateOptimalResourcesForContainers(usage metrics.Metrics, pod *corev1.Pod, scalingDecision ResourceScalingDecision) map[string]corev1.ResourceRequirements <span class="cov8" title="1">{
        resourcesMap := make(map[string]corev1.ResourceRequirements)

        // For simplicity, apply the same resources to all containers based on total pod usage
        // In production, you might want per-container metrics
        numContainers := len(pod.Spec.Containers)
        if numContainers == 0 </span><span class="cov0" title="0">{
                return resourcesMap
        }</span>

        // Divide resources among containers
        <span class="cov8" title="1">cpuPerContainer := usage.CPUMilli / float64(numContainers)
        memPerContainer := usage.MemMB / float64(numContainers)

        for _, container := range pod.Spec.Containers </span><span class="cov8" title="1">{
                newResources := r.calculateOptimalResources(cpuPerContainer, memPerContainer, scalingDecision)

                // Check if we can safely apply these resources
                currentResources := container.Resources
                adjustedResources := r.adjustResourcesForSafeResize(currentResources, newResources, container.ResizePolicy)

                resourcesMap[container.Name] = adjustedResources
        }</span>

        <span class="cov8" title="1">return resourcesMap</span>
}

// calculateOptimalResources determines optimal resource allocation for a single container
func (r *InPlaceRightSizer) calculateOptimalResources(cpuMilli float64, memMB float64, scalingDecision ResourceScalingDecision) corev1.ResourceRequirements <span class="cov8" title="1">{
        cfg := config.Get()

        var cpuRequest, memRequest int64

        // Apply different multipliers based on scaling decision for each resource
        // CPU calculation
        if scalingDecision.CPU == ScaleUp </span><span class="cov8" title="1">{
                cpuRequest = int64(cpuMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        }</span> else<span class="cov8" title="1"> if scalingDecision.CPU == ScaleDown </span><span class="cov8" title="1">{
                cpuRequest = int64(cpuMilli*1.1) + cfg.CPURequestAddition
        }</span> else<span class="cov0" title="0"> {
                cpuRequest = int64(cpuMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        }</span>

        // Memory calculation
        <span class="cov8" title="1">if scalingDecision.Memory == ScaleUp </span><span class="cov8" title="1">{
                memRequest = int64(memMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition
        }</span> else<span class="cov8" title="1"> if scalingDecision.Memory == ScaleDown </span><span class="cov8" title="1">{
                memRequest = int64(memMB*1.1) + cfg.MemoryRequestAddition
        }</span> else<span class="cov0" title="0"> {
                memRequest = int64(memMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition
        }</span>

        // Ensure minimum values
        <span class="cov8" title="1">if cpuRequest &lt; cfg.MinCPURequest </span><span class="cov0" title="0">{
                cpuRequest = cfg.MinCPURequest
        }</span>
        <span class="cov8" title="1">if memRequest &lt; cfg.MinMemoryRequest </span><span class="cov0" title="0">{
                memRequest = cfg.MinMemoryRequest
        }</span>

        // Calculate limits based on requests with multipliers and additions
        <span class="cov8" title="1">cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        // Apply maximum caps
        if cpuLimit &gt; cfg.MaxCPULimit </span><span class="cov8" title="1">{
                cpuLimit = cfg.MaxCPULimit
        }</span>
        <span class="cov8" title="1">if memLimit &gt; cfg.MaxMemoryLimit </span><span class="cov8" title="1">{
                memLimit = cfg.MaxMemoryLimit
        }</span>

        <span class="cov8" title="1">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// adjustResourcesForSafeResize adjusts resources to ensure they can be safely resized
func (r *InPlaceRightSizer) adjustResourcesForSafeResize(current, desired corev1.ResourceRequirements, resizePolicy []corev1.ContainerResizePolicy) corev1.ResourceRequirements <span class="cov8" title="1">{
        adjusted := desired.DeepCopy()

        // Check if we're trying to decrease memory limits
        currentMemLimit := current.Limits[corev1.ResourceMemory]
        desiredMemLimit := desired.Limits[corev1.ResourceMemory]

        // Check if we're trying to decrease CPU limits
        currentCPULimit := current.Limits[corev1.ResourceCPU]
        desiredCPULimit := desired.Limits[corev1.ResourceCPU]

        // If current resources are not set, we can set any value
        if currentMemLimit.IsZero() &amp;&amp; currentCPULimit.IsZero() </span><span class="cov0" title="0">{
                return *adjusted
        }</span>

        // Check resize policy for memory
        <span class="cov8" title="1">memoryCanDecrease := false
        cpuCanDecrease := false

        for _, policy := range resizePolicy </span><span class="cov0" title="0">{
                if policy.ResourceName == corev1.ResourceMemory &amp;&amp; policy.RestartPolicy == corev1.RestartContainer </span><span class="cov0" title="0">{
                        memoryCanDecrease = true
                }</span>
                <span class="cov0" title="0">if policy.ResourceName == corev1.ResourceCPU &amp;&amp; policy.RestartPolicy == corev1.RestartContainer </span><span class="cov0" title="0">{
                        cpuCanDecrease = true
                }</span>
        }

        // If we're trying to decrease memory limit and it's not allowed, keep current or increase
        <span class="cov8" title="1">if !currentMemLimit.IsZero() &amp;&amp; desiredMemLimit.Cmp(currentMemLimit) &lt; 0 &amp;&amp; !memoryCanDecrease </span><span class="cov0" title="0">{
                // Keep the current limit or slightly increase it
                adjusted.Limits[corev1.ResourceMemory] = currentMemLimit

                // Adjust request to be at most half of limit
                desiredMemReq := desired.Requests[corev1.ResourceMemory]
                halfLimit := resource.NewQuantity(currentMemLimit.Value()/2, resource.BinarySI)
                if desiredMemReq.Cmp(*halfLimit) &gt; 0 </span><span class="cov0" title="0">{
                        adjusted.Requests[corev1.ResourceMemory] = *halfLimit
                }</span>
        }

        // If we're trying to decrease CPU limit and it's not allowed, keep current or increase
        <span class="cov8" title="1">if !currentCPULimit.IsZero() &amp;&amp; desiredCPULimit.Cmp(currentCPULimit) &lt; 0 &amp;&amp; !cpuCanDecrease </span><span class="cov0" title="0">{
                // Keep the current limit or slightly increase it
                adjusted.Limits[corev1.ResourceCPU] = currentCPULimit

                // Adjust request to be at most half of limit
                desiredCPUReq := desired.Requests[corev1.ResourceCPU]
                halfLimit := resource.NewMilliQuantity(currentCPULimit.MilliValue()/2, resource.DecimalSI)
                if desiredCPUReq.Cmp(*halfLimit) &gt; 0 </span><span class="cov0" title="0">{
                        adjusted.Requests[corev1.ResourceCPU] = *halfLimit
                }</span>
        }

        // Ensure requests don't exceed limits
        <span class="cov8" title="1">cpuReq := adjusted.Requests[corev1.ResourceCPU]
        cpuLim := adjusted.Limits[corev1.ResourceCPU]
        if cpuReq.Cmp(cpuLim) &gt; 0 </span><span class="cov0" title="0">{
                adjusted.Requests[corev1.ResourceCPU] = cpuLim
        }</span>

        <span class="cov8" title="1">memReq := adjusted.Requests[corev1.ResourceMemory]
        memLim := adjusted.Limits[corev1.ResourceMemory]
        if memReq.Cmp(memLim) &gt; 0 </span><span class="cov0" title="0">{
                adjusted.Requests[corev1.ResourceMemory] = memLim
        }</span>

        <span class="cov8" title="1">return *adjusted</span>
}

// needsAdjustmentWithDetails checks if pod resources need updating and returns details
func (r *InPlaceRightSizer) needsAdjustmentWithDetails(pod *corev1.Pod, newResourcesMap map[string]corev1.ResourceRequirements) (bool, map[string]ResourceChange) <span class="cov0" title="0">{
        details := make(map[string]ResourceChange)
        needsUpdate := false

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                newResources, exists := newResourcesMap[container.Name]
                if !exists </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Get current CPU and memory requests
                <span class="cov0" title="0">currentCPU := container.Resources.Requests[corev1.ResourceCPU]
                currentMem := container.Resources.Requests[corev1.ResourceMemory]
                newCPU := newResources.Requests[corev1.ResourceCPU]
                newMem := newResources.Requests[corev1.ResourceMemory]

                change := ResourceChange{
                        CurrentCPU: formatResource(currentCPU),
                        NewCPU:     formatResource(newCPU),
                        CurrentMem: formatMemory(currentMem),
                        NewMem:     formatMemory(newMem),
                }

                // Skip if current resources are not set
                if currentCPU.IsZero() || currentMem.IsZero() </span><span class="cov0" title="0">{
                        details[container.Name] = change
                        needsUpdate = true
                        continue</span>
                }

                // Calculate percentage difference
                <span class="cov0" title="0">cpuDiff := float64(newCPU.MilliValue()-currentCPU.MilliValue()) / float64(currentCPU.MilliValue()) * 100
                memDiff := float64(newMem.Value()-currentMem.Value()) / float64(currentMem.Value()) * 100

                // Only adjust if difference is more than 10%
                if (cpuDiff &gt; 10 || cpuDiff &lt; -10) || (memDiff &gt; 10 || memDiff &lt; -10) </span><span class="cov0" title="0">{
                        details[container.Name] = change
                        needsUpdate = true
                }</span>
        }

        <span class="cov0" title="0">return needsUpdate, details</span>
}

// formatResource formats a resource quantity for display
func formatResource(q resource.Quantity) string <span class="cov0" title="0">{
        if q.IsZero() </span><span class="cov0" title="0">{
                return "0"
        }</span>
        <span class="cov0" title="0">return q.String()</span>
}

// formatMemory formats memory in a human-readable way
// formatMemory is defined in adaptive_rightsizer.go

// applyInPlaceResize performs the actual in-place resource update using the resize subresource
func (r *InPlaceRightSizer) applyInPlaceResize(ctx context.Context, pod *corev1.Pod, newResourcesMap map[string]corev1.ResourceRequirements) error <span class="cov0" title="0">{
        // Validate the new resources if validator is available
        if r.Validator != nil </span><span class="cov0" title="0">{
                for containerName, newResources := range newResourcesMap </span><span class="cov0" title="0">{
                        validationResult := r.Validator.ValidateResourceChange(ctx, pod, newResources, containerName)
                        if !validationResult.Valid </span><span class="cov0" title="0">{
                                // Log validation errors and skip this pod
                                // Check if validation failed due to node resource constraints
                                hasNodeConstraint := false
                                for _, err := range validationResult.Errors </span><span class="cov0" title="0">{
                                        if strings.Contains(err, "exceeds available node capacity") ||
                                                strings.Contains(err, "exceeds node allocatable capacity") </span><span class="cov0" title="0">{
                                                hasNodeConstraint = true
                                                break</span>
                                        }
                                }

                                <span class="cov0" title="0">if hasNodeConstraint </span><span class="cov0" title="0">{
                                        logger.Info("📍 Node resource constraint for pod %s/%s container %s:",
                                                pod.Namespace, pod.Name, containerName)
                                        for _, err := range validationResult.Errors </span><span class="cov0" title="0">{
                                                logger.Info("  - %s", err)
                                        }</span>
                                        // Return a specific error message for node constraints
                                        <span class="cov0" title="0">return fmt.Errorf("exceeds available node capacity: %v", validationResult.Errors)</span>
                                } else<span class="cov0" title="0"> {
                                        logger.Warn("Skipping resize for pod %s/%s container %s due to validation errors:",
                                                pod.Namespace, pod.Name, containerName)
                                        for _, err := range validationResult.Errors </span><span class="cov0" title="0">{
                                                logger.Warn("  - %s", err)
                                        }</span>
                                }
                                // Return early - don't attempt resize if validation fails
                                <span class="cov0" title="0">return fmt.Errorf("validation failed: %v", validationResult.Errors)</span>
                        }

                        // Log any warnings but continue
                        <span class="cov0" title="0">if len(validationResult.Warnings) &gt; 0 </span><span class="cov0" title="0">{
                                logger.Warn("Validation warnings for pod %s/%s container %s:",
                                        pod.Namespace, pod.Name, containerName)
                                for _, warning := range validationResult.Warnings </span><span class="cov0" title="0">{
                                        logger.Warn("  - %s", warning)
                                }</span>
                        }
                }
        }

        // Create the resize patch - ensure we never try to remove existing resources
        <span class="cov0" title="0">containers := make([]ContainerResourcesPatch, 0, len(newResourcesMap))
        for containerName, newResources := range newResourcesMap </span><span class="cov0" title="0">{
                // Find the current container to ensure we preserve existing resource structure
                var currentResources corev1.ResourceRequirements
                for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                        if container.Name == containerName </span><span class="cov0" title="0">{
                                currentResources = container.Resources
                                break</span>
                        }
                }

                // Debug logging for resource patch issue
                <span class="cov0" title="0">logger.Info("🔧 Preparing resize patch for pod %s/%s container %s", pod.Namespace, pod.Name, containerName)
                logger.Info("   📊 Current resources - CPU Req: %s, CPU Lim: %s, Mem Req: %s, Mem Lim: %s",
                        formatResource(currentResources.Requests[corev1.ResourceCPU]),
                        formatResource(currentResources.Limits[corev1.ResourceCPU]),
                        formatMemory(currentResources.Requests[corev1.ResourceMemory]),
                        formatMemory(currentResources.Limits[corev1.ResourceMemory]))
                logger.Info("   🎯 Desired resources - CPU Req: %s, CPU Lim: %s, Mem Req: %s, Mem Lim: %s",
                        formatResource(newResources.Requests[corev1.ResourceCPU]),
                        formatResource(newResources.Limits[corev1.ResourceCPU]),
                        formatMemory(newResources.Requests[corev1.ResourceMemory]),
                        formatMemory(newResources.Limits[corev1.ResourceMemory]))

                // Ensure the patch always includes both requests and limits to prevent removal
                safeResources := ensureSafeResourcePatch(currentResources, newResources)

                logger.Info("   ✅ Safe resources - CPU Req: %s, CPU Lim: %s, Mem Req: %s, Mem Lim: %s",
                        formatResource(safeResources.Requests[corev1.ResourceCPU]),
                        formatResource(safeResources.Limits[corev1.ResourceCPU]),
                        formatMemory(safeResources.Requests[corev1.ResourceMemory]),
                        formatMemory(safeResources.Limits[corev1.ResourceMemory]))

                containers = append(containers, ContainerResourcesPatch{
                        Name:      containerName,
                        Resources: safeResources,
                })</span>
        }

        <span class="cov0" title="0">resizePatch := PodResizePatch{
                Spec: PodSpecPatch{
                        Containers: containers,
                },
        }

        // Marshal the patch
        patchData, err := json.Marshal(resizePatch)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal resize patch: %w", err)
        }</span>

        // Debug logging for the actual patch data
        <span class="cov0" title="0">logger.Info("📋 Generated resize patch for pod %s/%s:", pod.Namespace, pod.Name)
        logger.Info("   📄 Patch data: %s", string(patchData))

        // Use the Kubernetes client-go to patch with the resize subresource
        // Apply the patch using the resize subresource
        // This is the key difference - using the resize subresource endpoint
        _, err = r.ClientSet.CoreV1().Pods(pod.Namespace).Patch(
                ctx,
                pod.Name,
                types.StrategicMergePatchType,
                patchData,
                metav1.PatchOptions{},
                "resize", // This is the crucial part - specifying the resize subresource
        )

        if err != nil </span><span class="cov0" title="0">{
                // Check if error is due to forbidden decrease
                if strings.Contains(err.Error(), "Forbidden") &amp;&amp; strings.Contains(err.Error(), "cannot be decreased") </span><span class="cov0" title="0">{
                        log.Printf("⚠️  Cannot decrease resources for pod %s/%s", pod.Namespace, pod.Name)
                        log.Printf("   💡 Pod needs RestartContainer policy for decreases. Skipping resize.")
                        // Return nil to not count this as an error
                        return nil
                }</span>

                // For other errors, log and return
                <span class="cov0" title="0">log.Printf("❌ Resize failed for pod %s/%s: %v", pod.Namespace, pod.Name, err)
                return fmt.Errorf("resize failed: %w", err)</span>
        }

        // Success - logging already done in rightSizePod
        <span class="cov0" title="0">return nil</span>
}

// shouldProcessNamespace checks if a namespace should be processed based on include/exclude lists
func (r *InPlaceRightSizer) shouldProcessNamespace(namespace string) bool <span class="cov0" title="0">{
        cfg := config.Get()

        // Check exclude list first (takes precedence)
        for _, excludeNs := range cfg.NamespaceExclude </span><span class="cov0" title="0">{
                if namespace == excludeNs </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // If include list is empty, process all non-excluded namespaces
        <span class="cov0" title="0">if len(cfg.NamespaceInclude) == 0 </span><span class="cov0" title="0">{
                return true
        }</span>

        // Check if namespace is in include list
        <span class="cov0" title="0">for _, includeNs := range cfg.NamespaceInclude </span><span class="cov0" title="0">{
                if namespace == includeNs </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// fallbackPatch is deprecated as regular patches cannot modify pod resources
// ensureSafeResourcePatch ensures the patch never tries to remove or add resource fields
// Only existing resource types in the current pod can be modified
func ensureSafeResourcePatch(current, desired corev1.ResourceRequirements) corev1.ResourceRequirements <span class="cov0" title="0">{
        logger.Info("🛡️  Ensuring safe resource patch...")

        result := corev1.ResourceRequirements{}

        // Only include requests that already exist in the current pod
        if current.Requests != nil &amp;&amp; len(current.Requests) &gt; 0 </span><span class="cov0" title="0">{
                result.Requests = make(corev1.ResourceList)

                // Only update CPU request if it exists in current
                if cpuReq, exists := current.Requests[corev1.ResourceCPU]; exists </span><span class="cov0" title="0">{
                        if desiredCPU, desiredExists := desired.Requests[corev1.ResourceCPU]; desiredExists </span><span class="cov0" title="0">{
                                result.Requests[corev1.ResourceCPU] = desiredCPU
                                logger.Info("   ✅ Updating existing CPU request: %s -&gt; %s", formatResource(cpuReq), formatResource(desiredCPU))
                        }</span> else<span class="cov0" title="0"> {
                                // Keep the current value if desired doesn't specify it
                                result.Requests[corev1.ResourceCPU] = cpuReq
                                logger.Info("   🔄 Preserving existing CPU request: %s", formatResource(cpuReq))
                        }</span>
                }

                // Only update Memory request if it exists in current
                <span class="cov0" title="0">if memReq, exists := current.Requests[corev1.ResourceMemory]; exists </span><span class="cov0" title="0">{
                        if desiredMem, desiredExists := desired.Requests[corev1.ResourceMemory]; desiredExists </span><span class="cov0" title="0">{
                                result.Requests[corev1.ResourceMemory] = desiredMem
                                logger.Info("   ✅ Updating existing Memory request: %s -&gt; %s", formatMemory(memReq), formatMemory(desiredMem))
                        }</span> else<span class="cov0" title="0"> {
                                // Keep the current value if desired doesn't specify it
                                result.Requests[corev1.ResourceMemory] = memReq
                                logger.Info("   🔄 Preserving existing Memory request: %s", formatMemory(memReq))
                        }</span>
                }
        }

        // Only include limits that already exist in the current pod
        <span class="cov0" title="0">if current.Limits != nil &amp;&amp; len(current.Limits) &gt; 0 </span><span class="cov0" title="0">{
                result.Limits = make(corev1.ResourceList)

                // Only update CPU limit if it exists in current
                if cpuLim, exists := current.Limits[corev1.ResourceCPU]; exists </span><span class="cov0" title="0">{
                        if desiredCPU, desiredExists := desired.Limits[corev1.ResourceCPU]; desiredExists </span><span class="cov0" title="0">{
                                result.Limits[corev1.ResourceCPU] = desiredCPU
                                logger.Info("   ✅ Updating existing CPU limit: %s -&gt; %s", formatResource(cpuLim), formatResource(desiredCPU))
                        }</span> else<span class="cov0" title="0"> {
                                // Keep the current value if desired doesn't specify it
                                result.Limits[corev1.ResourceCPU] = cpuLim
                                logger.Info("   🔄 Preserving existing CPU limit: %s", formatResource(cpuLim))
                        }</span>
                }

                // Only update Memory limit if it exists in current
                <span class="cov0" title="0">if memLim, exists := current.Limits[corev1.ResourceMemory]; exists </span><span class="cov0" title="0">{
                        if desiredMem, desiredExists := desired.Limits[corev1.ResourceMemory]; desiredExists </span><span class="cov0" title="0">{
                                result.Limits[corev1.ResourceMemory] = desiredMem
                                logger.Info("   ✅ Updating existing Memory limit: %s -&gt; %s", formatMemory(memLim), formatMemory(desiredMem))
                        }</span> else<span class="cov0" title="0"> {
                                // Keep the current value if desired doesn't specify it
                                result.Limits[corev1.ResourceMemory] = memLim
                                logger.Info("   🔄 Preserving existing Memory limit: %s", formatMemory(memLim))
                        }</span>
                }
        }

        // Log what we're NOT including to help debug
        <span class="cov0" title="0">if desired.Requests != nil </span><span class="cov0" title="0">{
                for resType, resVal := range desired.Requests </span><span class="cov0" title="0">{
                        if _, exists := current.Requests[resType]; !exists </span><span class="cov0" title="0">{
                                logger.Info("   ⚠️  Skipping new request type %s: %s (not in current pod)", resType, formatResource(resVal))
                        }</span>
                }
        }
        <span class="cov0" title="0">if desired.Limits != nil </span><span class="cov0" title="0">{
                for resType, resVal := range desired.Limits </span><span class="cov0" title="0">{
                        if _, exists := current.Limits[resType]; !exists </span><span class="cov0" title="0">{
                                logger.Info("   ⚠️  Skipping new limit type %s: %s (not in current pod)", resType, formatResource(resVal))
                        }</span>
                }
        }

        <span class="cov0" title="0">logger.Info("✅ Safe resource patch completed")
        return result</span>
}

func (r *InPlaceRightSizer) fallbackPatch(ctx context.Context, pod *corev1.Pod, newResourcesMap map[string]corev1.ResourceRequirements) error <span class="cov0" title="0">{
        // Regular patches cannot modify pod resources after creation
        // This is a Kubernetes limitation - only the resize subresource can change resources
        return fmt.Errorf("cannot modify pod resources without resize subresource")
}</span>

// isSystemPod checks if a pod is a system/infrastructure pod
func isSystemPod(pod *corev1.Pod) bool <span class="cov0" title="0">{
        // Skip kube-system and other system namespaces
        systemNamespaces := []string{"kube-system", "kube-public", "kube-node-lease", "ingress-nginx", "cert-manager"}
        for _, ns := range systemNamespaces </span><span class="cov0" title="0">{
                if pod.Namespace == ns </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Skip the right-sizer itself
        <span class="cov0" title="0">if pod.Labels["app"] == "right-sizer" </span><span class="cov0" title="0">{
                return true
        }</span>

        // Skip pods with system-related labels
        <span class="cov0" title="0">systemLabels := []string{
                "component",
                "tier",
        }
        for _, label := range systemLabels </span><span class="cov0" title="0">{
                if value, exists := pod.Labels[label]; exists </span><span class="cov0" title="0">{
                        if value == "control-plane" || value == "etcd" || value == "kube-scheduler" || value == "kube-controller-manager" </span><span class="cov0" title="0">{
                                return true
                        }</span>
                }
        }

        // Skip metrics-server
        <span class="cov0" title="0">if pod.Labels["k8s-app"] == "metrics-server" </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov0" title="0">return false</span>
}

// SetupInPlaceRightSizer creates and starts the in-place rightsizer with Kubernetes 1.33+ support
func SetupInPlaceRightSizer(mgr manager.Manager, provider metrics.Provider) error <span class="cov0" title="0">{
        cfg := config.Get()

        // Get the rest config from the manager
        restConfig := mgr.GetConfig()

        // Create a clientset for using the resize subresource
        clientSet, err := kubernetes.NewForConfig(restConfig)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to create kubernetes clientset: %w", err)
        }</span>

        // Create resource validator
        // Note: passing nil for metrics since we don't have OperatorMetrics here
        <span class="cov0" title="0">validator := validation.NewResourceValidator(mgr.GetClient(), clientSet, cfg, nil)

        rightsizer := &amp;InPlaceRightSizer{
                Client:          mgr.GetClient(),
                ClientSet:       clientSet,
                RestConfig:      restConfig,
                MetricsProvider: provider,
                Interval:        cfg.ResizeInterval,
                Validator:       validator,
                resizeCache:     make(map[string]*ResizeDecisionCache),
                cacheExpiry:     5 * time.Minute, // Cache entries for 5 minutes
        }

        // Start the rightsizer in a goroutine
        go func() </span><span class="cov0" title="0">{
                if err := mgr.Add(manager.RunnableFunc(func(ctx context.Context) error </span><span class="cov0" title="0">{
                        return rightsizer.Start(ctx)
                }</span>)); err != nil <span class="cov0" title="0">{
                        log.Printf("Failed to add rightsizer to manager: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">log.Println("✅ In-place rightsizer setup complete with Kubernetes 1.33+ resize subresource support")
        return nil</span>
}
</pre>
		
		<pre class="file" id="file10" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package controllers

import (
        "context"
        "encoding/json"
        "fmt"
        "log"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        appsv1 "k8s.io/api/apps/v1"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/manager"
)

// NonDisruptiveRightSizer performs resource analysis and adds recommendations as annotations
// without actually modifying resources or restarting pods
type NonDisruptiveRightSizer struct {
        Client          client.Client
        MetricsProvider metrics.Provider
        Interval        time.Duration
}

// ResourceRecommendation stores recommended resource values
type ResourceRecommendation struct {
        CPURequest    string    `json:"cpu_request"`
        CPULimit      string    `json:"cpu_limit"`
        MemoryRequest string    `json:"memory_request"`
        MemoryLimit   string    `json:"memory_limit"`
        Timestamp     time.Time `json:"timestamp"`
        BasedOnPods   int       `json:"based_on_pods"`
        AvgCPUUsage   float64   `json:"avg_cpu_usage_milli"`
        AvgMemUsage   float64   `json:"avg_mem_usage_mb"`
}

// Start begins the continuous monitoring and recommendation loop
func (r *NonDisruptiveRightSizer) Start(ctx context.Context) error <span class="cov0" title="0">{
        ticker := time.NewTicker(r.Interval)
        defer ticker.Stop()

        logger.Info("Starting non-disruptive right-sizer with %v interval", r.Interval)

        // Run immediately on start
        r.analyzeAndRecommend(ctx)

        for </span><span class="cov0" title="0">{
                select </span>{
                case &lt;-ticker.C:<span class="cov0" title="0">
                        r.analyzeAndRecommend(ctx)</span>
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        log.Println("Stopping non-disruptive right-sizer")
                        return nil</span>
                }
        }
}

// analyzeAndRecommend processes all deployments and statefulsets
func (r *NonDisruptiveRightSizer) analyzeAndRecommend(ctx context.Context) <span class="cov0" title="0">{
        // Analyze deployments
        var deployList appsv1.DeploymentList
        if err := r.Client.List(ctx, &amp;deployList); err != nil </span><span class="cov0" title="0">{
                logger.Error("Error listing deployments: %v", err)
                return
        }</span>

        <span class="cov0" title="0">log.Printf("Analyzing %d deployments for right-sizing recommendations", len(deployList.Items))

        for _, deploy := range deployList.Items </span><span class="cov0" title="0">{
                if isSystemResource(deploy.Namespace, deploy.Name) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">if err := r.analyzeDeployment(ctx, &amp;deploy); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Error analyzing deployment %s/%s: %v",
                                deploy.Namespace, deploy.Name, err)
                }</span>
        }

        // Process StatefulSets
        <span class="cov0" title="0">var stsList appsv1.StatefulSetList
        if err := r.Client.List(ctx, &amp;stsList); err != nil </span><span class="cov0" title="0">{
                log.Printf("Error listing statefulsets: %v", err)
                return
        }</span>

        <span class="cov0" title="0">log.Printf("Analyzing %d statefulsets for right-sizing recommendations", len(stsList.Items))

        for _, sts := range stsList.Items </span><span class="cov0" title="0">{
                if isSystemResource(sts.Namespace, sts.Name) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">if err := r.analyzeStatefulSet(ctx, &amp;sts); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Error analyzing statefulset %s/%s: %v",
                                sts.Namespace, sts.Name, err)
                }</span>
        }

        // Also analyze individual pods for immediate feedback
        <span class="cov0" title="0">r.analyzePods(ctx)</span>
}

// analyzeDeployment analyzes a deployment and adds recommendations
func (r *NonDisruptiveRightSizer) analyzeDeployment(ctx context.Context, deploy *appsv1.Deployment) error <span class="cov0" title="0">{
        recommendation, avgMetrics, podCount := r.getResourceRecommendation(ctx, deploy.Namespace, deploy.Spec.Selector.MatchLabels)
        if recommendation == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Add recommendation as annotation
        <span class="cov0" title="0">if deploy.Annotations == nil </span><span class="cov0" title="0">{
                deploy.Annotations = make(map[string]string)
        }</span>

        <span class="cov0" title="0">cpuReq := recommendation.Requests[corev1.ResourceCPU]
        cpuLim := recommendation.Limits[corev1.ResourceCPU]
        memReq := recommendation.Requests[corev1.ResourceMemory]
        memLim := recommendation.Limits[corev1.ResourceMemory]

        recommendationData := ResourceRecommendation{
                CPURequest:    cpuReq.String(),
                CPULimit:      cpuLim.String(),
                MemoryRequest: memReq.String(),
                MemoryLimit:   memLim.String(),
                Timestamp:     time.Now(),
                BasedOnPods:   podCount,
                AvgCPUUsage:   avgMetrics.CPUMilli,
                AvgMemUsage:   avgMetrics.MemMB,
        }

        jsonData, err := json.Marshal(recommendationData)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">deploy.Annotations["right-sizer/recommendation"] = string(jsonData)
        deploy.Annotations["right-sizer/last-analysis"] = time.Now().Format(time.RFC3339)

        // Check if current resources differ significantly from recommendations
        if r.needsAdjustment(&amp;deploy.Spec.Template.Spec, recommendation) </span><span class="cov0" title="0">{
                deploy.Annotations["right-sizer/action-needed"] = "true"
                log.Printf("📊 Deployment %s/%s needs adjustment - Current: %s CPU, %s Memory | Recommended: %s CPU, %s Memory",
                        deploy.Namespace, deploy.Name,
                        getCurrentResources(&amp;deploy.Spec.Template.Spec, "cpu"),
                        getCurrentResources(&amp;deploy.Spec.Template.Spec, "memory"),
                        cpuReq.String(),
                        memReq.String())
        }</span> else<span class="cov0" title="0"> {
                deploy.Annotations["right-sizer/action-needed"] = "false"
        }</span>

        // Update the deployment annotations only
        <span class="cov0" title="0">return r.Client.Update(ctx, deploy)</span>
}

// analyzeStatefulSet analyzes a statefulset and adds recommendations
func (r *NonDisruptiveRightSizer) analyzeStatefulSet(ctx context.Context, sts *appsv1.StatefulSet) error <span class="cov0" title="0">{
        recommendation, avgMetrics, podCount := r.getResourceRecommendation(ctx, sts.Namespace, sts.Spec.Selector.MatchLabels)
        if recommendation == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        // Add recommendation as annotation
        <span class="cov0" title="0">if sts.Annotations == nil </span><span class="cov0" title="0">{
                sts.Annotations = make(map[string]string)
        }</span>

        <span class="cov0" title="0">cpuReq := recommendation.Requests[corev1.ResourceCPU]
        cpuLim := recommendation.Limits[corev1.ResourceCPU]
        memReq := recommendation.Requests[corev1.ResourceMemory]
        memLim := recommendation.Limits[corev1.ResourceMemory]

        recommendationData := ResourceRecommendation{
                CPURequest:    cpuReq.String(),
                CPULimit:      cpuLim.String(),
                MemoryRequest: memReq.String(),
                MemoryLimit:   memLim.String(),
                Timestamp:     time.Now(),
                BasedOnPods:   podCount,
                AvgCPUUsage:   avgMetrics.CPUMilli,
                AvgMemUsage:   avgMetrics.MemMB,
        }

        jsonData, err := json.Marshal(recommendationData)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        <span class="cov0" title="0">sts.Annotations["right-sizer/recommendation"] = string(jsonData)
        sts.Annotations["right-sizer/last-analysis"] = time.Now().Format(time.RFC3339)

        // Check if current resources differ significantly from recommendations
        if r.needsAdjustment(&amp;sts.Spec.Template.Spec, recommendation) </span><span class="cov0" title="0">{
                sts.Annotations["right-sizer/action-needed"] = "true"
                log.Printf("📊 StatefulSet %s/%s needs adjustment - Current: %s CPU, %s Memory | Recommended: %s CPU, %s Memory",
                        sts.Namespace, sts.Name,
                        getCurrentResources(&amp;sts.Spec.Template.Spec, "cpu"),
                        getCurrentResources(&amp;sts.Spec.Template.Spec, "memory"),
                        cpuReq.String(),
                        memReq.String())
        }</span> else<span class="cov0" title="0"> {
                sts.Annotations["right-sizer/action-needed"] = "false"
        }</span>

        // Update the statefulset annotations only
        <span class="cov0" title="0">return r.Client.Update(ctx, sts)</span>
}

// analyzePods adds recommendations directly to pod annotations
func (r *NonDisruptiveRightSizer) analyzePods(ctx context.Context) <span class="cov0" title="0">{
        var podList corev1.PodList
        if err := r.Client.List(ctx, &amp;podList); err != nil </span><span class="cov0" title="0">{
                log.Printf("Error listing pods: %v", err)
                return
        }</span>

        <span class="cov0" title="0">for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase != corev1.PodRunning || isSystemResource(pod.Namespace, pod.Name) </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">recommendation := r.calculateOptimalResources(usage)

                // Update pod annotations with recommendations
                if pod.Annotations == nil </span><span class="cov0" title="0">{
                        pod.Annotations = make(map[string]string)
                }</span>

                <span class="cov0" title="0">cpuRec := recommendation.Requests[corev1.ResourceCPU]
                memRec := recommendation.Requests[corev1.ResourceMemory]

                pod.Annotations["right-sizer/cpu-usage"] = fmt.Sprintf("%.0fm", usage.CPUMilli)
                pod.Annotations["right-sizer/memory-usage"] = fmt.Sprintf("%.0fMi", usage.MemMB)
                pod.Annotations["right-sizer/cpu-recommendation"] = cpuRec.String()
                pod.Annotations["right-sizer/memory-recommendation"] = memRec.String()
                pod.Annotations["right-sizer/last-check"] = time.Now().Format(time.RFC3339)

                // Update the pod annotations
                if err := r.Client.Update(ctx, &amp;pod); err != nil </span><span class="cov0" title="0">{
                        log.Printf("Error updating pod annotations %s/%s: %v", pod.Namespace, pod.Name, err)
                }</span>
        }
}

// getResourceRecommendation calculates recommendations based on pod metrics
func (r *NonDisruptiveRightSizer) getResourceRecommendation(ctx context.Context, namespace string, labels map[string]string) (*corev1.ResourceRequirements, metrics.Metrics, int) <span class="cov0" title="0">{
        var podList corev1.PodList
        matchLabels := client.MatchingLabels(labels)
        if err := r.Client.List(ctx, &amp;podList, matchLabels, client.InNamespace(namespace)); err != nil </span><span class="cov0" title="0">{
                return nil, metrics.Metrics{}, 0
        }</span>

        <span class="cov0" title="0">if len(podList.Items) == 0 </span><span class="cov0" title="0">{
                return nil, metrics.Metrics{}, 0
        }</span>

        // Calculate average metrics across all pods
        <span class="cov0" title="0">totalCPU := 0.0
        totalMem := 0.0
        validPods := 0

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">totalCPU += usage.CPUMilli
                totalMem += usage.MemMB
                validPods++</span>
        }

        <span class="cov0" title="0">if validPods == 0 </span><span class="cov0" title="0">{
                return nil, metrics.Metrics{}, 0
        }</span>

        <span class="cov0" title="0">avgMetrics := metrics.Metrics{
                CPUMilli: totalCPU / float64(validPods),
                MemMB:    totalMem / float64(validPods),
        }

        recommendation := r.calculateOptimalResources(avgMetrics)
        return &amp;recommendation, avgMetrics, validPods</span>
}

// calculateOptimalResources determines optimal resource allocation
func (r *NonDisruptiveRightSizer) calculateOptimalResources(usage metrics.Metrics) corev1.ResourceRequirements <span class="cov0" title="0">{
        cfg := config.Get()

        // Add buffer for requests using configurable multipliers and additions
        cpuRequest := int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        memRequest := int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition

        // Ensure minimum values
        if cpuRequest &lt; cfg.MinCPURequest </span><span class="cov0" title="0">{
                cpuRequest = cfg.MinCPURequest
        }</span>
        <span class="cov0" title="0">if memRequest &lt; cfg.MinMemoryRequest </span><span class="cov0" title="0">{
                memRequest = cfg.MinMemoryRequest
        }</span>

        // Calculate limits based on requests with multipliers and additions
        <span class="cov0" title="0">cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        // Apply maximum caps
        if cpuLimit &gt; cfg.MaxCPULimit </span><span class="cov0" title="0">{
                cpuLimit = cfg.MaxCPULimit
        }</span>
        <span class="cov0" title="0">if memLimit &gt; cfg.MaxMemoryLimit </span><span class="cov0" title="0">{
                memLimit = cfg.MaxMemoryLimit
        }</span>

        <span class="cov0" title="0">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// needsAdjustment checks if resources need updating
func (r *NonDisruptiveRightSizer) needsAdjustment(podSpec *corev1.PodSpec, newResources *corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        if len(podSpec.Containers) == 0 || newResources == nil </span><span class="cov0" title="0">{
                return false
        }</span>

        // Check first container (main container)
        <span class="cov0" title="0">container := podSpec.Containers[0]

        // Get current CPU and memory requests
        currentCPU := container.Resources.Requests[corev1.ResourceCPU]
        currentMem := container.Resources.Requests[corev1.ResourceMemory]
        newCPU := newResources.Requests[corev1.ResourceCPU]
        newMem := newResources.Requests[corev1.ResourceMemory]

        // Skip if current resources are not set
        if currentCPU.IsZero() || currentMem.IsZero() </span><span class="cov0" title="0">{
                return true
        }</span>

        // Calculate percentage difference
        <span class="cov0" title="0">cpuDiff := float64(newCPU.MilliValue()-currentCPU.MilliValue()) / float64(currentCPU.MilliValue()) * 100
        memDiff := float64(newMem.Value()-currentMem.Value()) / float64(currentMem.Value()) * 100

        // Only flag as needing adjustment if difference is more than 15%
        threshold := 15.0
        return (cpuDiff &gt; threshold || cpuDiff &lt; -threshold) || (memDiff &gt; threshold || memDiff &lt; -threshold)</span>
}

// getCurrentResources returns current resource values as string
func getCurrentResources(podSpec *corev1.PodSpec, resourceType string) string <span class="cov0" title="0">{
        if len(podSpec.Containers) == 0 </span><span class="cov0" title="0">{
                return "not set"
        }</span>

        <span class="cov0" title="0">container := podSpec.Containers[0]
        if resourceType == "cpu" </span><span class="cov0" title="0">{
                if cpu, ok := container.Resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        return cpu.String()
                }</span>
        } else<span class="cov0" title="0"> if resourceType == "memory" </span><span class="cov0" title="0">{
                if mem, ok := container.Resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        return mem.String()
                }</span>
        }
        <span class="cov0" title="0">return "not set"</span>
}

// isSystemResource checks if a resource is a system/infrastructure resource
func isSystemResource(namespace, name string) bool <span class="cov0" title="0">{
        systemNamespaces := []string{"kube-system", "kube-public", "kube-node-lease"}
        for _, ns := range systemNamespaces </span><span class="cov0" title="0">{
                if namespace == ns </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        // Skip the right-sizer itself
        <span class="cov0" title="0">if name == "right-sizer" </span><span class="cov0" title="0">{
                return true
        }</span>

        <span class="cov0" title="0">return false</span>
}

// SetupNonDisruptiveRightSizer creates and starts the non-disruptive rightsizer
func SetupNonDisruptiveRightSizer(mgr manager.Manager, provider metrics.Provider) error <span class="cov0" title="0">{
        cfg := config.Get()
        rightsizer := &amp;NonDisruptiveRightSizer{
                Client:          mgr.GetClient(),
                MetricsProvider: provider,
                Interval:        cfg.ResizeInterval,
        }

        // Start the rightsizer in a goroutine
        go func() </span><span class="cov0" title="0">{
                if err := mgr.Add(manager.RunnableFunc(func(ctx context.Context) error </span><span class="cov0" title="0">{
                        return rightsizer.Start(ctx)
                }</span>)); err != nil <span class="cov0" title="0">{
                        log.Printf("Failed to add non-disruptive rightsizer to manager: %v", err)
                }</span>
        }()

        <span class="cov0" title="0">log.Println("Non-disruptive right-sizer initialized - will add recommendations as annotations without restarting pods")
        return nil</span>
}
</pre>
		
		<pre class="file" id="file11" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package controllers

import (
        "bytes"
        "context"
        "encoding/json"
        "fmt"
        "math"
        "net/http"
        "net/smtp"
        "time"

        "right-sizer/audit"
        "right-sizer/config"
        "right-sizer/health"
        "right-sizer/logger"
        "right-sizer/metrics"
        "right-sizer/retry"
        "right-sizer/validation"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/client-go/kubernetes"
        "k8s.io/klog/v2"
        metricsv1beta1 "k8s.io/metrics/pkg/apis/metrics/v1beta1"
        metricsclient "k8s.io/metrics/pkg/client/clientset/versioned"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/controller"
        "sigs.k8s.io/controller-runtime/pkg/reconcile"
)

// PodMemoryController handles pod reconciliation with memory metrics focus
type PodMemoryController struct {
        client.Client
        Clientset         *kubernetes.Clientset
        MetricsClient     *metricsclient.Clientset
        Scheme            *runtime.Scheme
        Config            *config.Config
        ResourceValidator *validation.ResourceValidator
        AuditLogger       *audit.AuditLogger
        HealthChecker     *health.OperatorHealthChecker
        OperatorMetrics   *metrics.OperatorMetrics
        MemoryMetrics     *metrics.MemoryMetrics
        RetryManager      *retry.RetryManager

        // Memory tracking
        memoryHistory     map[string][]float64 // namespace/pod/container -&gt; memory samples
        lastPressureCheck map[string]time.Time // namespace/pod/container -&gt; last check time
}

// NewPodMemoryController creates a new controller with memory metrics
func NewPodMemoryController(
        client client.Client,
        clientset *kubernetes.Clientset,
        scheme *runtime.Scheme,
        config *config.Config,
        resourceValidator *validation.ResourceValidator,
        auditLogger *audit.AuditLogger,
        healthChecker *health.OperatorHealthChecker,
        operatorMetrics *metrics.OperatorMetrics,
        memoryMetrics *metrics.MemoryMetrics,
        retryManager *retry.RetryManager,
) *PodMemoryController <span class="cov0" title="0">{

        // Create metrics client for memory metrics collection
        metricsClient, err := metricsclient.NewForConfig(ctrl.GetConfigOrDie())
        if err != nil </span><span class="cov0" title="0">{
                klog.Warningf("Failed to create metrics client: %v", err)
        }</span>

        <span class="cov0" title="0">return &amp;PodMemoryController{
                Client:            client,
                Clientset:         clientset,
                MetricsClient:     metricsClient,
                Scheme:            scheme,
                Config:            config,
                ResourceValidator: resourceValidator,
                AuditLogger:       auditLogger,
                HealthChecker:     healthChecker,
                OperatorMetrics:   operatorMetrics,
                MemoryMetrics:     memoryMetrics,
                RetryManager:      retryManager,
                memoryHistory:     make(map[string][]float64),
                lastPressureCheck: make(map[string]time.Time),
        }</span>
}

// Reconcile processes a pod for memory optimization
func (r *PodMemoryController) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) <span class="cov0" title="0">{
        startTime := time.Now()
        logger.Debug("[MEMORY_CONTROLLER] Reconciling pod: %s/%s", req.Namespace, req.Name)

        // Update health status
        r.HealthChecker.UpdateComponentStatus("memory-controller", true, "Memory controller is healthy")

        // Get the pod
        pod := &amp;corev1.Pod{}
        err := r.Get(ctx, req.NamespacedName, pod)
        if err != nil </span><span class="cov0" title="0">{
                if client.IgnoreNotFound(err) != nil </span><span class="cov0" title="0">{
                        logger.Error("[MEMORY_CONTROLLER] Failed to get pod: %v", err)
                        r.OperatorMetrics.RecordProcessingError(req.Namespace, req.Name, "get_failed")
                }</span>
                <span class="cov0" title="0">return reconcile.Result{}, client.IgnoreNotFound(err)</span>
        }

        // Skip if pod is being deleted
        <span class="cov0" title="0">if !pod.DeletionTimestamp.IsZero() </span><span class="cov0" title="0">{
                logger.Debug("[MEMORY_CONTROLLER] Pod %s/%s is being deleted, skipping", req.Namespace, req.Name)
                return reconcile.Result{}, nil
        }</span>

        // Skip if pod is not running
        <span class="cov0" title="0">if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                logger.Debug("[MEMORY_CONTROLLER] Pod %s/%s is not running (phase: %s), skipping",
                        req.Namespace, req.Name, pod.Status.Phase)
                return reconcile.Result{}, nil
        }</span>

        // Process memory metrics for the pod
        <span class="cov0" title="0">if err := r.processMemoryMetrics(ctx, pod); err != nil </span><span class="cov0" title="0">{
                logger.Error("[MEMORY_CONTROLLER] Failed to process memory metrics for %s/%s: %v",
                        req.Namespace, req.Name, err)
                r.OperatorMetrics.RecordProcessingError(req.Namespace, req.Name, "metrics_processing_failed")
        }</span>

        // Check memory pressure and make recommendations
        <span class="cov0" title="0">recommendations, err := r.analyzeMemoryAndRecommend(ctx, pod)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("[MEMORY_CONTROLLER] Failed to analyze memory for %s/%s: %v",
                        req.Namespace, req.Name, err)
                return reconcile.Result{RequeueAfter: 1 * time.Minute}, nil
        }</span>

        // Apply recommendations if needed
        <span class="cov0" title="0">if len(recommendations) &gt; 0 </span><span class="cov0" title="0">{
                if err := r.applyMemoryRecommendations(ctx, pod, recommendations); err != nil </span><span class="cov0" title="0">{
                        logger.Error("[MEMORY_CONTROLLER] Failed to apply recommendations for %s/%s: %v",
                                req.Namespace, req.Name, err)
                        r.OperatorMetrics.RecordProcessingError(req.Namespace, req.Name, "apply_failed")
                }</span>
        }

        // Record processing duration
        <span class="cov0" title="0">r.OperatorMetrics.RecordProcessingDuration("memory_reconcile", time.Since(startTime))

        // Requeue for periodic checks
        return reconcile.Result{RequeueAfter: 30 * time.Second}, nil</span>
}

// processMemoryMetrics collects and records memory metrics for a pod
func (r *PodMemoryController) processMemoryMetrics(ctx context.Context, pod *corev1.Pod) error <span class="cov0" title="0">{
        if r.MetricsClient == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("metrics client not available")
        }</span>

        // Get pod metrics from metrics-server
        <span class="cov0" title="0">podMetrics, err := r.MetricsClient.MetricsV1beta1().PodMetricses(pod.Namespace).Get(ctx, pod.Name, metav1.GetOptions{})
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to get pod metrics: %w", err)
        }</span>

        // Process each container
        <span class="cov0" title="0">for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Find matching container metrics
                var containerMetrics *metricsv1beta1.ContainerMetrics
                for _, cm := range podMetrics.Containers </span><span class="cov0" title="0">{
                        if cm.Name == container.Name </span><span class="cov0" title="0">{
                                containerMetrics = &amp;cm
                                break</span>
                        }
                }

                <span class="cov0" title="0">if containerMetrics == nil </span><span class="cov0" title="0">{
                        logger.Warn("[MEMORY_METRICS] No metrics found for container %s/%s/%s",
                                pod.Namespace, pod.Name, container.Name)
                        continue</span>
                }

                // Extract memory metrics
                <span class="cov0" title="0">memoryUsage := containerMetrics.Usage[corev1.ResourceMemory]
                memoryBytes := float64(memoryUsage.Value())

                // Get container limits and requests
                var limitBytes, requestBytes float64
                if limit, ok := container.Resources.Limits[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        limitBytes = float64(limit.Value())
                }</span>
                <span class="cov0" title="0">if request, ok := container.Resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        requestBytes = float64(request.Value())
                }</span>

                // Calculate additional memory metrics (simulated for now)
                <span class="cov0" title="0">workingSetBytes := memoryBytes * 0.85 // Approximate working set as 85% of usage
                rssBytes := memoryBytes * 0.75        // Approximate RSS as 75% of usage
                cacheBytes := memoryBytes * 0.15      // Approximate cache as 15% of usage
                swapBytes := 0.0                      // Swap is typically 0 in containers

                // Update Prometheus metrics
                r.MemoryMetrics.UpdatePodMemoryMetrics(
                        pod.Namespace, pod.Name, container.Name,
                        memoryBytes, workingSetBytes, rssBytes, cacheBytes, swapBytes,
                        limitBytes, requestBytes,
                )

                // Track memory history
                historyKey := fmt.Sprintf("%s/%s/%s", pod.Namespace, pod.Name, container.Name)
                r.trackMemoryHistory(historyKey, memoryBytes)

                // Detect and log memory pressure
                pressureLevel := r.MemoryMetrics.DetectAndRecordMemoryPressure(
                        pod.Namespace, pod.Name, container.Name,
                        memoryBytes, limitBytes,
                )

                // Log memory allocation info
                if pressureLevel != metrics.MemoryPressureNone </span><span class="cov0" title="0">{
                        metrics.LogMemoryAllocation(pod.Namespace, pod.Name, container.Name,
                                requestBytes, limitBytes, memoryBytes)
                }</span>

                // Check for potential memory leak
                <span class="cov0" title="0">if history, ok := r.memoryHistory[historyKey]; ok &amp;&amp; len(history) &gt; 10 </span><span class="cov0" title="0">{
                        pattern := metrics.AnalyzeMemoryPattern(pod.Namespace, pod.Name, container.Name, history)
                        if pattern == "potential_leak" </span><span class="cov0" title="0">{
                                logger.Warn("[MEMORY_LEAK] Potential memory leak detected in %s/%s/%s",
                                        pod.Namespace, pod.Name, container.Name)
                                r.MemoryMetrics.RecordMemoryThrottling(pod.Namespace, pod.Name, container.Name)
                        }</span>
                }

                // Check if we should alert on memory pressure
                <span class="cov0" title="0">r.checkMemoryPressureAlert(pod.Namespace, pod.Name, container.Name, pressureLevel)</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// analyzeMemoryAndRecommend analyzes memory usage and provides recommendations
func (r *PodMemoryController) analyzeMemoryAndRecommend(ctx context.Context, pod *corev1.Pod) ([]ContainerRecommendation, error) <span class="cov0" title="0">{
        var recommendations []ContainerRecommendation

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                historyKey := fmt.Sprintf("%s/%s/%s", pod.Namespace, pod.Name, container.Name)
                history, ok := r.memoryHistory[historyKey]
                if !ok || len(history) &lt; 3 </span><span class="cov0" title="0">{
                        // Not enough data to make recommendations
                        continue</span>
                }

                // Calculate statistics
                <span class="cov0" title="0">var sum, max, p95 float64
                for _, v := range history </span><span class="cov0" title="0">{
                        sum += v
                        if v &gt; max </span><span class="cov0" title="0">{
                                max = v
                        }</span>
                }
                <span class="cov0" title="0">avg := sum / float64(len(history))

                // Calculate 95th percentile
                if len(history) &gt; 20 </span><span class="cov0" title="0">{
                        sortedHistory := make([]float64, len(history))
                        copy(sortedHistory, history)
                        // Simple bubble sort for small arrays
                        for i := 0; i &lt; len(sortedHistory); i++ </span><span class="cov0" title="0">{
                                for j := i + 1; j &lt; len(sortedHistory); j++ </span><span class="cov0" title="0">{
                                        if sortedHistory[i] &gt; sortedHistory[j] </span><span class="cov0" title="0">{
                                                sortedHistory[i], sortedHistory[j] = sortedHistory[j], sortedHistory[i]
                                        }</span>
                                }
                        }
                        <span class="cov0" title="0">p95Index := int(float64(len(sortedHistory)) * 0.95)
                        p95 = sortedHistory[p95Index]</span>
                } else<span class="cov0" title="0"> {
                        p95 = max
                }</span>

                // Get current limits and requests
                <span class="cov0" title="0">currentRequest := container.Resources.Requests[corev1.ResourceMemory]
                currentLimit := container.Resources.Limits[corev1.ResourceMemory]

                // Calculate recommendations based on p95 with buffer
                recommendedRequest := int64(p95 * 1.1) // 10% buffer over p95
                recommendedLimit := int64(p95 * 1.5)   // 50% buffer over p95

                // Apply minimum thresholds
                minRequest := int64(32 * 1024 * 1024) // 32Mi minimum
                minLimit := int64(64 * 1024 * 1024)   // 64Mi minimum
                if recommendedRequest &lt; minRequest </span><span class="cov0" title="0">{
                        recommendedRequest = minRequest
                }</span>
                <span class="cov0" title="0">if recommendedLimit &lt; minLimit </span><span class="cov0" title="0">{
                        recommendedLimit = minLimit
                }</span>

                // Check if changes are significant enough (&gt;10% change)
                <span class="cov0" title="0">currentRequestBytes := currentRequest.Value()
                currentLimitBytes := currentLimit.Value()

                requestChange := math.Abs(float64(recommendedRequest-currentRequestBytes)) / float64(currentRequestBytes)
                limitChange := math.Abs(float64(recommendedLimit-currentLimitBytes)) / float64(currentLimitBytes)

                if requestChange &gt; 0.1 || limitChange &gt; 0.1 </span><span class="cov0" title="0">{
                        recommendation := ContainerRecommendation{
                                ContainerName:      container.Name,
                                RecommendedRequest: *resource.NewQuantity(recommendedRequest, resource.BinarySI),
                                RecommendedLimit:   *resource.NewQuantity(recommendedLimit, resource.BinarySI),
                                CurrentRequest:     currentRequest,
                                CurrentLimit:       currentLimit,
                                Reason:             fmt.Sprintf("Based on p95 usage: %.2fMi", p95/1024/1024),
                        }
                        recommendations = append(recommendations, recommendation)

                        // Record the recommendation in metrics
                        r.MemoryMetrics.RecordMemoryRecommendation(
                                pod.Namespace, pod.Name, container.Name, "request",
                                float64(recommendedRequest), float64(currentRequestBytes),
                        )
                        r.MemoryMetrics.RecordMemoryRecommendation(
                                pod.Namespace, pod.Name, container.Name, "limit",
                                float64(recommendedLimit), float64(currentLimitBytes),
                        )

                        // Log the recommendation
                        metrics.LogMemoryRecommendation(
                                pod.Namespace, pod.Name, container.Name,
                                float64(currentRequestBytes), float64(recommendedRequest),
                                recommendation.Reason,
                        )
                }</span>

                // Update memory trend metrics
                <span class="cov0" title="0">if len(history) &gt; 5 </span><span class="cov0" title="0">{
                        slope := r.calculateTrend(history)
                        r.MemoryMetrics.UpdateMemoryTrend(
                                pod.Namespace, pod.Name, container.Name,
                                slope, max, avg, "5m",
                        )
                }</span>
        }

        <span class="cov0" title="0">return recommendations, nil</span>
}

// applyMemoryRecommendations applies memory sizing recommendations to a pod
func (r *PodMemoryController) applyMemoryRecommendations(ctx context.Context, pod *corev1.Pod, recommendations []ContainerRecommendation) error <span class="cov0" title="0">{
        startTime := time.Now()

        if r.Config.DryRun </span><span class="cov0" title="0">{
                logger.Info("[MEMORY_CONTROLLER] DRY RUN: Would resize pod %s/%s", pod.Namespace, pod.Name)
                for _, rec := range recommendations </span><span class="cov0" title="0">{
                        logger.Info("[MEMORY_CONTROLLER] DRY RUN: Container %s: Memory %s -&gt; %s",
                                rec.ContainerName,
                                metrics.FormatMemorySize(float64(rec.CurrentRequest.Value())),
                                metrics.FormatMemorySize(float64(rec.RecommendedRequest.Value())))
                }</span>
                <span class="cov0" title="0">return nil</span>
        }

        // Apply the recommendations
        <span class="cov0" title="0">updatedPod := pod.DeepCopy()
        for _, rec := range recommendations </span><span class="cov0" title="0">{
                for i, container := range updatedPod.Spec.Containers </span><span class="cov0" title="0">{
                        if container.Name == rec.ContainerName </span><span class="cov0" title="0">{
                                updatedPod.Spec.Containers[i].Resources.Requests[corev1.ResourceMemory] = rec.RecommendedRequest
                                updatedPod.Spec.Containers[i].Resources.Limits[corev1.ResourceMemory] = rec.RecommendedLimit

                                // Record the resize operation
                                direction := "up"
                                if rec.RecommendedRequest.Value() &lt; rec.CurrentRequest.Value() </span><span class="cov0" title="0">{
                                        direction = "down"
                                }</span>
                                <span class="cov0" title="0">r.MemoryMetrics.RecordMemoryResize(
                                        pod.Namespace, pod.Name, container.Name,
                                        direction, "pending",
                                )</span>
                        }
                }
        }

        // Attempt to update the pod (in-place resize)
        <span class="cov0" title="0">err := r.RetryManager.RetryWithBackoff(func() error </span><span class="cov0" title="0">{
                return r.Update(ctx, updatedPod)
        }</span>)

        <span class="cov0" title="0">if err != nil </span><span class="cov0" title="0">{
                logger.Error("[MEMORY_CONTROLLER] Failed to update pod %s/%s: %v", pod.Namespace, pod.Name, err)
                for _, rec := range recommendations </span><span class="cov0" title="0">{
                        r.MemoryMetrics.RecordMemoryResize(
                                pod.Namespace, pod.Name, rec.ContainerName,
                                "up", "failed",
                        )
                }</span>
                <span class="cov0" title="0">return err</span>
        }

        // Success
        <span class="cov0" title="0">logger.Success("[MEMORY_CONTROLLER] Successfully resized pod %s/%s", pod.Namespace, pod.Name)
        for _, rec := range recommendations </span><span class="cov0" title="0">{
                direction := "up"
                if rec.RecommendedRequest.Value() &lt; rec.CurrentRequest.Value() </span><span class="cov0" title="0">{
                        direction = "down"
                }</span>
                <span class="cov0" title="0">r.MemoryMetrics.RecordMemoryResize(
                        pod.Namespace, pod.Name, rec.ContainerName,
                        direction, "success",
                )

                // Audit log the change
                if r.AuditLogger != nil </span><span class="cov0" title="0">{
                        oldResources := corev1.ResourceRequirements{
                                Requests: corev1.ResourceList{
                                        corev1.ResourceMemory: rec.CurrentRequest,
                                },
                        }
                        newResources := corev1.ResourceRequirements{
                                Requests: corev1.ResourceList{
                                        corev1.ResourceMemory: rec.RecommendedRequest,
                                },
                        }
                        r.AuditLogger.LogResourceChange(
                                ctx,
                                pod,
                                rec.ContainerName,
                                oldResources,
                                newResources,
                                "resize",
                                rec.Reason,
                                "success",
                                time.Since(startTime),
                                nil,
                        )
                }</span>
        }

        <span class="cov0" title="0">r.OperatorMetrics.RecordPodResized(pod.Namespace, pod.Name, "", "memory")

        return nil</span>
}

// trackMemoryHistory maintains a rolling window of memory usage samples
func (r *PodMemoryController) trackMemoryHistory(key string, value float64) <span class="cov0" title="0">{
        const maxHistorySize = 100

        if _, ok := r.memoryHistory[key]; !ok </span><span class="cov0" title="0">{
                r.memoryHistory[key] = []float64{}
        }</span>

        <span class="cov0" title="0">r.memoryHistory[key] = append(r.memoryHistory[key], value)

        // Keep only the last maxHistorySize samples
        if len(r.memoryHistory[key]) &gt; maxHistorySize </span><span class="cov0" title="0">{
                r.memoryHistory[key] = r.memoryHistory[key][1:]
        }</span>
}

// calculateTrend calculates the trend slope for memory usage
func (r *PodMemoryController) calculateTrend(samples []float64) float64 <span class="cov0" title="0">{
        if len(samples) &lt; 2 </span><span class="cov0" title="0">{
                return 0
        }</span>

        // Simple linear regression
        <span class="cov0" title="0">var sumX, sumY, sumXY, sumX2 float64
        n := float64(len(samples))

        for i, y := range samples </span><span class="cov0" title="0">{
                x := float64(i)
                sumX += x
                sumY += y
                sumXY += x * y
                sumX2 += x * x
        }</span>

        <span class="cov0" title="0">denominator := n*sumX2 - sumX*sumX
        if denominator == 0 </span><span class="cov0" title="0">{
                return 0
        }</span>

        <span class="cov0" title="0">slope := (n*sumXY - sumX*sumY) / denominator
        return slope</span>
}

// checkMemoryPressureAlert checks if we should alert on memory pressure
func (r *PodMemoryController) checkMemoryPressureAlert(namespace, pod, container string, level metrics.MemoryPressureLevel) <span class="cov0" title="0">{
        key := fmt.Sprintf("%s/%s/%s", namespace, pod, container)
        lastCheck, exists := r.lastPressureCheck[key]

        // Alert if pressure is high/critical and we haven't alerted recently
        if level &gt;= metrics.MemoryPressureHigh </span><span class="cov0" title="0">{
                if !exists || time.Since(lastCheck) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                        logger.Error("[MEMORY_ALERT] High memory pressure detected for %s: %s", key, level.String())
                        r.lastPressureCheck[key] = time.Now()

                        // Send notification if configured
                        if r.Config.NotificationConfig != nil &amp;&amp; r.Config.NotificationConfig.EnableNotifications </span><span class="cov0" title="0">{
                                message := fmt.Sprintf("🚨 High memory pressure detected for %s: %s", key, level.String())
                                if err := r.sendNotification(message); err != nil </span><span class="cov0" title="0">{
                                        logger.Warn("[MEMORY_NOTIFICATION] Failed to send notification: %v", err)
                                }</span> else<span class="cov0" title="0"> {
                                        logger.Info("[MEMORY_NOTIFICATION] Notification sent for %s", key)
                                }</span>
                        }
                }
        }
}

// sendNotification sends a notification using configured channels
func (r *PodMemoryController) sendNotification(message string) error <span class="cov0" title="0">{
        if r.Config.NotificationConfig == nil </span><span class="cov0" title="0">{
                return fmt.Errorf("notification config not available")
        }</span>

        <span class="cov0" title="0">var lastErr error

        // Send Slack notification if configured
        if r.Config.NotificationConfig.SlackWebhookURL != "" </span><span class="cov0" title="0">{
                if err := r.sendSlackNotification(message); err != nil </span><span class="cov0" title="0">{
                        logger.Warn("[NOTIFICATION] Slack notification failed: %v", err)
                        lastErr = err
                }</span>
        }

        // Send email notification if configured
        <span class="cov0" title="0">if len(r.Config.NotificationConfig.EmailRecipients) &gt; 0 &amp;&amp; r.Config.NotificationConfig.SMTPHost != "" </span><span class="cov0" title="0">{
                if err := r.sendEmailNotification(message); err != nil </span><span class="cov0" title="0">{
                        logger.Warn("[NOTIFICATION] Email notification failed: %v", err)
                        lastErr = err
                }</span>
        }

        <span class="cov0" title="0">return lastErr</span>
}

// sendSlackNotification sends a notification to Slack
func (r *PodMemoryController) sendSlackNotification(message string) error <span class="cov0" title="0">{
        payload := map[string]string{
                "text": message,
        }
        jsonPayload, err := json.Marshal(payload)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to marshal Slack payload: %w", err)
        }</span>

        <span class="cov0" title="0">resp, err := http.Post(r.Config.NotificationConfig.SlackWebhookURL, "application/json", bytes.NewBuffer(jsonPayload))
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to send Slack notification: %w", err)
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode != http.StatusOK </span><span class="cov0" title="0">{
                return fmt.Errorf("Slack notification failed with status: %d", resp.StatusCode)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// sendEmailNotification sends a notification via email
func (r *PodMemoryController) sendEmailNotification(message string) error <span class="cov0" title="0">{
        // Simple email implementation - in production, use a proper email library
        auth := smtp.PlainAuth("", r.Config.NotificationConfig.SMTPUsername, r.Config.NotificationConfig.SMTPPassword, r.Config.NotificationConfig.SMTPHost)

        subject := "Right-Sizer Memory Pressure Alert"
        body := fmt.Sprintf("Subject: %s\r\n\r\n%s\r\n", subject, message)

        for _, recipient := range r.Config.NotificationConfig.EmailRecipients </span><span class="cov0" title="0">{
                err := smtp.SendMail(
                        fmt.Sprintf("%s:%d", r.Config.NotificationConfig.SMTPHost, r.Config.NotificationConfig.SMTPPort),
                        auth,
                        r.Config.NotificationConfig.SMTPUsername, // from
                        []string{recipient},
                        []byte(body),
                )
                if err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("failed to send email to %s: %w", recipient, err)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// ContainerRecommendation holds memory sizing recommendations for a container
type ContainerRecommendation struct {
        ContainerName      string
        RecommendedRequest resource.Quantity
        RecommendedLimit   resource.Quantity
        CurrentRequest     resource.Quantity
        CurrentLimit       resource.Quantity
        Reason             string
}

// SetupWithManager sets up the controller with the manager
func (r *PodMemoryController) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;corev1.Pod{}).
                WithOptions(controller.Options{
                        MaxConcurrentReconciles: r.Config.MaxConcurrentReconciles,
                }).
                Complete(r)
}</span>
</pre>
		
		<pre class="file" id="file12" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package controllers

import (
        "context"
        "fmt"
        "time"

        "right-sizer/config"
        "right-sizer/metrics"

        appsv1 "k8s.io/api/apps/v1"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/manager"
        "sigs.k8s.io/controller-runtime/pkg/reconcile"
)

// RightSizer reconciles Pods and updates parent controller resource requests/limits
type RightSizer struct {
        client.Client
        MetricsProvider metrics.Provider
}

// Reconcile is called periodically for each Pod
func (r *RightSizer) Reconcile(ctx context.Context, req reconcile.Request) (reconcile.Result, error) <span class="cov0" title="0">{
        var pod corev1.Pod
        if err := r.Get(ctx, req.NamespacedName, &amp;pod); err != nil </span><span class="cov0" title="0">{
                return reconcile.Result{}, client.IgnoreNotFound(err)
        }</span>

        <span class="cov0" title="0">ns := pod.Namespace
        cfg := config.Get()
        // If NamespaceInclude is set, only monitor those
        if len(cfg.NamespaceInclude) &gt; 0 </span><span class="cov0" title="0">{
                found := false
                for _, incl := range cfg.NamespaceInclude </span><span class="cov0" title="0">{
                        if ns == incl </span><span class="cov0" title="0">{
                                found = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                        return reconcile.Result{}, nil
                }</span>
        }
        // If NamespaceExclude is set, skip those
        <span class="cov0" title="0">for _, excl := range cfg.NamespaceExclude </span><span class="cov0" title="0">{
                if ns == excl </span><span class="cov0" title="0">{
                        return reconcile.Result{}, nil
                }</span>
        }

        <span class="cov0" title="0">owner := getOwnerRef(&amp;pod)
        if owner == nil </span><span class="cov0" title="0">{
                return reconcile.Result{}, nil
        }</span>

        <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
        if err != nil </span><span class="cov0" title="0">{
                return reconcile.Result{}, err
        }</span>

        <span class="cov0" title="0">newResources := calculateResources(usage)

        if err := patchController(r.Client, owner, pod.Namespace, newResources); err != nil </span><span class="cov0" title="0">{
                return reconcile.Result{}, err
        }</span>

        <span class="cov0" title="0">return reconcile.Result{RequeueAfter: 10 * time.Minute}, nil</span>
}

// SetupRightSizerController registers the controller with the manager
func SetupRightSizerController(mgr manager.Manager, provider metrics.Provider) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;corev1.Pod{}).
                Complete(&amp;RightSizer{Client: mgr.GetClient(), MetricsProvider: provider})
}</span>

// getOwnerRef returns the first controller owner reference (Deployment/StatefulSet)
func getOwnerRef(pod *corev1.Pod) *metav1.OwnerReference <span class="cov0" title="0">{
        for _, owner := range pod.OwnerReferences </span><span class="cov0" title="0">{
                if owner.Controller != nil &amp;&amp; *owner.Controller </span><span class="cov0" title="0">{
                        if owner.Kind == "Deployment" || owner.Kind == "StatefulSet" </span><span class="cov0" title="0">{
                                return &amp;owner
                        }</span>
                }
        }
        <span class="cov0" title="0">return nil</span>
}

// calculateResources computes new resource requests/limits based on usage
func calculateResources(usage metrics.Metrics) corev1.ResourceRequirements <span class="cov0" title="0">{
        cfg := config.Get()

        cpuRequest := int64(usage.CPUMilli*cfg.CPURequestMultiplier) + cfg.CPURequestAddition
        memRequest := int64(usage.MemMB*cfg.MemoryRequestMultiplier) + cfg.MemoryRequestAddition
        cpuLimit := int64(float64(cpuRequest)*cfg.CPULimitMultiplier) + cfg.CPULimitAddition
        memLimit := int64(float64(memRequest)*cfg.MemoryLimitMultiplier) + cfg.MemoryLimitAddition

        return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }
}</span>

// patchController updates the parent controller (Deployment/StatefulSet) with new resources
func patchController(c client.Client, owner *metav1.OwnerReference, namespace string, resources corev1.ResourceRequirements) error <span class="cov0" title="0">{
        switch owner.Kind </span>{
        case "Deployment":<span class="cov0" title="0">
                var deploy appsv1.Deployment
                if err := c.Get(context.TODO(), client.ObjectKey{Namespace: namespace, Name: owner.Name}, &amp;deploy); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">for i := range deploy.Spec.Template.Spec.Containers </span><span class="cov0" title="0">{
                        deploy.Spec.Template.Spec.Containers[i].Resources = resources
                }</span>
                <span class="cov0" title="0">return c.Update(context.TODO(), &amp;deploy)</span>
        case "StatefulSet":<span class="cov0" title="0">
                var sts appsv1.StatefulSet
                if err := c.Get(context.TODO(), client.ObjectKey{Namespace: namespace, Name: owner.Name}, &amp;sts); err != nil </span><span class="cov0" title="0">{
                        return err
                }</span>
                <span class="cov0" title="0">for i := range sts.Spec.Template.Spec.Containers </span><span class="cov0" title="0">{
                        sts.Spec.Template.Spec.Containers[i].Resources = resources
                }</span>
                <span class="cov0" title="0">return c.Update(context.TODO(), &amp;sts)</span>
        default:<span class="cov0" title="0">
                return fmt.Errorf("unsupported owner kind: %s", owner.Kind)</span>
        }
}
</pre>
		
		<pre class="file" id="file13" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package controllers

import (
        "context"
        "fmt"
        "time"

        "right-sizer/admission"
        "right-sizer/api/v1alpha1"
        "right-sizer/audit"
        "right-sizer/config"
        "right-sizer/health"
        "right-sizer/logger"
        "right-sizer/metrics"

        "k8s.io/apimachinery/pkg/api/errors"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/runtime"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/controller"
)

// RightSizerConfigReconciler reconciles a RightSizerConfig object
type RightSizerConfigReconciler struct {
        client.Client
        Scheme          *runtime.Scheme
        Config          *config.Config
        MetricsProvider *metrics.Provider
        AuditLogger     *audit.AuditLogger
        WebhookManager  *admission.WebhookManager
        HealthChecker   *health.OperatorHealthChecker
}

// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerconfigs,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerconfigs/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerconfigs/finalizers,verbs=update
// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerpolicies,verbs=get;list;watch
// +kubebuilder:rbac:groups="",resources=namespaces,verbs=get;list;watch
// +kubebuilder:rbac:groups="",resources=events,verbs=create;patch

// Reconcile is part of the main kubernetes reconciliation loop
func (r *RightSizerConfigReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov0" title="0">{
        log := logger.GetLogger()
        log.Info("Reconciling RightSizerConfig: name=%s, namespace=%s", req.Name, req.Namespace)

        // Fetch the RightSizerConfig instance
        rsc := &amp;v1alpha1.RightSizerConfig{}
        err := r.Get(ctx, req.NamespacedName, rsc)
        if err != nil </span><span class="cov0" title="0">{
                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                        // Request object not found, could have been deleted after reconcile request.
                        // Reset to default configuration
                        log.Info("RightSizerConfig resource not found. Resetting to default configuration")
                        r.resetToDefaultConfig()
                        return ctrl.Result{}, nil
                }</span>
                // Error reading the object - requeue the request.
                <span class="cov0" title="0">log.Error("Failed to get RightSizerConfig: %v", err)
                return ctrl.Result{}, err</span>
        }

        // Initialize status if needed
        <span class="cov0" title="0">if rsc.Status.Phase == "" </span><span class="cov0" title="0">{
                rsc.Status.Phase = "Active"
                rsc.Status.OperatorVersion = "v1.0.0" // You may want to get this from build info
                if err := r.Status().Update(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                        log.Error("Failed to update initial status: %v", err)
                        return ctrl.Result{}, err
                }</span>
        }

        // Apply configuration from CRD
        <span class="cov0" title="0">if err := r.applyConfiguration(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                log.Error("Failed to apply configuration: %v", err)
                return r.updateConfigStatus(ctx, rsc, "Failed", fmt.Sprintf("Error: %v", err))
        }</span>

        // Update metrics provider if needed
        <span class="cov0" title="0">if err := r.updateMetricsProvider(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                log.Error("Failed to update metrics provider: %v", err)
                return r.updateConfigStatus(ctx, rsc, "Failed", fmt.Sprintf("Metrics provider error: %v", err))
        }</span>

        // Update feature components based on configuration
        <span class="cov0" title="0">if err := r.updateFeatureComponents(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                log.Warn("Failed to update feature components: %v", err)
                // Don't fail the reconciliation, just log the warning
        }</span>

        // Update system metrics
        <span class="cov0" title="0">if err := r.updateSystemMetrics(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                log.Warn("Failed to update system metrics: %v", err)
        }</span>

        // Update status to Active
        <span class="cov0" title="0">rsc.Status.Phase = "Active"
        rsc.Status.LastAppliedTime = &amp;metav1.Time{Time: time.Now()}
        rsc.Status.ObservedGeneration = rsc.Generation
        rsc.Status.Message = "Configuration successfully applied"

        // Update system health status
        rsc.Status.SystemHealth = r.getSystemHealth(ctx)

        if err := r.Status().Update(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                log.Error("Failed to update status: %v", err)
                return ctrl.Result{}, err
        }</span>

        // Requeue after the configured resize interval to refresh status
        <span class="cov0" title="0">requeueAfter := 60 * time.Second
        if rsc.Spec.ResizeInterval != "" </span><span class="cov0" title="0">{
                if duration, err := time.ParseDuration(rsc.Spec.ResizeInterval); err == nil </span><span class="cov0" title="0">{
                        requeueAfter = duration
                }</span>
        }

        <span class="cov0" title="0">log.Info("Successfully reconciled RightSizerConfig: name=%s, requeueAfter=%v", req.Name, requeueAfter)
        return ctrl.Result{RequeueAfter: requeueAfter}, nil</span>
}

// applyConfiguration applies the configuration from the CRD to the global config
func (r *RightSizerConfigReconciler) applyConfiguration(ctx context.Context, rsc *v1alpha1.RightSizerConfig) error <span class="cov0" title="0">{
        log := logger.GetLogger()
        log.Info("Applying configuration from RightSizerConfig CRD")

        // Parse resize interval
        resizeInterval := 30 * time.Second
        if rsc.Spec.ResizeInterval != "" </span><span class="cov0" title="0">{
                if duration, err := time.ParseDuration(rsc.Spec.ResizeInterval); err == nil </span><span class="cov0" title="0">{
                        resizeInterval = duration
                }</span>
        }

        // Parse retry interval
        <span class="cov0" title="0">retryInterval := 5 * time.Second
        if rsc.Spec.OperatorConfig.RetryInterval != "" </span><span class="cov0" title="0">{
                if duration, err := time.ParseDuration(rsc.Spec.OperatorConfig.RetryInterval); err == nil </span><span class="cov0" title="0">{
                        retryInterval = duration
                }</span>
        }

        // Extract values with safe defaults
        <span class="cov0" title="0">cpuRequestMultiplier := 1.2
        if rsc.Spec.DefaultResourceStrategy.CPU.RequestMultiplier != 0 </span><span class="cov0" title="0">{
                cpuRequestMultiplier = rsc.Spec.DefaultResourceStrategy.CPU.RequestMultiplier
        }</span>

        <span class="cov0" title="0">memoryRequestMultiplier := 1.2
        if rsc.Spec.DefaultResourceStrategy.Memory.RequestMultiplier != 0 </span><span class="cov0" title="0">{
                memoryRequestMultiplier = rsc.Spec.DefaultResourceStrategy.Memory.RequestMultiplier
        }</span>

        <span class="cov0" title="0">cpuRequestAddition := rsc.Spec.DefaultResourceStrategy.CPU.RequestAddition

        memoryRequestAddition := rsc.Spec.DefaultResourceStrategy.Memory.RequestAddition

        cpuLimitMultiplier := 2.0
        if rsc.Spec.DefaultResourceStrategy.CPU.LimitMultiplier != 0 </span><span class="cov0" title="0">{
                cpuLimitMultiplier = rsc.Spec.DefaultResourceStrategy.CPU.LimitMultiplier
        }</span>

        <span class="cov0" title="0">memoryLimitMultiplier := 2.0
        if rsc.Spec.DefaultResourceStrategy.Memory.LimitMultiplier != 0 </span><span class="cov0" title="0">{
                memoryLimitMultiplier = rsc.Spec.DefaultResourceStrategy.Memory.LimitMultiplier
        }</span>

        <span class="cov0" title="0">cpuLimitAddition := rsc.Spec.DefaultResourceStrategy.CPU.LimitAddition

        memoryLimitAddition := rsc.Spec.DefaultResourceStrategy.Memory.LimitAddition

        minCPURequest := int64(10)
        if rsc.Spec.DefaultResourceStrategy.CPU.MinRequest != "" </span><span class="cov0" title="0">{
                if parsed, err := parseResourceQuantity(rsc.Spec.DefaultResourceStrategy.CPU.MinRequest, "cpu"); err == nil </span><span class="cov0" title="0">{
                        minCPURequest = parsed
                }</span>
        }

        <span class="cov0" title="0">minMemoryRequest := int64(64)
        if rsc.Spec.DefaultResourceStrategy.Memory.MinRequest != "" </span><span class="cov0" title="0">{
                if parsed, err := parseResourceQuantity(rsc.Spec.DefaultResourceStrategy.Memory.MinRequest, "memory"); err == nil </span><span class="cov0" title="0">{
                        minMemoryRequest = parsed
                }</span>
        }

        <span class="cov0" title="0">maxCPULimit := int64(4000)
        if rsc.Spec.DefaultResourceStrategy.CPU.MaxLimit != "" </span><span class="cov0" title="0">{
                if parsed, err := parseResourceQuantity(rsc.Spec.DefaultResourceStrategy.CPU.MaxLimit, "cpu"); err == nil </span><span class="cov0" title="0">{
                        maxCPULimit = parsed
                }</span>
        }

        <span class="cov0" title="0">maxMemoryLimit := int64(8192)
        if rsc.Spec.DefaultResourceStrategy.Memory.MaxLimit != "" </span><span class="cov0" title="0">{
                if parsed, err := parseResourceQuantity(rsc.Spec.DefaultResourceStrategy.Memory.MaxLimit, "memory"); err == nil </span><span class="cov0" title="0">{
                        maxMemoryLimit = parsed
                }</span>
        }

        // Extract scaling thresholds
        <span class="cov0" title="0">memoryScaleUpThreshold := 0.8
        if rsc.Spec.DefaultResourceStrategy.Memory.ScaleUpThreshold != 0 </span><span class="cov0" title="0">{
                memoryScaleUpThreshold = rsc.Spec.DefaultResourceStrategy.Memory.ScaleUpThreshold
        }</span>

        <span class="cov0" title="0">memoryScaleDownThreshold := 0.3
        if rsc.Spec.DefaultResourceStrategy.Memory.ScaleDownThreshold != 0 </span><span class="cov0" title="0">{
                memoryScaleDownThreshold = rsc.Spec.DefaultResourceStrategy.Memory.ScaleDownThreshold
        }</span>

        <span class="cov0" title="0">cpuScaleUpThreshold := 0.8
        if rsc.Spec.DefaultResourceStrategy.CPU.ScaleUpThreshold != 0 </span><span class="cov0" title="0">{
                cpuScaleUpThreshold = rsc.Spec.DefaultResourceStrategy.CPU.ScaleUpThreshold
        }</span>

        <span class="cov0" title="0">cpuScaleDownThreshold := 0.3
        if rsc.Spec.DefaultResourceStrategy.CPU.ScaleDownThreshold != 0 </span><span class="cov0" title="0">{
                cpuScaleDownThreshold = rsc.Spec.DefaultResourceStrategy.CPU.ScaleDownThreshold
        }</span>

        // Extract metrics provider configuration
        <span class="cov0" title="0">metricsProvider := "metrics-server"
        if rsc.Spec.MetricsConfig.Provider != "" </span><span class="cov0" title="0">{
                metricsProvider = rsc.Spec.MetricsConfig.Provider
        }</span>

        <span class="cov0" title="0">prometheusURL := ""
        if rsc.Spec.MetricsConfig.PrometheusEndpoint != "" </span><span class="cov0" title="0">{
                prometheusURL = rsc.Spec.MetricsConfig.PrometheusEndpoint
        }</span>

        // Extract feature flags
        <span class="cov0" title="0">enableInPlaceResize := false
        if rsc.Spec.FeatureGates != nil </span><span class="cov0" title="0">{
                enableInPlaceResize = rsc.Spec.FeatureGates["EnableInPlaceResize"]
        }</span>

        // Update the global configuration
        <span class="cov0" title="0">r.Config.UpdateFromCRD(
                cpuRequestMultiplier,
                memoryRequestMultiplier,
                cpuRequestAddition,
                memoryRequestAddition,
                cpuLimitMultiplier,
                memoryLimitMultiplier,
                cpuLimitAddition,
                memoryLimitAddition,
                minCPURequest,
                minMemoryRequest,
                maxCPULimit,
                maxMemoryLimit,
                resizeInterval,
                rsc.Spec.DryRun,
                rsc.Spec.NamespaceConfig.IncludeNamespaces,
                rsc.Spec.NamespaceConfig.ExcludeNamespaces,
                rsc.Spec.ObservabilityConfig.LogLevel,
                rsc.Spec.ObservabilityConfig.EnableMetricsExport,
                int(rsc.Spec.ObservabilityConfig.MetricsPort),
                rsc.Spec.ObservabilityConfig.EnableAuditLog,
                int(rsc.Spec.OperatorConfig.MaxRetries),
                retryInterval,
                metricsProvider,
                prometheusURL,
                enableInPlaceResize,
                rsc.Spec.OperatorConfig.QPS,
                int(rsc.Spec.OperatorConfig.Burst),
                int(rsc.Spec.OperatorConfig.MaxConcurrentReconciles),
                memoryScaleUpThreshold,
                memoryScaleDownThreshold,
                cpuScaleUpThreshold,
                cpuScaleDownThreshold,
        )

        // Update logger level if changed
        if rsc.Spec.ObservabilityConfig.LogLevel != "" </span><span class="cov0" title="0">{
                logger.Init(rsc.Spec.ObservabilityConfig.LogLevel)
        }</span>

        <span class="cov0" title="0">log.Info("Configuration applied successfully from CRD")
        return nil</span>
}

// updateMetricsProvider updates the metrics provider based on configuration
func (r *RightSizerConfigReconciler) updateMetricsProvider(ctx context.Context, rsc *v1alpha1.RightSizerConfig) error <span class="cov0" title="0">{
        log := logger.GetLogger()

        if r.MetricsProvider == nil </span><span class="cov0" title="0">{
                log.Warn("MetricsProvider reference is nil, skipping update")
                return nil
        }</span>

        <span class="cov0" title="0">desiredProvider := rsc.Spec.MetricsConfig.Provider
        if desiredProvider == "" </span><span class="cov0" title="0">{
                desiredProvider = "metrics-server"
        }</span>

        // Check if we need to switch providers
        <span class="cov0" title="0">currentProviderType := "unknown"
        if _, ok := (*r.MetricsProvider).(*metrics.MetricsServerProvider); ok </span><span class="cov0" title="0">{
                currentProviderType = "metrics-server"
        }</span> else<span class="cov0" title="0"> if _, ok := (*r.MetricsProvider).(*metrics.PrometheusProvider); ok </span><span class="cov0" title="0">{
                currentProviderType = "prometheus"
        }</span>

        <span class="cov0" title="0">if currentProviderType != desiredProvider </span><span class="cov0" title="0">{
                log.Info("Switching metrics provider from %s to %s", currentProviderType, desiredProvider)

                var newProvider metrics.Provider
                if desiredProvider == "prometheus" &amp;&amp; rsc.Spec.MetricsConfig.PrometheusEndpoint != "" </span><span class="cov0" title="0">{
                        newProvider = metrics.NewPrometheusProvider(rsc.Spec.MetricsConfig.PrometheusEndpoint)
                        log.Info("Switched to Prometheus metrics provider: endpoint=%s", rsc.Spec.MetricsConfig.PrometheusEndpoint)
                        if r.HealthChecker != nil </span><span class="cov0" title="0">{
                                r.HealthChecker.UpdateComponentStatus("metrics-provider", true, "Prometheus provider initialized")
                        }</span>
                } else<span class="cov0" title="0"> {
                        newProvider = metrics.NewMetricsServerProvider(r.Client)
                        log.Info("Switched to metrics-server provider")
                        if r.HealthChecker != nil </span><span class="cov0" title="0">{
                                r.HealthChecker.UpdateComponentStatus("metrics-provider", true, "Metrics-server provider initialized")
                        }</span>
                }

                <span class="cov0" title="0">*r.MetricsProvider = newProvider</span>
        }

        <span class="cov0" title="0">return nil</span>
}

// updateFeatureComponents updates feature components based on configuration
func (r *RightSizerConfigReconciler) updateFeatureComponents(ctx context.Context, rsc *v1alpha1.RightSizerConfig) error <span class="cov0" title="0">{
        log := logger.GetLogger()

        // Update audit logger
        if r.AuditLogger != nil </span><span class="cov0" title="0">{
                if rsc.Spec.ObservabilityConfig.EnableAuditLog </span><span class="cov0" title="0">{
                        log.Info("Audit logging is enabled")
                }</span> else<span class="cov0" title="0"> {
                        log.Info("Audit logging is disabled")
                }</span>
        }

        // Update admission webhook
        <span class="cov0" title="0">if r.WebhookManager != nil </span><span class="cov0" title="0">{
                if rsc.Spec.SecurityConfig.EnableAdmissionController </span><span class="cov0" title="0">{
                        log.Info("Admission controller is enabled")
                        // The webhook manager will be started in main.go based on config
                        if r.HealthChecker != nil </span><span class="cov0" title="0">{
                                r.HealthChecker.UpdateComponentStatus("webhook", false, "Webhook enabled, waiting to start")
                        }</span>
                } else<span class="cov0" title="0"> {
                        log.Info("Admission controller is disabled")
                        if r.HealthChecker != nil </span><span class="cov0" title="0">{
                                r.HealthChecker.UpdateComponentStatus("webhook", false, "Not enabled")
                        }</span>
                }
        }

        // Update metrics export
        <span class="cov0" title="0">if rsc.Spec.ObservabilityConfig.EnableMetricsExport </span><span class="cov0" title="0">{
                log.Info("Metrics export enabled on port %d", rsc.Spec.ObservabilityConfig.MetricsPort)
                // Metrics server will be started in main.go based on config
        }</span> else<span class="cov0" title="0"> {
                log.Info("Metrics export disabled")
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// updateSystemMetrics updates system-wide metrics
func (r *RightSizerConfigReconciler) updateSystemMetrics(ctx context.Context, rsc *v1alpha1.RightSizerConfig) error <span class="cov0" title="0">{
        log := logger.GetLogger()

        // Count active policies
        policies := &amp;v1alpha1.RightSizerPolicyList{}
        if err := r.List(ctx, policies); err != nil </span><span class="cov0" title="0">{
                log.Warn("Failed to list policies for metrics: %v", err)
                return err
        }</span>

        <span class="cov0" title="0">activePolicies := 0
        for _, policy := range policies.Items </span><span class="cov0" title="0">{
                if policy.Spec.Enabled </span><span class="cov0" title="0">{
                        activePolicies++
                }</span>
        }
        <span class="cov0" title="0">rsc.Status.ActivePolicies = int32(activePolicies)

        // Count monitored resources
        // This is a simplified count - in production you'd count actual workloads
        deployments := 0
        statefulsets := 0
        daemonsets := 0

        // Update status counts
        rsc.Status.TotalResourcesMonitored = int32(deployments + statefulsets + daemonsets)

        log.Info("System metrics updated: activePolicies=%d, resourcesMonitored=%d",
                activePolicies, rsc.Status.TotalResourcesMonitored)

        return nil</span>
}

// getSystemHealth returns the current system health status
func (r *RightSizerConfigReconciler) getSystemHealth(ctx context.Context) *v1alpha1.SystemHealthStatus <span class="cov0" title="0">{
        health := &amp;v1alpha1.SystemHealthStatus{
                MetricsProviderHealthy: false,
                WebhookHealthy:         false,
                LeaderElectionActive:   false, // Not implemented in this example
                IsLeader:               true,  // Assuming single instance
                LastHealthCheck:        &amp;metav1.Time{Time: time.Now()},
                Errors:                 0,
                Warnings:               0,
        }

        // Get actual health status from health checker if available
        if r.HealthChecker != nil </span><span class="cov0" title="0">{
                // Check metrics provider health
                if status, exists := r.HealthChecker.GetComponentStatus("metrics-provider"); exists </span><span class="cov0" title="0">{
                        health.MetricsProviderHealthy = status.Healthy
                        if !status.Healthy &amp;&amp; status.Message != "Not enabled" &amp;&amp; status.Message != "Not initialized" </span><span class="cov0" title="0">{
                                health.Errors++
                        }</span>
                }

                // Check webhook health
                <span class="cov0" title="0">if status, exists := r.HealthChecker.GetComponentStatus("webhook"); exists </span><span class="cov0" title="0">{
                        health.WebhookHealthy = status.Healthy
                        if !status.Healthy &amp;&amp; status.Message != "Not enabled" </span><span class="cov0" title="0">{
                                health.Warnings++
                        }</span>
                }

                // Check controller health
                <span class="cov0" title="0">if status, exists := r.HealthChecker.GetComponentStatus("controller"); exists </span><span class="cov0" title="0">{
                        if !status.Healthy </span><span class="cov0" title="0">{
                                health.Errors++
                        }</span>
                }
        } else<span class="cov0" title="0"> {
                // Fallback if health checker is not available
                if r.MetricsProvider != nil &amp;&amp; *r.MetricsProvider != nil </span><span class="cov0" title="0">{
                        health.MetricsProviderHealthy = true
                }</span>

                <span class="cov0" title="0">if r.WebhookManager != nil &amp;&amp; r.Config.AdmissionController </span><span class="cov0" title="0">{
                        health.WebhookHealthy = true
                }</span>
        }

        <span class="cov0" title="0">return health</span>
}

// resetToDefaultConfig resets the configuration to defaults when CRD is deleted
func (r *RightSizerConfigReconciler) resetToDefaultConfig() <span class="cov0" title="0">{
        log := logger.GetLogger()
        log.Info("Resetting configuration to defaults")

        r.Config.ResetToDefaults()

        // Reset metrics provider to default
        if r.MetricsProvider != nil </span><span class="cov0" title="0">{
                *r.MetricsProvider = metrics.NewMetricsServerProvider(r.Client)
        }</span>

        <span class="cov0" title="0">log.Info("Configuration reset to defaults")</span>
}

// updateConfigStatus updates the status of the RightSizerConfig
func (r *RightSizerConfigReconciler) updateConfigStatus(ctx context.Context, rsc *v1alpha1.RightSizerConfig, phase string, message string) (ctrl.Result, error) <span class="cov0" title="0">{
        rsc.Status.Phase = phase
        rsc.Status.Message = message
        rsc.Status.ObservedGeneration = rsc.Generation

        if phase == "Failed" </span><span class="cov0" title="0">{
                // Add to errors in system health
                if rsc.Status.SystemHealth == nil </span><span class="cov0" title="0">{
                        rsc.Status.SystemHealth = &amp;v1alpha1.SystemHealthStatus{}
                }</span>
                <span class="cov0" title="0">rsc.Status.SystemHealth.Errors++</span>
        }

        <span class="cov0" title="0">if err := r.Status().Update(ctx, rsc); err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to update status: %v", err)
                return ctrl.Result{}, err
        }</span>

        // Requeue after a delay for failed states
        <span class="cov0" title="0">if phase == "Failed" </span><span class="cov0" title="0">{
                return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
        }</span>

        <span class="cov0" title="0">return ctrl.Result{}, nil</span>
}

// SetupWithManager sets up the controller with the Manager.
func (r *RightSizerConfigReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        return ctrl.NewControllerManagedBy(mgr).
                For(&amp;v1alpha1.RightSizerConfig{}).
                WithOptions(controller.Options{
                        MaxConcurrentReconciles: 1, // Only one config should be processed at a time
                }).
                Complete(r)
}</span>

// parseResourceQuantity parses Kubernetes resource quantity strings to int64 values
func parseResourceQuantity(quantity string, resourceType string) (int64, error) <span class="cov0" title="0">{
        if quantity == "" </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("empty quantity string")
        }</span>

        // Simple parsing for common cases
        // For CPU: "10m" -&gt; 10 (millicores), "1" -&gt; 1000 (millicores)
        // For Memory: "64Mi" -&gt; 64 (MiB), "1Gi" -&gt; 1024 (MiB)

        <span class="cov0" title="0">if resourceType == "cpu" </span><span class="cov0" title="0">{
                if quantity[len(quantity)-1:] == "m" </span><span class="cov0" title="0">{
                        // Parse millicores (e.g., "10m" -&gt; 10)
                        return parseIntFromString(quantity[:len(quantity)-1])
                }</span>
                // Assume whole cores, convert to millicores (e.g., "2" -&gt; 2000)
                <span class="cov0" title="0">if val, err := parseIntFromString(quantity); err == nil </span><span class="cov0" title="0">{
                        return val * 1000, nil
                }</span>
        }

        <span class="cov0" title="0">if resourceType == "memory" </span><span class="cov0" title="0">{
                if len(quantity) &gt;= 2 </span><span class="cov0" title="0">{
                        suffix := quantity[len(quantity)-2:]
                        if suffix == "Mi" </span><span class="cov0" title="0">{
                                // Parse MiB (e.g., "64Mi" -&gt; 64)
                                return parseIntFromString(quantity[:len(quantity)-2])
                        }</span>
                        <span class="cov0" title="0">if suffix == "Gi" </span><span class="cov0" title="0">{
                                // Parse GiB, convert to MiB (e.g., "1Gi" -&gt; 1024)
                                if val, err := parseIntFromString(quantity[:len(quantity)-2]); err == nil </span><span class="cov0" title="0">{
                                        return val * 1024, nil
                                }</span>
                        }
                }
                // Assume MiB if no suffix
                <span class="cov0" title="0">return parseIntFromString(quantity)</span>
        }

        <span class="cov0" title="0">return 0, fmt.Errorf("unknown resource type or format: %s", quantity)</span>
}

// parseIntFromString is a simple integer parser
func parseIntFromString(s string) (int64, error) <span class="cov0" title="0">{
        var result int64
        for _, ch := range s </span><span class="cov0" title="0">{
                if ch &lt; '0' || ch &gt; '9' </span><span class="cov0" title="0">{
                        return 0, fmt.Errorf("invalid integer: %s", s)
                }</span>
                <span class="cov0" title="0">result = result*10 + int64(ch-'0')</span>
        }
        <span class="cov0" title="0">return result, nil</span>
}
</pre>
		
		<pre class="file" id="file14" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package controllers

import (
        "context"
        "fmt"
        "time"

        "right-sizer/api/v1alpha1"
        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        appsv1 "k8s.io/api/apps/v1"
        batchv1 "k8s.io/api/batch/v1"
        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/errors"
        "k8s.io/apimachinery/pkg/api/resource"
        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/apimachinery/pkg/labels"
        "k8s.io/apimachinery/pkg/runtime"
        "k8s.io/apimachinery/pkg/types"
        ctrl "sigs.k8s.io/controller-runtime"
        "sigs.k8s.io/controller-runtime/pkg/client"
        "sigs.k8s.io/controller-runtime/pkg/controller"
        "sigs.k8s.io/controller-runtime/pkg/handler"
        "sigs.k8s.io/controller-runtime/pkg/reconcile"
        "sigs.k8s.io/controller-runtime/pkg/source"
)

// RightSizerPolicyReconciler reconciles a RightSizerPolicy object
type RightSizerPolicyReconciler struct {
        client.Client
        Scheme          *runtime.Scheme
        MetricsProvider metrics.Provider
        Config          *config.Config
}

// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerpolicies,verbs=get;list;watch;create;update;patch;delete
// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerpolicies/status,verbs=get;update;patch
// +kubebuilder:rbac:groups=rightsizer.io,resources=rightsizerpolicies/finalizers,verbs=update
// +kubebuilder:rbac:groups=apps,resources=deployments;statefulsets;daemonsets;replicasets,verbs=get;list;watch;update;patch
// +kubebuilder:rbac:groups=batch,resources=jobs;cronjobs,verbs=get;list;watch;update;patch
// +kubebuilder:rbac:groups="",resources=pods,verbs=get;list;watch;update;patch
// +kubebuilder:rbac:groups="",resources=events,verbs=create;patch

// Reconcile is part of the main kubernetes reconciliation loop
func (r *RightSizerPolicyReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) <span class="cov0" title="0">{
        log := logger.GetLogger()
        log.Info("Reconciling RightSizerPolicy: name=%s, namespace=%s", req.Name, req.Namespace)

        // Fetch the RightSizerPolicy instance
        policy := &amp;v1alpha1.RightSizerPolicy{}
        err := r.Get(ctx, req.NamespacedName, policy)
        if err != nil </span><span class="cov0" title="0">{
                if errors.IsNotFound(err) </span><span class="cov0" title="0">{
                        // Request object not found, could have been deleted after reconcile request.
                        // Owned objects are automatically garbage collected.
                        log.Info("RightSizerPolicy resource not found. Ignoring since object must be deleted")
                        return ctrl.Result{}, nil
                }</span>
                // Error reading the object - requeue the request.
                <span class="cov0" title="0">log.Error("Failed to get RightSizerPolicy: %v", err)
                return ctrl.Result{}, err</span>
        }

        // Check if the policy is enabled
        <span class="cov0" title="0">if !policy.Spec.Enabled </span><span class="cov0" title="0">{
                log.Info("RightSizerPolicy is disabled, skipping reconciliation: name=%s", policy.Name)
                return r.updatePolicyStatus(ctx, policy, "Disabled", "Policy is disabled")
        }</span>

        // Initialize status if needed
        <span class="cov0" title="0">if policy.Status.Phase == "" </span><span class="cov0" title="0">{
                policy.Status.Phase = "Active"
                policy.Status.ResourcesAffected = 0
                policy.Status.ResourcesResized = 0
                if err := r.Status().Update(ctx, policy); err != nil </span><span class="cov0" title="0">{
                        log.Error("Failed to update initial status: %v", err)
                        return ctrl.Result{}, err
                }</span>
        }

        // Check if this policy should be processed based on global namespace filters
        <span class="cov0" title="0">if !r.shouldProcessPolicy(ctx, policy) </span><span class="cov0" title="0">{
                log.Info("Policy skipped due to namespace filters: name=%s", policy.Name)
                return r.updatePolicyStatus(ctx, policy, "Skipped", "Policy namespace not included in global configuration")
        }</span>

        // Process the policy
        <span class="cov0" title="0">result, err := r.processPolicyTargets(ctx, policy)
        if err != nil </span><span class="cov0" title="0">{
                log.Error("Failed to process policy targets: %v", err)
                return r.updatePolicyStatus(ctx, policy, "Failed", fmt.Sprintf("Error: %v", err))
        }</span>

        // Update status with results
        <span class="cov0" title="0">policy.Status.Phase = "Active"
        policy.Status.LastAppliedTime = &amp;metav1.Time{Time: time.Now()}
        policy.Status.ResourcesAffected = result.affected
        policy.Status.ResourcesResized = result.resized
        policy.Status.ObservedGeneration = policy.Generation
        policy.Status.Message = fmt.Sprintf("Successfully processed %d resources, resized %d", result.affected, result.resized)

        // Calculate savings if applicable
        if result.cpuSaved &gt; 0 || result.memorySaved &gt; 0 </span><span class="cov0" title="0">{
                policy.Status.TotalSavings = v1alpha1.ResourceSavings{
                        CPUSaved:    result.cpuSaved,
                        MemorySaved: result.memorySaved,
                }
        }</span>

        <span class="cov0" title="0">if err := r.Status().Update(ctx, policy); err != nil </span><span class="cov0" title="0">{
                log.Error("Failed to update policy status: %v", err)
                return ctrl.Result{}, err
        }</span>

        // Requeue based on schedule
        <span class="cov0" title="0">requeueAfter := r.getRequeueInterval(policy)
        log.Info("Successfully reconciled RightSizerPolicy: name=%s, requeueAfter=%v", req.Name, requeueAfter)
        return ctrl.Result{RequeueAfter: requeueAfter}, nil</span>
}

type processResult struct {
        affected    int32
        resized     int32
        cpuSaved    int64
        memorySaved int64
}

// processPolicyTargets processes all resources targeted by the policy
func (r *RightSizerPolicyReconciler) processPolicyTargets(ctx context.Context, policy *v1alpha1.RightSizerPolicy) (*processResult, error) <span class="cov0" title="0">{
        result := &amp;processResult{}
        targetRef := policy.Spec.TargetRef

        // Get all matching resources
        resources, err := r.getMatchingResources(ctx, targetRef)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">result.affected = int32(len(resources))

        // Process each resource
        for _, res := range resources </span><span class="cov0" title="0">{
                resized, cpuSaved, memorySaved, err := r.processResource(ctx, policy, res)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error("Failed to process resource %s/%s: %v", res.GetNamespace(), res.GetName(), err)
                        continue</span>
                }
                <span class="cov0" title="0">if resized </span><span class="cov0" title="0">{
                        result.resized++
                        result.cpuSaved += cpuSaved
                        result.memorySaved += memorySaved
                }</span>
        }

        <span class="cov0" title="0">return result, nil</span>
}

// getMatchingResources returns all resources that match the target reference
func (r *RightSizerPolicyReconciler) getMatchingResources(ctx context.Context, targetRef v1alpha1.TargetReference) ([]client.Object, error) <span class="cov0" title="0">{
        var resources []client.Object

        // Build label selector
        var selector labels.Selector
        if targetRef.LabelSelector != nil </span><span class="cov0" title="0">{
                var err error
                selector, err = metav1.LabelSelectorAsSelector(targetRef.LabelSelector)
                if err != nil </span><span class="cov0" title="0">{
                        return nil, err
                }</span>
        } else<span class="cov0" title="0"> {
                selector = labels.Everything()
        }</span>

        // Get namespaces to search
        <span class="cov0" title="0">namespaces := r.getTargetNamespaces(ctx, targetRef)

        // Get resources based on kind
        for _, ns := range namespaces </span><span class="cov0" title="0">{
                switch targetRef.Kind </span>{
                case "Deployment":<span class="cov0" title="0">
                        deployments := &amp;appsv1.DeploymentList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, deployments, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range deployments.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;deployments.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;deployments.Items[i])
                                }</span>
                        }

                case "StatefulSet":<span class="cov0" title="0">
                        statefulsets := &amp;appsv1.StatefulSetList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, statefulsets, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range statefulsets.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;statefulsets.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;statefulsets.Items[i])
                                }</span>
                        }

                case "DaemonSet":<span class="cov0" title="0">
                        daemonsets := &amp;appsv1.DaemonSetList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, daemonsets, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range daemonsets.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;daemonsets.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;daemonsets.Items[i])
                                }</span>
                        }

                case "Pod":<span class="cov0" title="0">
                        pods := &amp;corev1.PodList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, pods, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range pods.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;pods.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;pods.Items[i])
                                }</span>
                        }

                case "Job":<span class="cov0" title="0">
                        jobs := &amp;batchv1.JobList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, jobs, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range jobs.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;jobs.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;jobs.Items[i])
                                }</span>
                        }

                case "CronJob":<span class="cov0" title="0">
                        cronjobs := &amp;batchv1.CronJobList{}
                        opts := []client.ListOption{
                                client.InNamespace(ns),
                                client.MatchingLabelsSelector{Selector: selector},
                        }
                        if err := r.List(ctx, cronjobs, opts...); err != nil </span><span class="cov0" title="0">{
                                return nil, err
                        }</span>
                        <span class="cov0" title="0">for i := range cronjobs.Items </span><span class="cov0" title="0">{
                                if r.matchesTargetRef(&amp;cronjobs.Items[i], targetRef) </span><span class="cov0" title="0">{
                                        resources = append(resources, &amp;cronjobs.Items[i])
                                }</span>
                        }
                }
        }

        <span class="cov0" title="0">return resources, nil</span>
}

// getTargetNamespaces returns the list of namespaces to search
func (r *RightSizerPolicyReconciler) getTargetNamespaces(ctx context.Context, targetRef v1alpha1.TargetReference) []string <span class="cov0" title="0">{
        var namespaces []string

        // Start with namespaces from policy targetRef or global config
        if len(targetRef.Namespaces) &gt; 0 </span><span class="cov0" title="0">{
                // Use specified namespaces from policy
                namespaces = targetRef.Namespaces
        }</span> else<span class="cov0" title="0"> if len(r.Config.NamespaceInclude) &gt; 0 </span><span class="cov0" title="0">{
                // Use global namespace include list
                namespaces = r.Config.NamespaceInclude
        }</span> else<span class="cov0" title="0"> {
                // Get all namespaces and filter
                nsList := &amp;corev1.NamespaceList{}
                if err := r.List(ctx, nsList); err != nil </span><span class="cov0" title="0">{
                        logger.Error("Failed to list namespaces: %v", err)
                        return []string{}
                }</span>

                <span class="cov0" title="0">for _, ns := range nsList.Items </span><span class="cov0" title="0">{
                        namespaces = append(namespaces, ns.Name)
                }</span>
        }

        // Apply exclusions - merge policy and global exclusions
        <span class="cov0" title="0">excludeSet := make(map[string]bool)

        // Add policy-level exclusions
        for _, excludeNs := range targetRef.ExcludeNamespaces </span><span class="cov0" title="0">{
                excludeSet[excludeNs] = true
        }</span>

        // Add global exclusions (these always apply)
        <span class="cov0" title="0">for _, excludeNs := range r.Config.NamespaceExclude </span><span class="cov0" title="0">{
                excludeSet[excludeNs] = true
        }</span>

        // Filter out excluded namespaces
        <span class="cov0" title="0">filteredNamespaces := []string{}
        for _, ns := range namespaces </span><span class="cov0" title="0">{
                if !excludeSet[ns] </span><span class="cov0" title="0">{
                        filteredNamespaces = append(filteredNamespaces, ns)
                }</span>
        }

        <span class="cov0" title="0">return filteredNamespaces</span>
}

// matchesTargetRef checks if a resource matches the target reference criteria
func (r *RightSizerPolicyReconciler) matchesTargetRef(obj client.Object, targetRef v1alpha1.TargetReference) bool <span class="cov0" title="0">{
        // Check name inclusion/exclusion
        name := obj.GetName()
        if len(targetRef.Names) &gt; 0 </span><span class="cov0" title="0">{
                found := false
                for _, n := range targetRef.Names </span><span class="cov0" title="0">{
                        if n == name </span><span class="cov0" title="0">{
                                found = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        <span class="cov0" title="0">for _, excludeName := range targetRef.ExcludeNames </span><span class="cov0" title="0">{
                if excludeName == name </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // Check annotation selector
        <span class="cov0" title="0">if len(targetRef.AnnotationSelector) &gt; 0 </span><span class="cov0" title="0">{
                annotations := obj.GetAnnotations()
                for key, value := range targetRef.AnnotationSelector </span><span class="cov0" title="0">{
                        if annotations[key] != value </span><span class="cov0" title="0">{
                                return false
                        }</span>
                }
        }

        <span class="cov0" title="0">return true</span>
}

// processResource processes a single resource according to the policy
func (r *RightSizerPolicyReconciler) processResource(ctx context.Context, policy *v1alpha1.RightSizerPolicy, obj client.Object) (bool, int64, int64, error) <span class="cov0" title="0">{
        // Skip if dry-run mode
        if policy.Spec.DryRun </span><span class="cov0" title="0">{
                logger.Info("Dry-run mode: would resize %s/%s", obj.GetNamespace(), obj.GetName())
                return false, 0, 0, nil
        }</span>

        // IMPORTANT: We NEVER update Deployments, StatefulSets, DaemonSets, Jobs, or CronJobs directly
        // as that would cause pod restarts. We ONLY resize pods in-place.

        // For all workload types, we find their pods and resize them directly
        <span class="cov0" title="0">var labelSelector map[string]string
        var namespace string

        switch res := obj.(type) </span>{
        case *appsv1.Deployment:<span class="cov0" title="0">
                labelSelector = res.Spec.Selector.MatchLabels
                namespace = res.Namespace
                logger.Info("Processing pods for Deployment %s/%s", namespace, res.Name)</span>
        case *appsv1.StatefulSet:<span class="cov0" title="0">
                labelSelector = res.Spec.Selector.MatchLabels
                namespace = res.Namespace
                logger.Info("Processing pods for StatefulSet %s/%s", namespace, res.Name)</span>
        case *appsv1.DaemonSet:<span class="cov0" title="0">
                labelSelector = res.Spec.Selector.MatchLabels
                namespace = res.Namespace
                logger.Info("Processing pods for DaemonSet %s/%s", namespace, res.Name)</span>
        case *batchv1.Job:<span class="cov0" title="0">
                labelSelector = res.Spec.Selector.MatchLabels
                namespace = res.Namespace
                logger.Info("Processing pods for Job %s/%s", namespace, res.Name)</span>
        case *batchv1.CronJob:<span class="cov0" title="0">
                // CronJobs don't have running pods unless a job is active
                // Skip CronJobs to avoid issues
                logger.Info("Skipping CronJob %s/%s - CronJobs are not resized", res.Namespace, res.Name)
                return false, 0, 0, nil</span>
        case *corev1.Pod:<span class="cov0" title="0">
                // For standalone pods, resize directly
                return r.processPod(ctx, policy, res)</span>
        default:<span class="cov0" title="0">
                return false, 0, 0, fmt.Errorf("unsupported resource type: %T", res)</span>
        }

        // Find all pods matching the workload's selector
        <span class="cov0" title="0">podList := &amp;corev1.PodList{}
        if err := r.List(ctx, podList,
                client.InNamespace(namespace),
                client.MatchingLabels(labelSelector)); err != nil </span><span class="cov0" title="0">{
                return false, 0, 0, err
        }</span>

        <span class="cov0" title="0">if len(podList.Items) == 0 </span><span class="cov0" title="0">{
                logger.Info("No pods found for %s/%s", namespace, obj.GetName())
                return false, 0, 0, nil
        }</span>

        // Process each pod individually with in-place resizing
        <span class="cov0" title="0">var totalResized int
        var totalCPUSaved, totalMemorySaved int64

        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                // Skip pods that are not running
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">resized, cpuSaved, memorySaved, err := r.processPod(ctx, policy, &amp;pod)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warn("Failed to resize pod %s/%s: %v", pod.Namespace, pod.Name, err)
                        continue</span>
                }

                <span class="cov0" title="0">if resized </span><span class="cov0" title="0">{
                        totalResized++
                        totalCPUSaved += cpuSaved
                        totalMemorySaved += memorySaved
                }</span>
        }

        <span class="cov0" title="0">if totalResized &gt; 0 </span><span class="cov0" title="0">{
                logger.Info("✅ Successfully resized %d pods for %s/%s (CPU saved: %dm, Memory saved: %dMi)",
                        totalResized, namespace, obj.GetName(), totalCPUSaved, totalMemorySaved/(1024*1024))

                // Create an event for the workload
                r.createEvent(ctx, obj, policy, "PodsResized",
                        fmt.Sprintf("Resized %d pods by policy %s", totalResized, policy.Name))
        }</span>

        <span class="cov0" title="0">return totalResized &gt; 0, totalCPUSaved, totalMemorySaved, nil</span>
}

// processPod handles in-place pod resizing
func (r *RightSizerPolicyReconciler) processPod(ctx context.Context, policy *v1alpha1.RightSizerPolicy, pod *corev1.Pod) (bool, int64, int64, error) <span class="cov0" title="0">{
        // Check if pod supports in-place resize
        if !r.supportsInPlaceResize(pod) </span><span class="cov0" title="0">{
                return false, 0, 0, nil
        }</span>

        // Calculate new resources
        <span class="cov0" title="0">newResources := make(map[string]corev1.ResourceRequirements)
        var cpuSaved, memorySaved int64

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warn("Failed to fetch metrics for pod %s/%s: %v", pod.Namespace, pod.Name, err)
                        continue</span>
                }

                <span class="cov0" title="0">newReqs := r.calculateOptimalResourcesFromPolicy(policy, usage)
                newResources[container.Name] = newReqs

                // Calculate savings
                if container.Resources.Requests != nil </span><span class="cov0" title="0">{
                        oldCPU := container.Resources.Requests.Cpu().MilliValue()
                        newCPU := newReqs.Requests.Cpu().MilliValue()
                        cpuSaved += oldCPU - newCPU

                        oldMem := container.Resources.Requests.Memory().Value() / (1024 * 1024)
                        newMem := newReqs.Requests.Memory().Value() / (1024 * 1024)
                        memorySaved += oldMem - newMem
                }</span>
        }

        // Apply the resize
        <span class="cov0" title="0">pod.Spec.Containers[0].Resources = newResources[pod.Spec.Containers[0].Name]

        if err := r.Update(ctx, pod); err != nil </span><span class="cov0" title="0">{
                return false, 0, 0, err
        }</span>

        <span class="cov0" title="0">return true, cpuSaved, memorySaved, nil</span>
}

// calculateNewResources calculates new resource requirements based on policy
func (r *RightSizerPolicyReconciler) calculateNewResources(ctx context.Context, policy *v1alpha1.RightSizerPolicy, obj client.Object, podTemplate *corev1.PodTemplateSpec) (map[string]corev1.ResourceRequirements, int64, int64, error) <span class="cov0" title="0">{
        newResources := make(map[string]corev1.ResourceRequirements)
        var totalCPUSaved, totalMemorySaved int64

        // Get pods for this workload to fetch metrics
        podList := &amp;corev1.PodList{}
        if err := r.List(ctx, podList, client.InNamespace(obj.GetNamespace()), client.MatchingLabels(podTemplate.Labels)); err != nil </span><span class="cov0" title="0">{
                return nil, 0, 0, err
        }</span>

        <span class="cov0" title="0">if len(podList.Items) == 0 </span><span class="cov0" title="0">{
                return newResources, 0, 0, nil
        }</span>

        // Aggregate metrics from all pods
        <span class="cov0" title="0">var totalCPU, totalMem float64
        validPods := 0
        for _, pod := range podList.Items </span><span class="cov0" title="0">{
                if pod.Status.Phase != corev1.PodRunning </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">usage, err := r.MetricsProvider.FetchPodMetrics(pod.Namespace, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        continue</span>
                }

                <span class="cov0" title="0">totalCPU += usage.CPUMilli
                totalMem += usage.MemMB
                validPods++</span>
        }

        <span class="cov0" title="0">if validPods == 0 </span><span class="cov0" title="0">{
                return newResources, 0, 0, nil
        }</span>

        // Calculate average usage
        <span class="cov0" title="0">avgUsage := metrics.Metrics{
                CPUMilli: totalCPU / float64(validPods),
                MemMB:    totalMem / float64(validPods),
        }

        // Calculate new resources for each container
        for _, container := range podTemplate.Spec.Containers </span><span class="cov0" title="0">{
                newReqs := r.calculateOptimalResourcesFromPolicy(policy, avgUsage)
                newResources[container.Name] = newReqs

                // Calculate savings
                if container.Resources.Requests != nil </span><span class="cov0" title="0">{
                        oldCPU := container.Resources.Requests.Cpu().MilliValue()
                        newCPU := newReqs.Requests.Cpu().MilliValue()
                        totalCPUSaved += oldCPU - newCPU

                        oldMem := container.Resources.Requests.Memory().Value() / (1024 * 1024)
                        newMem := newReqs.Requests.Memory().Value() / (1024 * 1024)
                        totalMemorySaved += oldMem - newMem
                }</span>
        }

        <span class="cov0" title="0">return newResources, totalCPUSaved, totalMemorySaved, nil</span>
}

// calculateOptimalResourcesFromPolicy calculates resources based on policy settings
func (r *RightSizerPolicyReconciler) calculateOptimalResourcesFromPolicy(policy *v1alpha1.RightSizerPolicy, usage metrics.Metrics) corev1.ResourceRequirements <span class="cov0" title="0">{
        strategy := policy.Spec.ResourceStrategy

        // Get multipliers and additions from policy or use defaults
        cpuRequestMultiplier := r.Config.CPURequestMultiplier
        memoryRequestMultiplier := r.Config.MemoryRequestMultiplier
        cpuRequestAddition := r.Config.CPURequestAddition
        memoryRequestAddition := r.Config.MemoryRequestAddition
        cpuLimitMultiplier := r.Config.CPULimitMultiplier
        memoryLimitMultiplier := r.Config.MemoryLimitMultiplier
        cpuLimitAddition := r.Config.CPULimitAddition
        memoryLimitAddition := r.Config.MemoryLimitAddition

        // Override with policy-specific values if provided
        if strategy.CPU.RequestMultiplier != nil </span><span class="cov0" title="0">{
                cpuRequestMultiplier = *strategy.CPU.RequestMultiplier
        }</span>
        <span class="cov0" title="0">if strategy.CPU.RequestAddition != nil </span><span class="cov0" title="0">{
                cpuRequestAddition = *strategy.CPU.RequestAddition
        }</span>
        <span class="cov0" title="0">if strategy.CPU.LimitMultiplier != nil </span><span class="cov0" title="0">{
                cpuLimitMultiplier = *strategy.CPU.LimitMultiplier
        }</span>
        <span class="cov0" title="0">if strategy.CPU.LimitAddition != nil </span><span class="cov0" title="0">{
                cpuLimitAddition = *strategy.CPU.LimitAddition
        }</span>

        <span class="cov0" title="0">if strategy.Memory.RequestMultiplier != nil </span><span class="cov0" title="0">{
                memoryRequestMultiplier = *strategy.Memory.RequestMultiplier
        }</span>
        <span class="cov0" title="0">if strategy.Memory.RequestAddition != nil </span><span class="cov0" title="0">{
                memoryRequestAddition = *strategy.Memory.RequestAddition
        }</span>
        <span class="cov0" title="0">if strategy.Memory.LimitMultiplier != nil </span><span class="cov0" title="0">{
                memoryLimitMultiplier = *strategy.Memory.LimitMultiplier
        }</span>
        <span class="cov0" title="0">if strategy.Memory.LimitAddition != nil </span><span class="cov0" title="0">{
                memoryLimitAddition = *strategy.Memory.LimitAddition
        }</span>

        // Calculate requests with multipliers and additions
        <span class="cov0" title="0">cpuRequest := int64(usage.CPUMilli*cpuRequestMultiplier) + cpuRequestAddition
        memRequest := int64(usage.MemMB*memoryRequestMultiplier) + memoryRequestAddition

        // Apply minimum values
        minCPU := r.Config.MinCPURequest
        minMem := r.Config.MinMemoryRequest
        if strategy.CPU.MinRequest != nil </span><span class="cov0" title="0">{
                minCPU = *strategy.CPU.MinRequest
        }</span>
        <span class="cov0" title="0">if strategy.Memory.MinRequest != nil </span><span class="cov0" title="0">{
                minMem = *strategy.Memory.MinRequest
        }</span>

        <span class="cov0" title="0">if cpuRequest &lt; minCPU </span><span class="cov0" title="0">{
                cpuRequest = minCPU
        }</span>
        <span class="cov0" title="0">if memRequest &lt; minMem </span><span class="cov0" title="0">{
                memRequest = minMem
        }</span>

        // Calculate limits
        <span class="cov0" title="0">cpuLimit := int64(float64(cpuRequest)*cpuLimitMultiplier) + cpuLimitAddition
        memLimit := int64(float64(memRequest)*memoryLimitMultiplier) + memoryLimitAddition

        // Apply maximum caps
        maxCPU := r.Config.MaxCPULimit
        maxMem := r.Config.MaxMemoryLimit
        if strategy.CPU.MaxLimit != nil </span><span class="cov0" title="0">{
                maxCPU = *strategy.CPU.MaxLimit
        }</span>
        <span class="cov0" title="0">if strategy.Memory.MaxLimit != nil </span><span class="cov0" title="0">{
                maxMem = *strategy.Memory.MaxLimit
        }</span>

        <span class="cov0" title="0">if cpuLimit &gt; maxCPU </span><span class="cov0" title="0">{
                cpuLimit = maxCPU
        }</span>
        <span class="cov0" title="0">if memLimit &gt; maxMem </span><span class="cov0" title="0">{
                memLimit = maxMem
        }</span>

        <span class="cov0" title="0">return corev1.ResourceRequirements{
                Requests: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuRequest, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memRequest*1024*1024, resource.BinarySI),
                },
                Limits: corev1.ResourceList{
                        corev1.ResourceCPU:    *resource.NewMilliQuantity(cpuLimit, resource.DecimalSI),
                        corev1.ResourceMemory: *resource.NewQuantity(memLimit*1024*1024, resource.BinarySI),
                },
        }</span>
}

// needsUpdate checks if resources need to be updated
func (r *RightSizerPolicyReconciler) needsUpdate(podTemplate *corev1.PodTemplateSpec, newResources map[string]corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        for _, container := range podTemplate.Spec.Containers </span><span class="cov0" title="0">{
                if newReqs, ok := newResources[container.Name]; ok </span><span class="cov0" title="0">{
                        if !resourcesEqual(container.Resources, newReqs) </span><span class="cov0" title="0">{
                                return true
                        }</span>
                }
        }
        <span class="cov0" title="0">return false</span>
}

// resourcesEqual compares two resource requirements
func resourcesEqual(a, b corev1.ResourceRequirements) bool <span class="cov0" title="0">{
        if !a.Requests.Cpu().Equal(*b.Requests.Cpu()) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">if !a.Requests.Memory().Equal(*b.Requests.Memory()) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">if !a.Limits.Cpu().Equal(*b.Limits.Cpu()) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">if !a.Limits.Memory().Equal(*b.Limits.Memory()) </span><span class="cov0" title="0">{
                return false
        }</span>
        <span class="cov0" title="0">return true</span>
}

// supportsInPlaceResize checks if a pod supports in-place resize
func (r *RightSizerPolicyReconciler) supportsInPlaceResize(pod *corev1.Pod) bool <span class="cov0" title="0">{
        // Check if pod has resize policy defined
        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                if container.ResizePolicy != nil &amp;&amp; len(container.ResizePolicy) &gt; 0 </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// getRequeueInterval determines the requeue interval based on policy schedule
func (r *RightSizerPolicyReconciler) getRequeueInterval(policy *v1alpha1.RightSizerPolicy) time.Duration <span class="cov0" title="0">{
        if policy.Spec.Schedule.Interval != "" </span><span class="cov0" title="0">{
                duration, err := time.ParseDuration(policy.Spec.Schedule.Interval)
                if err == nil </span><span class="cov0" title="0">{
                        return duration
                }</span>
        }
        // Default to 1 minute
        <span class="cov0" title="0">return time.Minute</span>
}

// updatePolicyStatus updates the policy status
func (r *RightSizerPolicyReconciler) updatePolicyStatus(ctx context.Context, policy *v1alpha1.RightSizerPolicy, phase, message string) (ctrl.Result, error) <span class="cov0" title="0">{
        policy.Status.Phase = phase
        policy.Status.Message = message
        policy.Status.LastEvaluationTime = &amp;metav1.Time{Time: time.Now()}
        policy.Status.ObservedGeneration = policy.Generation

        if err := r.Status().Update(ctx, policy); err != nil </span><span class="cov0" title="0">{
                return ctrl.Result{}, err
        }</span>

        // Requeue after default interval
        <span class="cov0" title="0">return ctrl.Result{RequeueAfter: time.Minute}, nil</span>
}

// createEvent creates a Kubernetes event for the resource
func (r *RightSizerPolicyReconciler) createEvent(ctx context.Context, obj client.Object, policy *v1alpha1.RightSizerPolicy, reason, message string) <span class="cov0" title="0">{
        // Implementation would create a Kubernetes event
        // This is simplified for brevity
        logger.Info("Event: %s/%s - %s: %s", obj.GetNamespace(), obj.GetName(), reason, message)
}</span>

// shouldProcessPolicy checks if a policy should be processed based on namespace filters
func (r *RightSizerPolicyReconciler) shouldProcessPolicy(ctx context.Context, policy *v1alpha1.RightSizerPolicy) bool <span class="cov0" title="0">{
        // If policy has specific namespaces, check if any are allowed
        if len(policy.Spec.TargetRef.Namespaces) &gt; 0 </span><span class="cov0" title="0">{
                targetNamespaces := r.getTargetNamespaces(ctx, policy.Spec.TargetRef)
                return len(targetNamespaces) &gt; 0
        }</span>

        // If policy is in a namespace that's excluded globally, skip it
        <span class="cov0" title="0">for _, excludeNs := range r.Config.NamespaceExclude </span><span class="cov0" title="0">{
                if policy.Namespace == excludeNs </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // If we have a global include list and policy namespace is not in it, skip
        <span class="cov0" title="0">if len(r.Config.NamespaceInclude) &gt; 0 </span><span class="cov0" title="0">{
                found := false
                for _, includeNs := range r.Config.NamespaceInclude </span><span class="cov0" title="0">{
                        if policy.Namespace == includeNs </span><span class="cov0" title="0">{
                                found = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        <span class="cov0" title="0">return true</span>
}

// SetupWithManager sets up the controller with the Manager
func (r *RightSizerPolicyReconciler) SetupWithManager(mgr ctrl.Manager) error <span class="cov0" title="0">{
        // Create controller
        c, err := controller.New("rightsizerpolicy-controller", mgr, controller.Options{
                Reconciler: r,
        })
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Watch RightSizerPolicy resources
        <span class="cov0" title="0">err = c.Watch(source.Kind(mgr.GetCache(), &amp;v1alpha1.RightSizerPolicy{}, &amp;handler.TypedEnqueueRequestForObject[*v1alpha1.RightSizerPolicy]{}))
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>

        // Watch target resources and enqueue policies that target them
        // NOTE: Commented out Deployment, StatefulSet, and DaemonSet watchers
        // since we're doing in-place pod resizing directly on pods
        // instead of updating the parent controllers

        // // Watch Deployments
        // err = c.Watch(source.Kind(mgr.GetCache(), &amp;appsv1.Deployment{},
        //         handler.TypedEnqueueRequestsFromMapFunc(func(ctx context.Context, obj *appsv1.Deployment) []reconcile.Request {
        //                 return r.findPoliciesForResource(obj)
        //         })))
        // if err != nil {
        //         return err
        // }

        // // Watch StatefulSets
        // err = c.Watch(source.Kind(mgr.GetCache(), &amp;appsv1.StatefulSet{},
        //         handler.TypedEnqueueRequestsFromMapFunc(func(ctx context.Context, obj *appsv1.StatefulSet) []reconcile.Request {
        //                 return r.findPoliciesForResource(obj)
        //         })))
        // if err != nil {
        //         return err
        // }

        // // Watch DaemonSets
        // err = c.Watch(source.Kind(mgr.GetCache(), &amp;appsv1.DaemonSet{},
        //         handler.TypedEnqueueRequestsFromMapFunc(func(ctx context.Context, obj *appsv1.DaemonSet) []reconcile.Request {
        //                 return r.findPoliciesForResource(obj)
        //         })))
        // if err != nil {
        //         return err
        // }

        <span class="cov0" title="0">return nil</span>
}

// findPoliciesForResource finds all policies that target the given resource
func (r *RightSizerPolicyReconciler) findPoliciesForResource(obj client.Object) []reconcile.Request <span class="cov0" title="0">{
        var policies v1alpha1.RightSizerPolicyList
        ctx := context.Background()

        // List all policies
        if err := r.List(ctx, &amp;policies); err != nil </span><span class="cov0" title="0">{
                logger.Error("Failed to list policies: %v", err)
                return []reconcile.Request{}
        }</span>

        <span class="cov0" title="0">var requests []reconcile.Request

        // Check each policy to see if it targets this resource
        for _, policy := range policies.Items </span><span class="cov0" title="0">{
                // Check if the resource type matches
                gvk := obj.GetObjectKind().GroupVersionKind()
                if policy.Spec.TargetRef.Kind == "" || policy.Spec.TargetRef.Kind == gvk.Kind </span><span class="cov0" title="0">{
                        // Check if namespace matches
                        namespaceMatch := false
                        if len(policy.Spec.TargetRef.Namespaces) == 0 </span><span class="cov0" title="0">{
                                // No namespace filter means all namespaces
                                namespaceMatch = true
                        }</span> else<span class="cov0" title="0"> {
                                // Check if object's namespace is in the list
                                for _, ns := range policy.Spec.TargetRef.Namespaces </span><span class="cov0" title="0">{
                                        if ns == obj.GetNamespace() </span><span class="cov0" title="0">{
                                                namespaceMatch = true
                                                break</span>
                                        }
                                }
                        }

                        // Check if namespace is excluded
                        <span class="cov0" title="0">if namespaceMatch </span><span class="cov0" title="0">{
                                for _, excludedNs := range policy.Spec.TargetRef.ExcludeNamespaces </span><span class="cov0" title="0">{
                                        if excludedNs == obj.GetNamespace() </span><span class="cov0" title="0">{
                                                namespaceMatch = false
                                                break</span>
                                        }
                                }
                        }

                        // Check label selector if present
                        <span class="cov0" title="0">labelMatch := true
                        if policy.Spec.TargetRef.LabelSelector != nil </span><span class="cov0" title="0">{
                                selector, err := metav1.LabelSelectorAsSelector(policy.Spec.TargetRef.LabelSelector)
                                if err == nil </span><span class="cov0" title="0">{
                                        labelMatch = selector.Matches(labels.Set(obj.GetLabels()))
                                }</span>
                        }

                        <span class="cov0" title="0">if namespaceMatch &amp;&amp; labelMatch </span><span class="cov0" title="0">{
                                // This policy targets this resource, enqueue it
                                requests = append(requests, reconcile.Request{
                                        NamespacedName: types.NamespacedName{
                                                Name:      policy.Name,
                                                Namespace: policy.Namespace,
                                        },
                                })
                        }</span>
                }
        }

        <span class="cov0" title="0">return requests</span>
}
</pre>
		
		<pre class="file" id="file15" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package health

import (
        "context"
        "fmt"
        "net/http"
        "sync"
        "time"

        "right-sizer/logger"

        "sigs.k8s.io/controller-runtime/pkg/healthz"
)

// ComponentStatus represents the health status of a component
type ComponentStatus struct {
        Healthy     bool
        LastChecked time.Time
        Message     string
}

// OperatorHealthChecker checks the health of operator components
type OperatorHealthChecker struct {
        mu               sync.RWMutex
        components       map[string]*ComponentStatus
        metricsServerURL string
        webhookServerURL string
        checkInterval    time.Duration
        lastOverallCheck time.Time
}

// NewOperatorHealthChecker creates a new health checker
func NewOperatorHealthChecker() *OperatorHealthChecker <span class="cov8" title="1">{
        return &amp;OperatorHealthChecker{
                components: map[string]*ComponentStatus{
                        "controller": {
                                Healthy:     true,
                                LastChecked: time.Now(),
                                Message:     "Controller initialized",
                        },
                        "metrics-provider": {
                                Healthy:     false,
                                LastChecked: time.Now(),
                                Message:     "Metrics provider not yet initialized",
                        },
                        "webhook": {
                                Healthy:     false,
                                LastChecked: time.Now(),
                                Message:     "Webhook not yet initialized",
                        },
                },
                metricsServerURL: "http://localhost:8080/metrics",
                webhookServerURL: "http://localhost:8443/health",
                checkInterval:    30 * time.Second,
        }
}</span>

// UpdateComponentStatus updates the status of a specific component
func (h *OperatorHealthChecker) UpdateComponentStatus(component string, healthy bool, message string) <span class="cov0" title="0">{
        h.mu.Lock()
        defer h.mu.Unlock()

        if status, exists := h.components[component]; exists </span><span class="cov0" title="0">{
                status.Healthy = healthy
                status.LastChecked = time.Now()
                status.Message = message
        }</span> else<span class="cov0" title="0"> {
                h.components[component] = &amp;ComponentStatus{
                        Healthy:     healthy,
                        LastChecked: time.Now(),
                        Message:     message,
                }
        }</span>

        <span class="cov0" title="0">logger.Debug("Health status updated for %s: healthy=%v, message=%s", component, healthy, message)</span>
}

// GetComponentStatus returns the status of a specific component
func (h *OperatorHealthChecker) GetComponentStatus(component string) (*ComponentStatus, bool) <span class="cov0" title="0">{
        h.mu.RLock()
        defer h.mu.RUnlock()

        status, exists := h.components[component]
        if !exists </span><span class="cov0" title="0">{
                return nil, false
        }</span>

        // Return a copy to avoid race conditions
        <span class="cov0" title="0">statusCopy := &amp;ComponentStatus{
                Healthy:     status.Healthy,
                LastChecked: status.LastChecked,
                Message:     status.Message,
        }
        return statusCopy, true</span>
}

// IsHealthy returns true if all components are healthy
func (h *OperatorHealthChecker) IsHealthy() bool <span class="cov0" title="0">{
        h.mu.RLock()
        defer h.mu.RUnlock()

        for name, status := range h.components </span><span class="cov0" title="0">{
                // Skip optional components that are not initialized
                if name == "webhook" || name == "metrics-provider" </span><span class="cov0" title="0">{
                        if status.Message == "Not enabled" || status.Message == "Not initialized" </span><span class="cov0" title="0">{
                                continue</span>
                        }
                }

                <span class="cov0" title="0">if !status.Healthy </span><span class="cov0" title="0">{
                        return false
                }</span>

                // Check if the component hasn't been updated recently (stale health check)
                <span class="cov0" title="0">if time.Since(status.LastChecked) &gt; 5*time.Minute </span><span class="cov0" title="0">{
                        logger.Warn("Component %s health check is stale (last checked: %v ago)",
                                name, time.Since(status.LastChecked))
                        return false
                }</span>
        }

        <span class="cov0" title="0">return true</span>
}

// GetHealthReport returns a detailed health report
func (h *OperatorHealthChecker) GetHealthReport() map[string]interface{} <span class="cov0" title="0">{
        h.mu.RLock()
        defer h.mu.RUnlock()

        report := make(map[string]interface{})
        report["overall_healthy"] = h.IsHealthy()
        report["last_check"] = h.lastOverallCheck

        components := make(map[string]interface{})
        for name, status := range h.components </span><span class="cov0" title="0">{
                components[name] = map[string]interface{}{
                        "healthy":      status.Healthy,
                        "last_checked": status.LastChecked,
                        "message":      status.Message,
                        "age":          time.Since(status.LastChecked).String(),
                }
        }</span>
        <span class="cov0" title="0">report["components"] = components

        return report</span>
}

// StartPeriodicHealthChecks starts periodic health checks for components
func (h *OperatorHealthChecker) StartPeriodicHealthChecks(ctx context.Context) <span class="cov0" title="0">{
        go func() </span><span class="cov0" title="0">{
                ticker := time.NewTicker(h.checkInterval)
                defer ticker.Stop()

                for </span><span class="cov0" title="0">{
                        select </span>{
                        case &lt;-ctx.Done():<span class="cov0" title="0">
                                logger.Info("Stopping periodic health checks")
                                return</span>
                        case &lt;-ticker.C:<span class="cov0" title="0">
                                h.performHealthChecks()</span>
                        }
                }
        }()
}

// performHealthChecks performs health checks on all components
func (h *OperatorHealthChecker) performHealthChecks() <span class="cov0" title="0">{
        h.mu.Lock()
        h.lastOverallCheck = time.Now()
        h.mu.Unlock()

        // Check controller health (always healthy if this code is running)
        h.UpdateComponentStatus("controller", true, "Controller is running")

        // Check metrics server if enabled
        if h.metricsServerURL != "" </span><span class="cov0" title="0">{
                if err := h.CheckHTTPEndpoint(h.metricsServerURL, 2*time.Second); err != nil </span><span class="cov0" title="0">{
                        h.UpdateComponentStatus("metrics-provider", false, fmt.Sprintf("Metrics server check failed: %v", err))
                }</span> else<span class="cov0" title="0"> {
                        h.UpdateComponentStatus("metrics-provider", true, "Metrics server is healthy")
                }</span>
        }

        // Check webhook server if enabled
        <span class="cov0" title="0">if h.webhookServerURL != "" </span><span class="cov0" title="0">{
                if err := h.CheckHTTPEndpoint(h.webhookServerURL, 2*time.Second); err != nil </span><span class="cov0" title="0">{
                        // Webhook might not be enabled, which is okay
                        if h.components["webhook"].Message != "Not enabled" </span><span class="cov0" title="0">{
                                h.UpdateComponentStatus("webhook", false, fmt.Sprintf("Webhook check failed: %v", err))
                        }</span>
                } else<span class="cov0" title="0"> {
                        h.UpdateComponentStatus("webhook", true, "Webhook server is healthy")
                }</span>
        }
}

// CheckHTTPEndpoint checks if an HTTP endpoint is responsive
func (h *OperatorHealthChecker) CheckHTTPEndpoint(url string, timeout time.Duration) error <span class="cov0" title="0">{
        client := &amp;http.Client{
                Timeout: timeout,
        }

        resp, err := client.Get(url)
        if err != nil </span><span class="cov0" title="0">{
                return err
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        if resp.StatusCode &gt;= 400 </span><span class="cov0" title="0">{
                return fmt.Errorf("endpoint returned status %d", resp.StatusCode)
        }</span>

        <span class="cov0" title="0">return nil</span>
}

// LivenessCheck implements the healthz.Checker interface for liveness probes
func (h *OperatorHealthChecker) LivenessCheck(_ *http.Request) error <span class="cov0" title="0">{
        // For liveness, we only check if the controller is running
        // This prevents unnecessary restarts if external dependencies are down
        if status, exists := h.GetComponentStatus("controller"); exists &amp;&amp; status.Healthy </span><span class="cov0" title="0">{
                return nil
        }</span>
        <span class="cov0" title="0">return fmt.Errorf("controller is not healthy")</span>
}

// ReadinessCheck implements the healthz.Checker interface for readiness probes
func (h *OperatorHealthChecker) ReadinessCheck(_ *http.Request) error <span class="cov0" title="0">{
        // For readiness, we check all critical components
        if !h.IsHealthy() </span><span class="cov0" title="0">{
                report := h.GetHealthReport()
                unhealthyComponents := []string{}

                if components, ok := report["components"].(map[string]interface{}); ok </span><span class="cov0" title="0">{
                        for name, details := range components </span><span class="cov0" title="0">{
                                if componentDetails, ok := details.(map[string]interface{}); ok </span><span class="cov0" title="0">{
                                        if healthy, ok := componentDetails["healthy"].(bool); ok &amp;&amp; !healthy </span><span class="cov0" title="0">{
                                                // Skip optional components
                                                if name == "webhook" || name == "metrics-provider" </span><span class="cov0" title="0">{
                                                        if msg, ok := componentDetails["message"].(string); ok </span><span class="cov0" title="0">{
                                                                if msg == "Not enabled" || msg == "Not initialized" </span><span class="cov0" title="0">{
                                                                        continue</span>
                                                                }
                                                        }
                                                }
                                                <span class="cov0" title="0">unhealthyComponents = append(unhealthyComponents, name)</span>
                                        }
                                }
                        }
                }

                <span class="cov0" title="0">if len(unhealthyComponents) &gt; 0 </span><span class="cov0" title="0">{
                        return fmt.Errorf("unhealthy components: %v", unhealthyComponents)
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// SetCheckInterval sets the interval for periodic health checks
func (h *OperatorHealthChecker) SetCheckInterval(interval time.Duration) <span class="cov0" title="0">{
        h.mu.Lock()
        defer h.mu.Unlock()
        h.checkInterval = interval
}</span>

// SetMetricsServerURL sets the URL for the metrics server health check
func (h *OperatorHealthChecker) SetMetricsServerURL(url string) <span class="cov0" title="0">{
        h.mu.Lock()
        defer h.mu.Unlock()
        h.metricsServerURL = url
}</span>

// SetWebhookServerURL sets the URL for the webhook server health check
func (h *OperatorHealthChecker) SetWebhookServerURL(url string) <span class="cov0" title="0">{
        h.mu.Lock()
        defer h.mu.Unlock()
        h.webhookServerURL = url
}</span>

// DetailedHealthCheck returns a custom health check that provides detailed information
func (h *OperatorHealthChecker) DetailedHealthCheck() healthz.Checker <span class="cov0" title="0">{
        return func(req *http.Request) error </span><span class="cov0" title="0">{
                // Perform a fresh health check
                h.performHealthChecks()

                // Return readiness check result
                return h.ReadinessCheck(req)
        }</span>
}
</pre>
		
		<pre class="file" id="file16" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package logger

import (
        "fmt"
        "log"
        "os"
        "strings"
        "time"
)

// LogLevel represents the severity of a log message
type LogLevel int

const (
        DEBUG LogLevel = iota
        INFO
        WARN
        ERROR
)

// Logger represents a logger with configurable level
type Logger struct {
        level  LogLevel
        prefix string
        logger *log.Logger
}

var (
        // Global logger instance
        Global *Logger

        // Color codes for different log levels
        colorReset  = "\033[0m"
        colorRed    = "\033[31m"
        colorYellow = "\033[33m"
        colorBlue   = "\033[34m"
        colorGray   = "\033[90m"
        colorGreen  = "\033[32m"
)

// NewLogger creates a new logger with the specified level
func NewLogger(levelStr string, prefix string) *Logger <span class="cov0" title="0">{
        level := parseLogLevel(levelStr)
        return &amp;Logger{
                level:  level,
                prefix: prefix,
                logger: log.New(os.Stdout, "", 0),
        }
}</span>

// Init initializes the global logger
func Init(levelStr string) <span class="cov0" title="0">{
        Global = NewLogger(levelStr, "")
}</span>

// parseLogLevel converts a string log level to LogLevel
func parseLogLevel(levelStr string) LogLevel <span class="cov0" title="0">{
        switch strings.ToLower(levelStr) </span>{
        case "debug":<span class="cov0" title="0">
                return DEBUG</span>
        case "info":<span class="cov0" title="0">
                return INFO</span>
        case "warn", "warning":<span class="cov0" title="0">
                return WARN</span>
        case "error":<span class="cov0" title="0">
                return ERROR</span>
        default:<span class="cov0" title="0">
                return INFO</span>
        }
}

// formatMessage formats a log message with timestamp and level
func (l *Logger) formatMessage(level string, color string, format string, args ...interface{}) string <span class="cov0" title="0">{
        timestamp := time.Now().Format("2006/01/02 15:04:05")
        message := fmt.Sprintf(format, args...)

        // Add prefix if set
        if l.prefix != "" </span><span class="cov0" title="0">{
                message = fmt.Sprintf("[%s] %s", l.prefix, message)
        }</span>

        // Check if we should use colors (when outputting to terminal)
        <span class="cov0" title="0">useColor := false
        if fileInfo, _ := os.Stdout.Stat(); (fileInfo.Mode() &amp; os.ModeCharDevice) != 0 </span><span class="cov0" title="0">{
                useColor = true
        }</span>

        <span class="cov0" title="0">if useColor </span><span class="cov0" title="0">{
                return fmt.Sprintf("%s %s[%s]%s %s", timestamp, color, level, colorReset, message)
        }</span>
        <span class="cov0" title="0">return fmt.Sprintf("%s [%s] %s", timestamp, level, message)</span>
}

// Debug logs a debug message
func (l *Logger) Debug(format string, args ...interface{}) <span class="cov0" title="0">{
        if l.level &lt;= DEBUG </span><span class="cov0" title="0">{
                msg := l.formatMessage("DEBUG", colorGray, format, args...)
                l.logger.Println(msg)
        }</span>
}

// Info logs an info message (without level prefix for cleaner output)
func (l *Logger) Info(format string, args ...interface{}) <span class="cov0" title="0">{
        if l.level &lt;= INFO </span><span class="cov0" title="0">{
                timestamp := time.Now().Format("2006/01/02 15:04:05")
                message := fmt.Sprintf(format, args...)

                // Add prefix if set
                if l.prefix != "" </span><span class="cov0" title="0">{
                        message = fmt.Sprintf("[%s] %s", l.prefix, message)
                }</span>

                // Format without [INFO] prefix for cleaner logs
                <span class="cov0" title="0">msg := fmt.Sprintf("%s %s", timestamp, message)
                l.logger.Println(msg)</span>
        }
}

// Warn logs a warning message
func (l *Logger) Warn(format string, args ...interface{}) <span class="cov0" title="0">{
        if l.level &lt;= WARN </span><span class="cov0" title="0">{
                msg := l.formatMessage("WARN", colorYellow, format, args...)
                l.logger.Println(msg)
        }</span>
}

// Error logs an error message
func (l *Logger) Error(format string, args ...interface{}) <span class="cov0" title="0">{
        if l.level &lt;= ERROR </span><span class="cov0" title="0">{
                msg := l.formatMessage("ERROR", colorRed, format, args...)
                l.logger.Println(msg)
        }</span>
}

// Success logs a success message (always shown, without level prefix for cleaner output)
func (l *Logger) Success(format string, args ...interface{}) <span class="cov0" title="0">{
        if l.level &lt;= INFO </span><span class="cov0" title="0">{
                timestamp := time.Now().Format("2006/01/02 15:04:05")
                message := fmt.Sprintf(format, args...)

                // Add prefix if set
                if l.prefix != "" </span><span class="cov0" title="0">{
                        message = fmt.Sprintf("[%s] %s", l.prefix, message)
                }</span>

                // Format without [INFO] prefix for cleaner logs
                <span class="cov0" title="0">msg := fmt.Sprintf("%s %s", timestamp, message)
                l.logger.Println(msg)</span>
        }
}

// SetLevel changes the log level
func (l *Logger) SetLevel(levelStr string) <span class="cov0" title="0">{
        l.level = parseLogLevel(levelStr)
}</span>

// WithPrefix creates a new logger with a prefix
func (l *Logger) WithPrefix(prefix string) *Logger <span class="cov0" title="0">{
        return &amp;Logger{
                level:  l.level,
                prefix: prefix,
                logger: l.logger,
        }
}</span>

// Global logging functions that use the global logger

// Debug logs a debug message using the global logger
func Debug(format string, args ...interface{}) <span class="cov0" title="0">{
        if Global != nil </span><span class="cov0" title="0">{
                Global.Debug(format, args...)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("[DEBUG] "+format, args...)
        }</span>
}

// Info logs an info message using the global logger
func Info(format string, args ...interface{}) <span class="cov0" title="0">{
        if Global != nil </span><span class="cov0" title="0">{
                Global.Info(format, args...)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("[INFO] "+format, args...)
        }</span>
}

// Warn logs a warning message using the global logger
func Warn(format string, args ...interface{}) <span class="cov0" title="0">{
        if Global != nil </span><span class="cov0" title="0">{
                Global.Warn(format, args...)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("[WARN] "+format, args...)
        }</span>
}

// Error logs an error message using the global logger
func Error(format string, args ...interface{}) <span class="cov0" title="0">{
        if Global != nil </span><span class="cov0" title="0">{
                Global.Error(format, args...)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("[ERROR] "+format, args...)
        }</span>
}

// Success logs a success message using the global logger
func Success(format string, args ...interface{}) <span class="cov0" title="0">{
        if Global != nil </span><span class="cov0" title="0">{
                Global.Success(format, args...)
        }</span> else<span class="cov0" title="0"> {
                log.Printf("[SUCCESS] "+format, args...)
        }</span>
}

// New creates a new logger with the specified level
func New(level LogLevel) *Logger <span class="cov0" title="0">{
        return &amp;Logger{
                level:  level,
                prefix: "",
                logger: log.New(os.Stdout, "", 0),
        }
}</span>

// GetLogger returns the global logger instance, creating it if necessary
func GetLogger() *Logger <span class="cov0" title="0">{
        if Global == nil </span><span class="cov0" title="0">{
                Global = New(INFO)
        }</span>
        <span class="cov0" title="0">return Global</span>
}
</pre>
		
		<pre class="file" id="file17" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package main

import (
        "context"
        "fmt"
        "os"
        "os/signal"
        "right-sizer/admission"
        "right-sizer/api/v1alpha1"
        "right-sizer/audit"
        "right-sizer/config"
        "right-sizer/controllers"
        "right-sizer/health"
        "right-sizer/logger"
        "right-sizer/metrics"
        "right-sizer/retry"
        "right-sizer/validation"
        "runtime"
        "strconv"
        "syscall"
        "time"

        "github.com/go-logr/zapr"
        "go.uber.org/zap"
        "k8s.io/apimachinery/pkg/version"
        "k8s.io/client-go/kubernetes"
        ctrl "sigs.k8s.io/controller-runtime"
        ctrlconfig "sigs.k8s.io/controller-runtime/pkg/config"
        ctrllog "sigs.k8s.io/controller-runtime/pkg/log"
        "sigs.k8s.io/controller-runtime/pkg/manager"
        "sigs.k8s.io/controller-runtime/pkg/metrics/server"
)

// Health server is handled by the controller-runtime manager
// which provides /healthz and /readyz endpoints automatically

func main() <span class="cov0" title="0">{
        // Print startup banner
        fmt.Println("========================================")
        fmt.Println("🚀 Right-Sizer Operator Starting...")
        fmt.Println("========================================")

        // Initialize configuration with defaults
        // Configuration will be updated from CRDs once they are loaded
        cfg := config.Load()

        // Initialize logger with default level
        logger.Init(cfg.LogLevel)

        // Initialize controller-runtime logger to prevent warnings
        zapLog, err := zap.NewProduction()
        if err != nil </span><span class="cov0" title="0">{
                // Fall back to development logger if production logger fails
                zapLog, _ = zap.NewDevelopment()
        }</span>
        <span class="cov0" title="0">ctrllog.SetLogger(zapr.NewLogger(zapLog))

        fmt.Println("----------------------------------------")
        logger.Info("📋 Using Default Configuration")
        logger.Info("   Waiting for RightSizerConfig CRD to override defaults...")
        logger.Info("   Configuration Source: %s", cfg.ConfigSource)
        fmt.Println("----------------------------------------")

        // Print build information
        logger.Info("📦 Build Information:")
        logger.Info("   Go Version: %s", runtime.Version())
        logger.Info("   Go OS/Arch: %s/%s", runtime.GOOS, runtime.GOARCH)
        logger.Info("   Kubernetes Client-Go: v0.34.0")
        logger.Info("   Controller Runtime: v0.22.0")
        logger.Info("   API Machinery: v0.34.0")

        // Initialize enhanced components
        operatorMetrics := metrics.NewOperatorMetrics()

        // Initialize health checker
        healthChecker := health.NewOperatorHealthChecker()
        logger.Info("✅ Health checker initialized")

        // Get Kubernetes config with rate limiting to prevent API server overload
        kubeConfig := ctrl.GetConfigOrDie()

        // Configure rate limiting for the Kubernetes client
        // QPS: Queries Per Second allowed to the API server
        // Burst: Maximum burst for throttle
        kubeConfig.QPS = float32(cfg.QPS) // Use configured value (default: 20)
        kubeConfig.Burst = cfg.Burst      // Use configured value (default: 30)

        // Print Kubernetes client and server versions
        clientset, err := kubernetes.NewForConfig(kubeConfig)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warn("Could not create clientset for version info: %v", err)
        }</span> else<span class="cov0" title="0"> {
                fmt.Println("----------------------------------------")
                logger.Info("🌐 Kubernetes Cluster Information:")

                discoveryClient := clientset.Discovery()

                // Get server version
                serverVersion, err := discoveryClient.ServerVersion()
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warn("   ⚠️  Could not get server version: %v", err)
                }</span> else<span class="cov0" title="0"> {
                        logger.Info("   Server Version: %s", serverVersion.GitVersion)
                        logger.Info("   Server Platform: %s", serverVersion.Platform)
                        logger.Info("   Server Go Version: %s", serverVersion.GoVersion)

                        // Parse version for feature detection
                        versionInfo := version.Info{
                                Major:      serverVersion.Major,
                                Minor:      serverVersion.Minor,
                                GitVersion: serverVersion.GitVersion,
                        }
                        logger.Info("   API Version: %s.%s", versionInfo.Major, versionInfo.Minor)
                }</span>

                // Check API resources including resize subresource
                <span class="cov0" title="0">fmt.Println("----------------------------------------")
                logger.Info("🔍 Checking API Resources:")
                logger.Info("   Rate Limiting: QPS=%v, Burst=%v", kubeConfig.QPS, kubeConfig.Burst)
                logger.Info("   Concurrency: MaxConcurrentReconciles=%v", cfg.MaxConcurrentReconciles)

                apiResourceList, err := discoveryClient.ServerResourcesForGroupVersion("v1")
                if err == nil </span><span class="cov0" title="0">{
                        hasResize := false
                        hasPodMetrics := false

                        for _, resource := range apiResourceList.APIResources </span><span class="cov0" title="0">{
                                if resource.Name == "pods/resize" </span><span class="cov0" title="0">{
                                        hasResize = true
                                }</span>
                                <span class="cov0" title="0">if resource.Name == "pods/metrics" </span><span class="cov0" title="0">{
                                        hasPodMetrics = true
                                }</span>
                        }

                        <span class="cov0" title="0">if hasResize </span><span class="cov0" title="0">{
                                logger.Success("   ✅ pods/resize subresource: AVAILABLE (In-place resize supported)")
                        }</span> else<span class="cov0" title="0"> {
                                logger.Warn("   ❌ pods/resize subresource: NOT FOUND (Will use fallback methods)")
                        }</span>

                        <span class="cov0" title="0">if hasPodMetrics </span><span class="cov0" title="0">{
                                logger.Success("   ✅ pods/metrics: AVAILABLE")
                        }</span> else<span class="cov0" title="0"> {
                                logger.Warn("   ⚠️  pods/metrics: NOT FOUND")
                        }</span>
                } else<span class="cov0" title="0"> {
                        logger.Warn("   ⚠️  Could not query API resources: %v", err)
                }</span>

                // Check metrics-server availability
                <span class="cov0" title="0">_, err = discoveryClient.ServerResourcesForGroupVersion("metrics.k8s.io/v1beta1")
                if err == nil </span><span class="cov0" title="0">{
                        logger.Success("   ✅ metrics-server: AVAILABLE")
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("   ⚠️  metrics-server: NOT AVAILABLE or NOT READY")
                }</span>
        }

        <span class="cov0" title="0">fmt.Println("========================================")

        // Configure leader election from environment variables
        enableLeaderElection := false
        if envVal := os.Getenv("ENABLE_LEADER_ELECTION"); envVal != "" </span><span class="cov0" title="0">{
                if parsed, err := strconv.ParseBool(envVal); err == nil </span><span class="cov0" title="0">{
                        enableLeaderElection = parsed
                        logger.Info("🔧 Leader election configured from environment: %v", enableLeaderElection)
                }</span>
        }

        <span class="cov0" title="0">leaderElectionID := "right-sizer-leader-election"
        if envVal := os.Getenv("LEADER_ELECTION_ID"); envVal != "" </span><span class="cov0" title="0">{
                leaderElectionID = envVal
        }</span>

        <span class="cov0" title="0">leaderElectionNamespace := os.Getenv("OPERATOR_NAMESPACE")
        if leaderElectionNamespace == "" </span><span class="cov0" title="0">{
                leaderElectionNamespace = "right-sizer"
        }</span>

        <span class="cov0" title="0">if enableLeaderElection </span><span class="cov0" title="0">{
                logger.Info("👑 Leader election enabled:")
                logger.Info("   ID: %s", leaderElectionID)
                logger.Info("   Namespace: %s", leaderElectionNamespace)
        }</span>

        // Create controller manager with rate limiting and resource protection
        <span class="cov0" title="0">mgr, err := manager.New(kubeConfig, manager.Options{
                // Limit the number of concurrent reconciles per controller
                // This prevents overwhelming the API server with too many concurrent operations
                Controller: ctrlconfig.Controller{
                        MaxConcurrentReconciles: cfg.MaxConcurrentReconciles, // Use configured value (default: 3)
                },

                // Graceful shutdown timeout
                GracefulShutdownTimeout: &amp;[]time.Duration{30 * time.Second}[0],

                // Leader election helps prevent multiple instances from making changes simultaneously
                LeaderElection:          enableLeaderElection,
                LeaderElectionID:        leaderElectionID,
                LeaderElectionNamespace: leaderElectionNamespace,

                // Health and readiness probes
                HealthProbeBindAddress: ":8081",

                // Metrics server configuration
                Metrics: server.Options{
                        BindAddress: ":8080",
                },
        })
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to start manager: %v", err)
                os.Exit(1)
        }</span>

        // Add health check endpoints with custom health checker
        <span class="cov0" title="0">if err := mgr.AddHealthzCheck("healthz", healthChecker.LivenessCheck); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to set up health check: %v", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">if err := mgr.AddReadyzCheck("readyz", healthChecker.ReadinessCheck); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to set up ready check: %v", err)
                os.Exit(1)
        }</span>
        // Add a detailed health check endpoint
        <span class="cov0" title="0">if err := mgr.AddReadyzCheck("detailed", healthChecker.DetailedHealthCheck()); err != nil </span><span class="cov0" title="0">{
                logger.Warn("unable to set up detailed health check: %v", err)
        }</span>
        <span class="cov0" title="0">logger.Info("✅ Health and readiness probes configured on :8081")
        logger.Info("   - /healthz for liveness probe")
        logger.Info("   - /readyz for readiness probe")
        logger.Info("   - /readyz/detailed for detailed health status")

        // Register CRD schemes
        if err := v1alpha1.AddToScheme(mgr.GetScheme()); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to add CRD schemes: %v", err)
                os.Exit(1)
        }</span>

        // Initialize Kubernetes clientset
        <span class="cov0" title="0">clientset, err = kubernetes.NewForConfig(kubeConfig)
        if err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to create clientset: %v", err)
                os.Exit(1)
        }</span>

        // Initialize enhanced components
        <span class="cov0" title="0">ctx := context.Background()

        // Initialize resource validator
        resourceValidator := validation.NewResourceValidator(mgr.GetClient(), clientset, cfg, operatorMetrics)
        if err := resourceValidator.RefreshCaches(ctx); err != nil </span><span class="cov0" title="0">{
                logger.Warn("Failed to refresh resource validator caches: %v", err)
        }</span>

        // Initialize audit logger (will be enabled/disabled based on CRD config)
        <span class="cov0" title="0">var auditLogger *audit.AuditLogger
        auditConfig := audit.DefaultAuditConfig()
        auditLogger, err = audit.NewAuditLogger(mgr.GetClient(), cfg, operatorMetrics, auditConfig)
        if err != nil </span><span class="cov0" title="0">{
                logger.Warn("Failed to initialize audit logger: %v", err)
        }</span>

        // Initialize admission webhook (will be enabled/disabled based on CRD config)
        <span class="cov0" title="0">var webhookManager *admission.WebhookManager
        webhookConfig := admission.WebhookConfig{
                Port:              8443,
                EnableValidation:  true,
                EnableMutation:    false,
                DryRun:            cfg.DryRun,
                RequireAnnotation: false,
        }
        webhookManager = admission.NewWebhookManager(
                mgr.GetClient(),
                clientset,
                resourceValidator,
                cfg,
                operatorMetrics,
                webhookConfig,
        )

        // Initialize metrics provider (default to metrics-server, will be updated from CRD)
        var provider metrics.Provider
        logger.Info("Using default metrics-server provider (can be changed via RightSizerConfig CRD)")
        provider = metrics.NewMetricsServerProvider(mgr.GetClient())
        healthChecker.UpdateComponentStatus("metrics-provider", true, "Metrics provider initialized")

        // Initialize retry configuration
        retryConfig := retry.Config{
                MaxRetries:          cfg.MaxRetries,
                InitialDelay:        cfg.RetryInterval,
                MaxDelay:            30 * time.Second,
                BackoffFactor:       2.0,
                RandomizationFactor: 0.1,
                Timeout:             60 * time.Second,
        }

        // Initialize circuit breaker configuration
        cbConfig := retry.DefaultCircuitBreakerConfig()
        cbConfig.RecoveryTimeout = 30 * time.Second

        // Create retry handler with circuit breaker
        retryHandler := retry.NewRetryWithCircuitBreaker(
                "right-sizer-operations",
                retryConfig,
                cbConfig,
                operatorMetrics,
        )

        // Setup signal handling for graceful shutdown
        signalChan := make(chan os.Signal, 1)
        signal.Notify(signalChan, syscall.SIGINT, syscall.SIGTERM)

        // Setup CRD controllers
        logger.Info("Setting up CRD controllers...")

        // Setup RightSizerConfig controller (this will manage configuration)
        configController := &amp;controllers.RightSizerConfigReconciler{
                Client:          mgr.GetClient(),
                Scheme:          mgr.GetScheme(),
                Config:          cfg,
                MetricsProvider: &amp;provider,
                AuditLogger:     auditLogger,
                WebhookManager:  webhookManager,
                HealthChecker:   healthChecker,
        }
        if err := configController.SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to setup RightSizerConfig controller: %v", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">logger.Info("✅ RightSizerConfig controller initialized")

        // Setup RightSizerPolicy controller
        policyController := &amp;controllers.RightSizerPolicyReconciler{
                Client:          mgr.GetClient(),
                Scheme:          mgr.GetScheme(),
                MetricsProvider: provider,
                Config:          cfg,
        }
        if err := policyController.SetupWithManager(mgr); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to setup RightSizerPolicy controller: %v", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">logger.Info("✅ RightSizerPolicy controller initialized")

        // Setup the main rightsizer controller
        // The controller will use configuration from CRDs
        logger.Info("Setting up main RightSizer controller...")

        // Use AdaptiveRightSizer as the default implementation with rate limiting
        // It will check for in-place resize capability based on CRD configuration
        // The controller will respect the manager's rate limiting configuration
        if err := controllers.SetupAdaptiveRightSizer(mgr, provider, cfg.DryRun); err != nil </span><span class="cov0" title="0">{
                logger.Error("unable to setup AdaptiveRightSizer: %v", err)
                os.Exit(1)
        }</span>
        <span class="cov0" title="0">logger.Info("✅ AdaptiveRightSizer controller initialized")

        // Start metrics server (will be enabled/disabled based on CRD config)
        go func() </span><span class="cov0" title="0">{
                // Wait for configuration to be loaded from CRD
                time.Sleep(5 * time.Second)

                if cfg.MetricsEnabled </span><span class="cov0" title="0">{
                        logger.Info("🔍 Starting metrics server on port %d", cfg.MetricsPort)
                        if err := metrics.StartMetricsServer(cfg.MetricsPort); err != nil </span><span class="cov0" title="0">{
                                logger.Error("Metrics server error: %v", err)
                        }</span>
                }
        }()

        // Start admission webhook (will be enabled/disabled based on CRD config)
        <span class="cov0" title="0">go func() </span><span class="cov0" title="0">{
                // Wait for configuration to be loaded from CRD
                time.Sleep(5 * time.Second)

                if cfg.AdmissionController &amp;&amp; webhookManager != nil </span><span class="cov0" title="0">{
                        ctx, cancel := context.WithCancel(context.Background())
                        defer cancel()

                        logger.Info("🛡️  Starting admission webhook...")
                        healthChecker.UpdateComponentStatus("webhook", false, "Webhook starting...")
                        if err := webhookManager.Start(ctx); err != nil </span><span class="cov0" title="0">{
                                logger.Error("admission webhook error: %v", err)
                                healthChecker.UpdateComponentStatus("webhook", false, fmt.Sprintf("Webhook error: %v", err))
                        }</span> else<span class="cov0" title="0"> {
                                healthChecker.UpdateComponentStatus("webhook", true, "Webhook server is running")
                        }</span>
                } else<span class="cov0" title="0"> {
                        healthChecker.UpdateComponentStatus("webhook", false, "Not enabled")
                }</span>
        }()

        // Start periodic health checks
        <span class="cov0" title="0">healthCheckCtx, healthCheckCancel := context.WithCancel(context.Background())
        defer healthCheckCancel()
        healthChecker.StartPeriodicHealthChecks(healthCheckCtx)
        logger.Info("🔍 Started periodic health checks")

        // Start manager in a goroutine
        managerDone := make(chan error, 1)
        go func() </span><span class="cov0" title="0">{
                logger.Info("🚀 Starting right-sizer operator manager...")
                logger.Info("📋 Configuration will be loaded from RightSizerConfig CRDs")
                logger.Info("📋 Policies will be loaded from RightSizerPolicy CRDs")
                healthChecker.UpdateComponentStatus("controller", true, "Controller manager started")
                managerDone &lt;- mgr.Start(ctrl.SetupSignalHandler())
        }</span>()

        // Wait for shutdown signal or manager error
        <span class="cov0" title="0">select </span>{
        case &lt;-signalChan:<span class="cov0" title="0">
                logger.Info("📢 Shutdown signal received, initiating graceful shutdown...")</span>
        case err := &lt;-managerDone:<span class="cov0" title="0">
                if err != nil </span><span class="cov0" title="0">{
                        logger.Error("❌ Manager error: %v", err)
                }</span>
        }

        // Graceful shutdown
        <span class="cov0" title="0">shutdownCtx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
        defer cancel()

        // Cleanup components
        if auditLogger != nil </span><span class="cov0" title="0">{
                logger.Info("📋 Closing audit logger...")
                if err := auditLogger.Close(); err != nil </span><span class="cov0" title="0">{
                        logger.Warn("Error closing audit logger: %v", err)
                }</span>
        }

        <span class="cov0" title="0">if webhookManager != nil </span><span class="cov0" title="0">{
                logger.Info("🛡️  Stopping admission webhook...")
                if err := webhookManager.Stop(shutdownCtx); err != nil </span><span class="cov0" title="0">{
                        logger.Warn("Error stopping webhook manager: %v", err)
                }</span>
        }

        // Log final statistics
        <span class="cov0" title="0">logger.Info("✅ Right-sizer operator shutdown completed")

        // Print shutdown summary
        fmt.Println("========================================")
        fmt.Println("🎯 Right-Sizer Operator Summary:")
        fmt.Printf("   Configuration Source: %s\n", cfg.ConfigSource)
        fmt.Printf("   Circuit Breaker State: %s\n", retryHandler.GetCircuitBreakerState())
        if operatorMetrics != nil </span><span class="cov0" title="0">{
                fmt.Println("   Metrics available at /metrics endpoint")
        }</span>
        <span class="cov0" title="0">fmt.Println("========================================")</span>
}
</pre>
		
		<pre class="file" id="file18" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package metrics

import (
        "fmt"

        "github.com/prometheus/client_golang/prometheus"
        "k8s.io/klog/v2"
)

// MemoryMetrics holds all memory-specific Prometheus metrics
type MemoryMetrics struct {
        // Core memory metrics
        PodMemoryUsageBytes      *prometheus.GaugeVec
        PodMemoryWorkingSetBytes *prometheus.GaugeVec
        PodMemoryRSSBytes        *prometheus.GaugeVec
        PodMemoryCacheBytes      *prometheus.GaugeVec
        PodMemorySwapBytes       *prometheus.GaugeVec

        // Memory limits and requests
        PodMemoryLimitBytes   *prometheus.GaugeVec
        PodMemoryRequestBytes *prometheus.GaugeVec

        // Memory utilization metrics
        PodMemoryUtilizationPercentage *prometheus.GaugeVec
        PodMemoryRequestUtilization    *prometheus.GaugeVec
        PodMemoryLimitUtilization      *prometheus.GaugeVec

        // Memory recommendation metrics
        MemoryRecommendationBytes *prometheus.GaugeVec
        MemoryRecommendationRatio *prometheus.GaugeVec

        // Memory pressure metrics
        MemoryPressureEvents   *prometheus.CounterVec
        MemoryPressureLevel    *prometheus.GaugeVec
        MemoryOOMKillEvents    *prometheus.CounterVec
        MemoryThrottlingEvents *prometheus.CounterVec

        // Memory trend metrics
        MemoryTrendSlope        *prometheus.GaugeVec
        MemoryPeakUsageBytes    *prometheus.GaugeVec
        MemoryAverageUsageBytes *prometheus.GaugeVec

        // Memory efficiency metrics
        MemoryWasteBytes      *prometheus.GaugeVec
        MemoryEfficiencyScore *prometheus.GaugeVec

        // Container-specific memory metrics
        ContainerMemoryUsageBytes      *prometheus.GaugeVec
        ContainerMemoryWorkingSetBytes *prometheus.GaugeVec
        ContainerMemoryRSSBytes        *prometheus.GaugeVec
        ContainerMemoryCacheBytes      *prometheus.GaugeVec

        // Memory allocation metrics
        MemoryAllocationFailures *prometheus.CounterVec
        MemoryResizeOperations   *prometheus.CounterVec
        MemoryResizeSuccessRate  *prometheus.GaugeVec
}

// MemoryPressureLevel represents different levels of memory pressure
type MemoryPressureLevel int

const (
        MemoryPressureNone MemoryPressureLevel = iota
        MemoryPressureLow
        MemoryPressureMedium
        MemoryPressureHigh
        MemoryPressureCritical
)

// String returns the string representation of memory pressure level
func (m MemoryPressureLevel) String() string <span class="cov0" title="0">{
        switch m </span>{
        case MemoryPressureNone:<span class="cov0" title="0">
                return "none"</span>
        case MemoryPressureLow:<span class="cov0" title="0">
                return "low"</span>
        case MemoryPressureMedium:<span class="cov0" title="0">
                return "medium"</span>
        case MemoryPressureHigh:<span class="cov0" title="0">
                return "high"</span>
        case MemoryPressureCritical:<span class="cov0" title="0">
                return "critical"</span>
        default:<span class="cov0" title="0">
                return "unknown"</span>
        }
}

// NewMemoryMetrics creates and registers all memory-specific Prometheus metrics
func NewMemoryMetrics() *MemoryMetrics <span class="cov0" title="0">{
        metrics := &amp;MemoryMetrics{
                PodMemoryUsageBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_usage_bytes",
                                Help: "Current memory usage in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryWorkingSetBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_working_set_bytes",
                                Help: "Current working set memory in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryRSSBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_rss_bytes",
                                Help: "Current RSS (Resident Set Size) memory in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryCacheBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_cache_bytes",
                                Help: "Current cache memory in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemorySwapBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_swap_bytes",
                                Help: "Current swap memory usage in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryLimitBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_limit_bytes",
                                Help: "Memory limit in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryRequestBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_pod_memory_request_bytes",
                                Help: "Memory request in bytes for pods",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryUtilizationPercentage: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_utilization_percentage",
                                Help: "Memory utilization percentage (usage/limit)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryRequestUtilization: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_request_utilization",
                                Help: "Memory request utilization ratio (usage/request)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                PodMemoryLimitUtilization: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_limit_utilization",
                                Help: "Memory limit utilization ratio (usage/limit)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryRecommendationBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_recommendation_bytes",
                                Help: "Recommended memory allocation in bytes",
                        },
                        []string{"namespace", "pod", "container", "recommendation_type"},
                ),

                MemoryRecommendationRatio: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_recommendation_ratio",
                                Help: "Ratio of recommended memory to current allocation",
                        },
                        []string{"namespace", "pod", "container", "recommendation_type"},
                ),

                MemoryPressureEvents: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_pressure_events_total",
                                Help: "Total number of memory pressure events detected",
                        },
                        []string{"namespace", "pod", "container", "pressure_level"},
                ),

                MemoryPressureLevel: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_pressure_level",
                                Help: "Current memory pressure level (0=none, 1=low, 2=medium, 3=high, 4=critical)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryOOMKillEvents: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_oom_kill_events_total",
                                Help: "Total number of OOM kill events",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryThrottlingEvents: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_throttling_events_total",
                                Help: "Total number of memory throttling events",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryTrendSlope: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_trend_slope",
                                Help: "Memory usage trend slope (positive=increasing, negative=decreasing)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryPeakUsageBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_peak_usage_bytes",
                                Help: "Peak memory usage observed in bytes",
                        },
                        []string{"namespace", "pod", "container", "time_window"},
                ),

                MemoryAverageUsageBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_average_usage_bytes",
                                Help: "Average memory usage in bytes over time window",
                        },
                        []string{"namespace", "pod", "container", "time_window"},
                ),

                MemoryWasteBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_waste_bytes",
                                Help: "Wasted memory in bytes (allocated but unused)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryEfficiencyScore: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_efficiency_score",
                                Help: "Memory efficiency score (0-100, higher is better)",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                ContainerMemoryUsageBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_container_memory_usage_bytes",
                                Help: "Container-level memory usage in bytes",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                ContainerMemoryWorkingSetBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_container_memory_working_set_bytes",
                                Help: "Container-level working set memory in bytes",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                ContainerMemoryRSSBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_container_memory_rss_bytes",
                                Help: "Container-level RSS memory in bytes",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                ContainerMemoryCacheBytes: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_container_memory_cache_bytes",
                                Help: "Container-level cache memory in bytes",
                        },
                        []string{"namespace", "pod", "container"},
                ),

                MemoryAllocationFailures: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_allocation_failures_total",
                                Help: "Total number of memory allocation failures",
                        },
                        []string{"namespace", "pod", "container", "reason"},
                ),

                MemoryResizeOperations: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_resize_operations_total",
                                Help: "Total number of memory resize operations",
                        },
                        []string{"namespace", "pod", "container", "direction", "result"},
                ),

                MemoryResizeSuccessRate: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_memory_resize_success_rate",
                                Help: "Success rate of memory resize operations",
                        },
                        []string{"namespace", "pod", "container"},
                ),
        }

        // Register all metrics
        prometheus.MustRegister(
                metrics.PodMemoryUsageBytes,
                metrics.PodMemoryWorkingSetBytes,
                metrics.PodMemoryRSSBytes,
                metrics.PodMemoryCacheBytes,
                metrics.PodMemorySwapBytes,
                metrics.PodMemoryLimitBytes,
                metrics.PodMemoryRequestBytes,
                metrics.PodMemoryUtilizationPercentage,
                metrics.PodMemoryRequestUtilization,
                metrics.PodMemoryLimitUtilization,
                metrics.MemoryRecommendationBytes,
                metrics.MemoryRecommendationRatio,
                metrics.MemoryPressureEvents,
                metrics.MemoryPressureLevel,
                metrics.MemoryOOMKillEvents,
                metrics.MemoryThrottlingEvents,
                metrics.MemoryTrendSlope,
                metrics.MemoryPeakUsageBytes,
                metrics.MemoryAverageUsageBytes,
                metrics.MemoryWasteBytes,
                metrics.MemoryEfficiencyScore,
                metrics.ContainerMemoryUsageBytes,
                metrics.ContainerMemoryWorkingSetBytes,
                metrics.ContainerMemoryRSSBytes,
                metrics.ContainerMemoryCacheBytes,
                metrics.MemoryAllocationFailures,
                metrics.MemoryResizeOperations,
                metrics.MemoryResizeSuccessRate,
        )

        return metrics
}</span>

// UpdatePodMemoryMetrics updates all memory metrics for a pod
func (m *MemoryMetrics) UpdatePodMemoryMetrics(namespace, pod, container string, usage, workingSet, rss, cache, swap, limit, request float64) <span class="cov0" title="0">{
        m.PodMemoryUsageBytes.WithLabelValues(namespace, pod, container).Set(usage)
        m.PodMemoryWorkingSetBytes.WithLabelValues(namespace, pod, container).Set(workingSet)
        m.PodMemoryRSSBytes.WithLabelValues(namespace, pod, container).Set(rss)
        m.PodMemoryCacheBytes.WithLabelValues(namespace, pod, container).Set(cache)
        m.PodMemorySwapBytes.WithLabelValues(namespace, pod, container).Set(swap)
        m.PodMemoryLimitBytes.WithLabelValues(namespace, pod, container).Set(limit)
        m.PodMemoryRequestBytes.WithLabelValues(namespace, pod, container).Set(request)

        // Calculate utilization percentages
        if limit &gt; 0 </span><span class="cov0" title="0">{
                utilizationPct := (usage / limit) * 100
                m.PodMemoryUtilizationPercentage.WithLabelValues(namespace, pod, container).Set(utilizationPct)
                m.PodMemoryLimitUtilization.WithLabelValues(namespace, pod, container).Set(usage / limit)
        }</span>

        <span class="cov0" title="0">if request &gt; 0 </span><span class="cov0" title="0">{
                m.PodMemoryRequestUtilization.WithLabelValues(namespace, pod, container).Set(usage / request)
        }</span>

        // Calculate waste and efficiency
        <span class="cov0" title="0">if limit &gt; 0 &amp;&amp; usage &gt; 0 </span><span class="cov0" title="0">{
                waste := limit - usage
                m.MemoryWasteBytes.WithLabelValues(namespace, pod, container).Set(waste)

                efficiency := (usage / limit) * 100
                if efficiency &gt; 100 </span><span class="cov0" title="0">{
                        efficiency = 100
                }</span>
                <span class="cov0" title="0">m.MemoryEfficiencyScore.WithLabelValues(namespace, pod, container).Set(efficiency)</span>
        }
}

// RecordMemoryRecommendation records a memory sizing recommendation
func (m *MemoryMetrics) RecordMemoryRecommendation(namespace, pod, container, recommendationType string, recommendedBytes, currentBytes float64) <span class="cov0" title="0">{
        m.MemoryRecommendationBytes.WithLabelValues(namespace, pod, container, recommendationType).Set(recommendedBytes)

        if currentBytes &gt; 0 </span><span class="cov0" title="0">{
                ratio := recommendedBytes / currentBytes
                m.MemoryRecommendationRatio.WithLabelValues(namespace, pod, container, recommendationType).Set(ratio)
        }</span>
}

// DetectAndRecordMemoryPressure detects memory pressure and records metrics
func (m *MemoryMetrics) DetectAndRecordMemoryPressure(namespace, pod, container string, usage, limit float64) MemoryPressureLevel <span class="cov0" title="0">{
        if limit &lt;= 0 </span><span class="cov0" title="0">{
                return MemoryPressureNone
        }</span>

        <span class="cov0" title="0">utilizationRatio := usage / limit
        var pressureLevel MemoryPressureLevel

        switch </span>{
        case utilizationRatio &gt;= 0.95:<span class="cov0" title="0">
                pressureLevel = MemoryPressureCritical
                LogMemoryPressure(namespace, pod, container, "CRITICAL", usage, limit, utilizationRatio)</span>
        case utilizationRatio &gt;= 0.90:<span class="cov0" title="0">
                pressureLevel = MemoryPressureHigh
                LogMemoryPressure(namespace, pod, container, "HIGH", usage, limit, utilizationRatio)</span>
        case utilizationRatio &gt;= 0.80:<span class="cov0" title="0">
                pressureLevel = MemoryPressureMedium
                LogMemoryPressure(namespace, pod, container, "MEDIUM", usage, limit, utilizationRatio)</span>
        case utilizationRatio &gt;= 0.70:<span class="cov0" title="0">
                pressureLevel = MemoryPressureLow
                LogMemoryPressure(namespace, pod, container, "LOW", usage, limit, utilizationRatio)</span>
        default:<span class="cov0" title="0">
                pressureLevel = MemoryPressureNone</span>
        }

        <span class="cov0" title="0">if pressureLevel != MemoryPressureNone </span><span class="cov0" title="0">{
                m.MemoryPressureEvents.WithLabelValues(namespace, pod, container, pressureLevel.String()).Inc()
        }</span>

        <span class="cov0" title="0">m.MemoryPressureLevel.WithLabelValues(namespace, pod, container).Set(float64(pressureLevel))

        return pressureLevel</span>
}

// RecordOOMKill records an OOM kill event
func (m *MemoryMetrics) RecordOOMKill(namespace, pod, container string) <span class="cov0" title="0">{
        m.MemoryOOMKillEvents.WithLabelValues(namespace, pod, container).Inc()
        LogOOMKill(namespace, pod, container)
}</span>

// RecordMemoryThrottling records a memory throttling event
func (m *MemoryMetrics) RecordMemoryThrottling(namespace, pod, container string) <span class="cov0" title="0">{
        m.MemoryThrottlingEvents.WithLabelValues(namespace, pod, container).Inc()
        LogMemoryThrottling(namespace, pod, container)
}</span>

// UpdateMemoryTrend updates memory trend metrics
func (m *MemoryMetrics) UpdateMemoryTrend(namespace, pod, container string, slope, peak, average float64, timeWindow string) <span class="cov0" title="0">{
        m.MemoryTrendSlope.WithLabelValues(namespace, pod, container).Set(slope)
        m.MemoryPeakUsageBytes.WithLabelValues(namespace, pod, container, timeWindow).Set(peak)
        m.MemoryAverageUsageBytes.WithLabelValues(namespace, pod, container, timeWindow).Set(average)

        if slope &gt; 0.1 </span><span class="cov0" title="0">{
                LogMemoryTrend(namespace, pod, container, "INCREASING", slope, peak, average)
        }</span> else<span class="cov0" title="0"> if slope &lt; -0.1 </span><span class="cov0" title="0">{
                LogMemoryTrend(namespace, pod, container, "DECREASING", slope, peak, average)
        }</span>
}

// RecordMemoryResize records a memory resize operation
func (m *MemoryMetrics) RecordMemoryResize(namespace, pod, container, direction, result string) <span class="cov0" title="0">{
        m.MemoryResizeOperations.WithLabelValues(namespace, pod, container, direction, result).Inc()
        LogMemoryResize(namespace, pod, container, direction, result)
}</span>

// UpdateContainerMemoryMetrics updates container-specific memory metrics
func (m *MemoryMetrics) UpdateContainerMemoryMetrics(namespace, pod, container string, usage, workingSet, rss, cache float64) <span class="cov0" title="0">{
        m.ContainerMemoryUsageBytes.WithLabelValues(namespace, pod, container).Set(usage)
        m.ContainerMemoryWorkingSetBytes.WithLabelValues(namespace, pod, container).Set(workingSet)
        m.ContainerMemoryRSSBytes.WithLabelValues(namespace, pod, container).Set(rss)
        m.ContainerMemoryCacheBytes.WithLabelValues(namespace, pod, container).Set(cache)
}</span>

// Memory Pressure Logging Functions

// LogMemoryPressure logs memory pressure events with detailed information
func LogMemoryPressure(namespace, pod, container, level string, usage, limit, ratio float64) <span class="cov0" title="0">{
        klog.Warningf("[MEMORY_PRESSURE] %s detected for %s/%s/%s - Usage: %.2fMi/%.2fMi (%.1f%% utilization)",
                level, namespace, pod, container,
                usage/1024/1024, limit/1024/1024, ratio*100)

        // Additional context based on pressure level
        switch level </span>{
        case "CRITICAL":<span class="cov0" title="0">
                klog.Errorf("[MEMORY_CRITICAL] Pod %s/%s at risk of OOM kill - Immediate action required", namespace, pod)</span>
        case "HIGH":<span class="cov0" title="0">
                klog.Warningf("[MEMORY_HIGH] Pod %s/%s approaching memory limit - Consider increasing allocation", namespace, pod)</span>
        }
}

// LogOOMKill logs OOM kill events
func LogOOMKill(namespace, pod, container string) <span class="cov0" title="0">{
        klog.Errorf("[OOM_KILL] Container %s/%s/%s was OOM killed - Memory allocation insufficient",
                namespace, pod, container)
}</span>

// LogMemoryThrottling logs memory throttling events
func LogMemoryThrottling(namespace, pod, container string) <span class="cov0" title="0">{
        klog.Warningf("[MEMORY_THROTTLING] Container %s/%s/%s experiencing memory throttling - Performance degraded",
                namespace, pod, container)
}</span>

// LogMemoryTrend logs memory usage trends
func LogMemoryTrend(namespace, pod, container, trend string, slope, peak, average float64) <span class="cov0" title="0">{
        klog.Infof("[MEMORY_TREND] %s trend for %s/%s/%s - Slope: %.2f, Peak: %.2fMi, Avg: %.2fMi",
                trend, namespace, pod, container,
                slope, peak/1024/1024, average/1024/1024)

        if trend == "INCREASING" &amp;&amp; slope &gt; 0.5 </span><span class="cov0" title="0">{
                klog.Warningf("[MEMORY_LEAK] Potential memory leak detected in %s/%s/%s - Rapid increase in memory usage",
                        namespace, pod, container)
        }</span>
}

// LogMemoryResize logs memory resize operations
func LogMemoryResize(namespace, pod, container, direction, result string) <span class="cov0" title="0">{
        if result == "success" </span><span class="cov0" title="0">{
                klog.Infof("[MEMORY_RESIZE] Successfully %s memory for %s/%s/%s",
                        direction, namespace, pod, container)
        }</span> else<span class="cov0" title="0"> {
                klog.Errorf("[MEMORY_RESIZE] Failed to %s memory for %s/%s/%s: %s",
                        direction, namespace, pod, container, result)
        }</span>
}

// LogMemoryAllocation logs memory allocation events
func LogMemoryAllocation(namespace, pod, container string, requested, allocated, usage float64) <span class="cov0" title="0">{
        efficiency := (usage / allocated) * 100
        klog.Infof("[MEMORY_ALLOCATION] %s/%s/%s - Requested: %.2fMi, Allocated: %.2fMi, Used: %.2fMi (%.1f%% efficiency)",
                namespace, pod, container,
                requested/1024/1024, allocated/1024/1024, usage/1024/1024, efficiency)
}</span>

// LogMemoryRecommendation logs memory sizing recommendations
func LogMemoryRecommendation(namespace, pod, container string, current, recommended float64, reason string) <span class="cov0" title="0">{
        changePercent := ((recommended - current) / current) * 100
        klog.Infof("[MEMORY_RECOMMENDATION] %s/%s/%s - Current: %.2fMi, Recommended: %.2fMi (%.1f%% change) - Reason: %s",
                namespace, pod, container,
                current/1024/1024, recommended/1024/1024, changePercent, reason)
}</span>

// AnalyzeMemoryPattern analyzes memory usage patterns
func AnalyzeMemoryPattern(namespace, pod, container string, samples []float64) string <span class="cov0" title="0">{
        if len(samples) &lt; 2 </span><span class="cov0" title="0">{
                return "insufficient_data"
        }</span>

        // Calculate basic statistics
        <span class="cov0" title="0">var sum, max, min float64
        min = samples[0]
        for _, v := range samples </span><span class="cov0" title="0">{
                sum += v
                if v &gt; max </span><span class="cov0" title="0">{
                        max = v
                }</span>
                <span class="cov0" title="0">if v &lt; min </span><span class="cov0" title="0">{
                        min = v
                }</span>
        }
        <span class="cov0" title="0">avg := sum / float64(len(samples))

        // Detect patterns
        var pattern string
        variance := max - min
        varianceRatio := variance / avg

        switch </span>{
        case varianceRatio &lt; 0.1:<span class="cov0" title="0">
                pattern = "stable"
                klog.V(4).Infof("[MEMORY_PATTERN] %s/%s/%s - Stable memory usage pattern detected", namespace, pod, container)</span>
        case varianceRatio &lt; 0.3:<span class="cov0" title="0">
                pattern = "moderate_variance"
                klog.V(4).Infof("[MEMORY_PATTERN] %s/%s/%s - Moderate variance in memory usage", namespace, pod, container)</span>
        case varianceRatio &lt; 0.5:<span class="cov0" title="0">
                pattern = "high_variance"
                klog.Infof("[MEMORY_PATTERN] %s/%s/%s - High variance in memory usage - Consider buffer", namespace, pod, container)</span>
        default:<span class="cov0" title="0">
                pattern = "erratic"
                klog.Warningf("[MEMORY_PATTERN] %s/%s/%s - Erratic memory usage pattern - Investigate application behavior", namespace, pod, container)</span>
        }

        // Check for memory leak
        <span class="cov0" title="0">if len(samples) &gt; 10 </span><span class="cov0" title="0">{
                // Simple linear regression to detect trend
                var sumX, sumY, sumXY, sumX2 float64
                n := float64(len(samples))
                for i, y := range samples </span><span class="cov0" title="0">{
                        x := float64(i)
                        sumX += x
                        sumY += y
                        sumXY += x * y
                        sumX2 += x * x
                }</span>
                <span class="cov0" title="0">slope := (n*sumXY - sumX*sumY) / (n*sumX2 - sumX*sumX)

                if slope &gt; avg*0.01 </span><span class="cov0" title="0">{ // Growing more than 1% of average per sample
                        pattern = "potential_leak"
                        klog.Warningf("[MEMORY_LEAK_DETECTION] %s/%s/%s - Potential memory leak detected, slope: %.2f",
                                namespace, pod, container, slope)
                }</span>
        }

        <span class="cov0" title="0">return pattern</span>
}

// FormatMemorySize formats memory size in bytes to human-readable format
func FormatMemorySize(bytes float64) string <span class="cov0" title="0">{
        units := []string{"B", "Ki", "Mi", "Gi", "Ti"}
        size := bytes
        unitIndex := 0

        for size &gt;= 1024 &amp;&amp; unitIndex &lt; len(units)-1 </span><span class="cov0" title="0">{
                size /= 1024
                unitIndex++
        }</span>

        <span class="cov0" title="0">return fmt.Sprintf("%.2f%s", size, units[unitIndex])</span>
}
</pre>
		
		<pre class="file" id="file19" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package metrics

import (
        "context"
        "fmt"

        metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
        "k8s.io/client-go/rest"
        metricsclient "k8s.io/metrics/pkg/client/clientset/versioned"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// NewMetricsServerProvider returns a new metrics-server provider
func NewMetricsServerProvider(client client.Client) Provider <span class="cov0" title="0">{
        // Get the REST config
        config, err := rest.InClusterConfig()
        if err != nil </span><span class="cov0" title="0">{
                // Fallback for local development
                config = &amp;rest.Config{
                        Host: "https://localhost:6443",
                }
        }</span>

        // Create metrics client
        <span class="cov0" title="0">metricsClient, err := metricsclient.NewForConfig(config)
        if err != nil </span><span class="cov0" title="0">{
                // Return a provider that will fail gracefully
                return &amp;MetricsServerProvider{Client: client, MetricsClient: nil}
        }</span>

        <span class="cov0" title="0">return &amp;MetricsServerProvider{Client: client, MetricsClient: metricsClient}</span>
}

// FetchPodMetrics fetches CPU and memory usage for a pod from metrics-server
func (m *MetricsServerProvider) FetchPodMetrics(namespace, podName string) (Metrics, error) <span class="cov0" title="0">{
        if m.MetricsClient == nil </span><span class="cov0" title="0">{
                return Metrics{}, fmt.Errorf("metrics client not available")
        }</span>

        // Get pod metrics from metrics-server
        <span class="cov0" title="0">podMetrics, err := m.MetricsClient.MetricsV1beta1().PodMetricses(namespace).Get(context.TODO(), podName, metav1.GetOptions{})
        if err != nil </span><span class="cov0" title="0">{
                return Metrics{}, fmt.Errorf("failed to get pod metrics: %w", err)
        }</span>

        // Sum metrics across all containers
        <span class="cov0" title="0">var totalCPUMilli float64
        var totalMemBytes int64

        for _, container := range podMetrics.Containers </span><span class="cov0" title="0">{
                // CPU usage in millicores
                if cpuUsage, ok := container.Usage["cpu"]; ok </span><span class="cov0" title="0">{
                        totalCPUMilli += float64(cpuUsage.MilliValue())
                }</span>

                // Memory usage in bytes
                <span class="cov0" title="0">if memUsage, ok := container.Usage["memory"]; ok </span><span class="cov0" title="0">{
                        totalMemBytes += memUsage.Value()
                }</span>
        }

        // Convert memory bytes to MB
        <span class="cov0" title="0">totalMemMB := float64(totalMemBytes) / (1024 * 1024)

        return Metrics{
                CPUMilli: totalCPUMilli,
                MemMB:    totalMemMB,
        }, nil</span>
}
</pre>
		
		<pre class="file" id="file20" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package metrics

import (
        "net/http"
        "strconv"
        "time"

        "github.com/prometheus/client_golang/prometheus"
        "github.com/prometheus/client_golang/prometheus/promhttp"
)

// OperatorMetrics holds all Prometheus metrics for the right-sizer operator
type OperatorMetrics struct {
        // Pod processing metrics
        PodsProcessedTotal  prometheus.Counter
        PodsResizedTotal    *prometheus.CounterVec
        PodsSkippedTotal    *prometheus.CounterVec
        PodProcessingErrors *prometheus.CounterVec

        // Resource adjustment metrics
        CPUAdjustmentsTotal    *prometheus.CounterVec
        MemoryAdjustmentsTotal *prometheus.CounterVec
        ResourceChangeSize     *prometheus.HistogramVec

        // Performance metrics
        ProcessingDuration        *prometheus.HistogramVec
        APICallDuration           *prometheus.HistogramVec
        MetricsCollectionDuration prometheus.Histogram

        // Safety and validation metrics
        SafetyThresholdViolations *prometheus.CounterVec
        ResourceValidationErrors  *prometheus.CounterVec

        // Retry and error metrics
        RetryAttemptsTotal *prometheus.CounterVec
        RetrySuccessTotal  *prometheus.CounterVec

        // Cluster resource metrics
        ClusterResourceUtilization *prometheus.GaugeVec
        NodeResourceAvailability   *prometheus.GaugeVec

        // Policy and configuration metrics
        PolicyRuleApplications *prometheus.CounterVec
        ConfigurationReloads   prometheus.Counter

        // Historical trend metrics
        ResourceTrendPredictions *prometheus.GaugeVec
        HistoricalDataPoints     prometheus.Gauge
}

// NewOperatorMetrics creates and registers all Prometheus metrics
func NewOperatorMetrics() *OperatorMetrics <span class="cov0" title="0">{
        metrics := &amp;OperatorMetrics{
                PodsProcessedTotal: prometheus.NewCounter(prometheus.CounterOpts{
                        Name: "rightsizer_pods_processed_total",
                        Help: "Total number of pods processed by the right-sizer operator",
                }),

                PodsResizedTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_pods_resized_total",
                                Help: "Total number of pods that were resized",
                        },
                        []string{"namespace", "pod_name", "container_name", "resize_type"},
                ),

                PodsSkippedTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_pods_skipped_total",
                                Help: "Total number of pods that were skipped from resizing",
                        },
                        []string{"namespace", "pod_name", "reason"},
                ),

                PodProcessingErrors: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_pod_processing_errors_total",
                                Help: "Total number of errors encountered while processing pods",
                        },
                        []string{"namespace", "pod_name", "error_type"},
                ),

                CPUAdjustmentsTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_cpu_adjustments_total",
                                Help: "Total number of CPU resource adjustments made",
                        },
                        []string{"namespace", "pod_name", "container_name", "direction"},
                ),

                MemoryAdjustmentsTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_memory_adjustments_total",
                                Help: "Total number of memory resource adjustments made",
                        },
                        []string{"namespace", "pod_name", "container_name", "direction"},
                ),

                ResourceChangeSize: prometheus.NewHistogramVec(
                        prometheus.HistogramOpts{
                                Name:    "rightsizer_resource_change_percentage",
                                Help:    "Distribution of resource change percentages",
                                Buckets: prometheus.LinearBuckets(0, 10, 11), // 0%, 10%, 20%, ..., 100%
                        },
                        []string{"resource_type", "direction"},
                ),

                ProcessingDuration: prometheus.NewHistogramVec(
                        prometheus.HistogramOpts{
                                Name:    "rightsizer_processing_duration_seconds",
                                Help:    "Time spent processing pods for right-sizing",
                                Buckets: prometheus.DefBuckets,
                        },
                        []string{"operation"},
                ),

                APICallDuration: prometheus.NewHistogramVec(
                        prometheus.HistogramOpts{
                                Name:    "rightsizer_api_call_duration_seconds",
                                Help:    "Duration of Kubernetes API calls",
                                Buckets: prometheus.DefBuckets,
                        },
                        []string{"api_endpoint", "method"},
                ),

                MetricsCollectionDuration: prometheus.NewHistogram(
                        prometheus.HistogramOpts{
                                Name:    "rightsizer_metrics_collection_duration_seconds",
                                Help:    "Time spent collecting metrics from metrics providers",
                                Buckets: prometheus.DefBuckets,
                        },
                ),

                SafetyThresholdViolations: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_safety_threshold_violations_total",
                                Help: "Total number of times safety threshold was violated",
                        },
                        []string{"namespace", "pod_name", "resource_type"},
                ),

                ResourceValidationErrors: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_resource_validation_errors_total",
                                Help: "Total number of resource validation errors",
                        },
                        []string{"validation_type", "error_reason"},
                ),

                RetryAttemptsTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_retry_attempts_total",
                                Help: "Total number of retry attempts for operations",
                        },
                        []string{"operation", "attempt_number"},
                ),

                RetrySuccessTotal: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_retry_success_total",
                                Help: "Total number of successful retries",
                        },
                        []string{"operation"},
                ),

                ClusterResourceUtilization: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_cluster_resource_utilization_ratio",
                                Help: "Current cluster resource utilization ratio",
                        },
                        []string{"resource_type", "node_name"},
                ),

                NodeResourceAvailability: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_node_resource_availability",
                                Help: "Available resources on cluster nodes",
                        },
                        []string{"resource_type", "node_name"},
                ),

                PolicyRuleApplications: prometheus.NewCounterVec(
                        prometheus.CounterOpts{
                                Name: "rightsizer_policy_rule_applications_total",
                                Help: "Total number of policy rule applications",
                        },
                        []string{"policy_name", "rule_type", "result"},
                ),

                ConfigurationReloads: prometheus.NewCounter(prometheus.CounterOpts{
                        Name: "rightsizer_configuration_reloads_total",
                        Help: "Total number of configuration reloads",
                }),

                ResourceTrendPredictions: prometheus.NewGaugeVec(
                        prometheus.GaugeOpts{
                                Name: "rightsizer_resource_trend_predictions",
                                Help: "Predicted resource requirements based on historical trends",
                        },
                        []string{"namespace", "pod_name", "container_name", "resource_type", "prediction_horizon"},
                ),

                HistoricalDataPoints: prometheus.NewGauge(prometheus.GaugeOpts{
                        Name: "rightsizer_historical_data_points",
                        Help: "Number of historical data points stored",
                }),
        }

        // Register all metrics
        prometheus.MustRegister(
                metrics.PodsProcessedTotal,
                metrics.PodsResizedTotal,
                metrics.PodsSkippedTotal,
                metrics.PodProcessingErrors,
                metrics.CPUAdjustmentsTotal,
                metrics.MemoryAdjustmentsTotal,
                metrics.ResourceChangeSize,
                metrics.ProcessingDuration,
                metrics.APICallDuration,
                metrics.MetricsCollectionDuration,
                metrics.SafetyThresholdViolations,
                metrics.ResourceValidationErrors,
                metrics.RetryAttemptsTotal,
                metrics.RetrySuccessTotal,
                metrics.ClusterResourceUtilization,
                metrics.NodeResourceAvailability,
                metrics.PolicyRuleApplications,
                metrics.ConfigurationReloads,
                metrics.ResourceTrendPredictions,
                metrics.HistoricalDataPoints,
        )

        return metrics
}</span>

// RecordPodProcessed records that a pod has been processed
func (m *OperatorMetrics) RecordPodProcessed() <span class="cov0" title="0">{
        m.PodsProcessedTotal.Inc()
}</span>

// RecordPodResized records that a pod has been resized
func (m *OperatorMetrics) RecordPodResized(namespace, podName, containerName, resizeType string) <span class="cov0" title="0">{
        m.PodsResizedTotal.WithLabelValues(namespace, podName, containerName, resizeType).Inc()
}</span>

// RecordPodSkipped records that a pod was skipped
func (m *OperatorMetrics) RecordPodSkipped(namespace, podName, reason string) <span class="cov0" title="0">{
        m.PodsSkippedTotal.WithLabelValues(namespace, podName, reason).Inc()
}</span>

// RecordProcessingError records a processing error
func (m *OperatorMetrics) RecordProcessingError(namespace, podName, errorType string) <span class="cov0" title="0">{
        m.PodProcessingErrors.WithLabelValues(namespace, podName, errorType).Inc()
}</span>

// RecordResourceAdjustment records a resource adjustment
func (m *OperatorMetrics) RecordResourceAdjustment(namespace, podName, containerName, resourceType, direction string, changePercentage float64) <span class="cov0" title="0">{
        if resourceType == "cpu" </span><span class="cov0" title="0">{
                m.CPUAdjustmentsTotal.WithLabelValues(namespace, podName, containerName, direction).Inc()
        }</span> else<span class="cov0" title="0"> if resourceType == "memory" </span><span class="cov0" title="0">{
                m.MemoryAdjustmentsTotal.WithLabelValues(namespace, podName, containerName, direction).Inc()
        }</span>

        <span class="cov0" title="0">m.ResourceChangeSize.WithLabelValues(resourceType, direction).Observe(changePercentage)</span>
}

// RecordProcessingDuration records the duration of a processing operation
func (m *OperatorMetrics) RecordProcessingDuration(operation string, duration time.Duration) <span class="cov0" title="0">{
        m.ProcessingDuration.WithLabelValues(operation).Observe(duration.Seconds())
}</span>

// RecordAPICall records the duration of an API call
func (m *OperatorMetrics) RecordAPICall(endpoint, method string, duration time.Duration) <span class="cov0" title="0">{
        m.APICallDuration.WithLabelValues(endpoint, method).Observe(duration.Seconds())
}</span>

// RecordMetricsCollection records the duration of metrics collection
func (m *OperatorMetrics) RecordMetricsCollection(duration time.Duration) <span class="cov0" title="0">{
        m.MetricsCollectionDuration.Observe(duration.Seconds())
}</span>

// RecordSafetyThresholdViolation records a safety threshold violation
func (m *OperatorMetrics) RecordSafetyThresholdViolation(namespace, podName, resourceType string) <span class="cov0" title="0">{
        m.SafetyThresholdViolations.WithLabelValues(namespace, podName, resourceType).Inc()
}</span>

// RecordResourceValidationError records a resource validation error
func (m *OperatorMetrics) RecordResourceValidationError(validationType, errorReason string) <span class="cov0" title="0">{
        m.ResourceValidationErrors.WithLabelValues(validationType, errorReason).Inc()
}</span>

// RecordRetryAttempt records a retry attempt
func (m *OperatorMetrics) RecordRetryAttempt(operation string, attemptNumber int) <span class="cov0" title="0">{
        m.RetryAttemptsTotal.WithLabelValues(operation, strconv.Itoa(attemptNumber)).Inc()
}</span>

// RecordRetrySuccess records a successful retry
func (m *OperatorMetrics) RecordRetrySuccess(operation string) <span class="cov0" title="0">{
        m.RetrySuccessTotal.WithLabelValues(operation).Inc()
}</span>

// UpdateClusterResourceUtilization updates cluster resource utilization metrics
func (m *OperatorMetrics) UpdateClusterResourceUtilization(resourceType, nodeName string, utilization float64) <span class="cov0" title="0">{
        m.ClusterResourceUtilization.WithLabelValues(resourceType, nodeName).Set(utilization)
}</span>

// UpdateNodeResourceAvailability updates node resource availability metrics
func (m *OperatorMetrics) UpdateNodeResourceAvailability(resourceType, nodeName string, available float64) <span class="cov0" title="0">{
        m.NodeResourceAvailability.WithLabelValues(resourceType, nodeName).Set(available)
}</span>

// RecordPolicyRuleApplication records a policy rule application
func (m *OperatorMetrics) RecordPolicyRuleApplication(policyName, ruleType, result string) <span class="cov0" title="0">{
        m.PolicyRuleApplications.WithLabelValues(policyName, ruleType, result).Inc()
}</span>

// RecordConfigurationReload records a configuration reload
func (m *OperatorMetrics) RecordConfigurationReload() <span class="cov0" title="0">{
        m.ConfigurationReloads.Inc()
}</span>

// UpdateResourceTrendPrediction updates resource trend prediction metrics
func (m *OperatorMetrics) UpdateResourceTrendPrediction(namespace, podName, containerName, resourceType, predictionHorizon string, prediction float64) <span class="cov0" title="0">{
        m.ResourceTrendPredictions.WithLabelValues(namespace, podName, containerName, resourceType, predictionHorizon).Set(prediction)
}</span>

// UpdateHistoricalDataPoints updates the count of historical data points
func (m *OperatorMetrics) UpdateHistoricalDataPoints(count float64) <span class="cov0" title="0">{
        m.HistoricalDataPoints.Set(count)
}</span>

// StartMetricsServer starts the Prometheus metrics HTTP server
func StartMetricsServer(port int) error <span class="cov0" title="0">{
        http.Handle("/metrics", promhttp.Handler())

        // Add custom health check for metrics
        http.HandleFunc("/metrics/health", func(w http.ResponseWriter, r *http.Request) </span><span class="cov0" title="0">{
                w.WriteHeader(http.StatusOK)
                w.Write([]byte("metrics server healthy"))
        }</span>)

        <span class="cov0" title="0">return http.ListenAndServe(":"+strconv.Itoa(port), nil)</span>
}

// Timer is a helper for measuring operation durations
type Timer struct {
        start time.Time
}

// NewTimer creates a new timer
func NewTimer() *Timer <span class="cov0" title="0">{
        return &amp;Timer{start: time.Now()}
}</span>

// Duration returns the elapsed duration since the timer was created
func (t *Timer) Duration() time.Duration <span class="cov0" title="0">{
        return time.Since(t.start)
}</span>

// ObserveDuration observes the duration in the given histogram
func (t *Timer) ObserveDuration(observer prometheus.Observer) <span class="cov0" title="0">{
        observer.Observe(t.Duration().Seconds())
}</span>
</pre>
		
		<pre class="file" id="file21" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
package metrics

import (
        "encoding/json"
        "fmt"
        "io/ioutil"
        "net/http"
        "net/url"
)

// NewPrometheusProvider returns a PrometheusProvider
func NewPrometheusProvider(promURL string) Provider <span class="cov0" title="0">{
        return &amp;PrometheusProvider{URL: promURL}
}</span>

// FetchPodMetrics queries Prometheus for CPU and memory usage for a pod
func (p *PrometheusProvider) FetchPodMetrics(namespace, podName string) (Metrics, error) <span class="cov0" title="0">{
        // Query CPU usage (millicores)
        cpuQuery := fmt.Sprintf(`sum(rate(container_cpu_usage_seconds_total{namespace="%s", pod="%s"}[5m])) * 1000`, namespace, podName)
        cpuMilli, err := p.queryPrometheus(cpuQuery)
        if err != nil </span><span class="cov0" title="0">{
                return Metrics{}, fmt.Errorf("failed to query CPU metrics: %w", err)
        }</span>

        // Query memory usage (bytes)
        <span class="cov0" title="0">memQuery := fmt.Sprintf(`sum(container_memory_usage_bytes{namespace="%s", pod="%s"})`, namespace, podName)
        memBytes, err := p.queryPrometheus(memQuery)
        if err != nil </span><span class="cov0" title="0">{
                return Metrics{}, fmt.Errorf("failed to query memory metrics: %w", err)
        }</span>

        // Convert bytes to MB
        <span class="cov0" title="0">memMB := memBytes / (1024 * 1024)

        return Metrics{
                CPUMilli: cpuMilli,
                MemMB:    memMB,
        }, nil</span>
}

// queryPrometheus runs a Prometheus instant query and returns the value
func (p *PrometheusProvider) queryPrometheus(query string) (float64, error) <span class="cov0" title="0">{
        endpoint := fmt.Sprintf("%s/api/v1/query?query=%s", p.URL, url.QueryEscape(query))
        resp, err := http.Get(endpoint)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov0" title="0">defer resp.Body.Close()

        body, err := ioutil.ReadAll(resp.Body)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov0" title="0">var result struct {
                Status string `json:"status"`
                Data   struct {
                        ResultType string `json:"resultType"`
                        Result     []struct {
                                Value []interface{} `json:"value"`
                        } `json:"result"`
                } `json:"data"`
        }
        if err := json.Unmarshal(body, &amp;result); err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>

        <span class="cov0" title="0">if result.Status != "success" || len(result.Data.Result) == 0 </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("no data returned from Prometheus")
        }</span>

        // Value[1] is the string representation of the metric value
        <span class="cov0" title="0">valStr, ok := result.Data.Result[0].Value[1].(string)
        if !ok </span><span class="cov0" title="0">{
                return 0, fmt.Errorf("unexpected value format")
        }</span>

        <span class="cov0" title="0">var val float64
        _, err = fmt.Sscanf(valStr, "%f", &amp;val)
        if err != nil </span><span class="cov0" title="0">{
                return 0, err
        }</span>
        <span class="cov0" title="0">return val, nil</span>
}
</pre>
		
		<pre class="file" id="file22" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package policy

import (
        "context"
        "fmt"
        "regexp"
        "strings"
        "time"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        "k8s.io/apimachinery/pkg/labels"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// PolicyEngine manages and evaluates resource sizing policies
type PolicyEngine struct {
        client  client.Client
        config  *config.Config
        metrics *metrics.OperatorMetrics
        rules   []Rule
}

// Rule represents a resource sizing rule
type Rule struct {
        Name        string        `json:"name" yaml:"name"`
        Description string        `json:"description" yaml:"description"`
        Priority    int           `json:"priority" yaml:"priority"`
        Selectors   RuleSelectors `json:"selectors" yaml:"selectors"`
        Actions     RuleActions   `json:"actions" yaml:"actions"`
        Schedule    *RuleSchedule `json:"schedule,omitempty" yaml:"schedule,omitempty"`
        Enabled     bool          `json:"enabled" yaml:"enabled"`
}

// RuleSelectors defines criteria for rule matching
type RuleSelectors struct {
        Namespaces    []string          `json:"namespaces,omitempty" yaml:"namespaces,omitempty"`
        Labels        map[string]string `json:"labels,omitempty" yaml:"labels,omitempty"`
        Annotations   map[string]string `json:"annotations,omitempty" yaml:"annotations,omitempty"`
        PodNameRegex  string            `json:"podNameRegex,omitempty" yaml:"podNameRegex,omitempty"`
        ContainerName string            `json:"containerName,omitempty" yaml:"containerName,omitempty"`
        QoSClass      string            `json:"qosClass,omitempty" yaml:"qosClass,omitempty"`
        WorkloadType  string            `json:"workloadType,omitempty" yaml:"workloadType,omitempty"`
}

// RuleActions defines what actions to take when rule matches
type RuleActions struct {
        CPUMultiplier    *float64 `json:"cpuMultiplier,omitempty" yaml:"cpuMultiplier,omitempty"`
        MemoryMultiplier *float64 `json:"memoryMultiplier,omitempty" yaml:"memoryMultiplier,omitempty"`
        MinCPU           *string  `json:"minCPU,omitempty" yaml:"minCPU,omitempty"`
        MaxCPU           *string  `json:"maxCPU,omitempty" yaml:"maxCPU,omitempty"`
        MinMemory        *string  `json:"minMemory,omitempty" yaml:"minMemory,omitempty"`
        MaxMemory        *string  `json:"maxMemory,omitempty" yaml:"maxMemory,omitempty"`
        SetCPURequest    *string  `json:"setCPURequest,omitempty" yaml:"setCPURequest,omitempty"`
        SetMemoryRequest *string  `json:"setMemoryRequest,omitempty" yaml:"setMemoryRequest,omitempty"`
        SetCPULimit      *string  `json:"setCPULimit,omitempty" yaml:"setCPULimit,omitempty"`
        SetMemoryLimit   *string  `json:"setMemoryLimit,omitempty" yaml:"setMemoryLimit,omitempty"`
        Skip             bool     `json:"skip,omitempty" yaml:"skip,omitempty"`
}

// RuleSchedule defines when a rule should be active
type RuleSchedule struct {
        TimeRanges []TimeRange `json:"timeRanges,omitempty" yaml:"timeRanges,omitempty"`
        DaysOfWeek []string    `json:"daysOfWeek,omitempty" yaml:"daysOfWeek,omitempty"`
        Timezone   string      `json:"timezone,omitempty" yaml:"timezone,omitempty"`
}

// TimeRange represents a time range during which a rule is active
type TimeRange struct {
        Start string `json:"start" yaml:"start"` // HH:MM format
        End   string `json:"end" yaml:"end"`     // HH:MM format
}

// PolicyEvaluationResult contains the result of policy evaluation
type PolicyEvaluationResult struct {
        AppliedRules      []string
        RecommendedCPU    *resource.Quantity
        RecommendedMemory *resource.Quantity
        CPULimit          *resource.Quantity
        MemoryLimit       *resource.Quantity
        Skip              bool
        Reason            string
}

// NewPolicyEngine creates a new policy engine
func NewPolicyEngine(client client.Client, cfg *config.Config, metrics *metrics.OperatorMetrics) *PolicyEngine <span class="cov0" title="0">{
        return &amp;PolicyEngine{
                client:  client,
                config:  cfg,
                metrics: metrics,
                rules:   []Rule{},
        }
}</span>

// LoadRules loads rules from ConfigMap
func (pe *PolicyEngine) LoadRules(ctx context.Context, configMapName, namespace string) error <span class="cov0" title="0">{
        configMap := &amp;corev1.ConfigMap{}
        err := pe.client.Get(ctx, client.ObjectKey{
                Name:      configMapName,
                Namespace: namespace,
        }, configMap)

        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to load policy ConfigMap %s/%s: %v", namespace, configMapName, err)
        }</span>

        // Parse rules from ConfigMap data
        <span class="cov0" title="0">rules, err := pe.parseRulesFromConfigMap(configMap)
        if err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to parse rules: %v", err)
        }</span>

        <span class="cov0" title="0">pe.rules = rules
        logger.Info("Loaded %d policy rules from ConfigMap %s/%s", len(rules), namespace, configMapName)

        return nil</span>
}

// AddRule adds a rule to the policy engine
func (pe *PolicyEngine) AddRule(rule Rule) <span class="cov0" title="0">{
        pe.rules = append(pe.rules, rule)
        logger.Debug("Added policy rule: %s", rule.Name)
}</span>

// EvaluatePolicy evaluates policies for a pod and returns sizing recommendations
func (pe *PolicyEngine) EvaluatePolicy(ctx context.Context, pod *corev1.Pod, containerName string, currentUsage map[string]*resource.Quantity) *PolicyEvaluationResult <span class="cov0" title="0">{
        result := &amp;PolicyEvaluationResult{
                AppliedRules: []string{},
        }

        // Sort rules by priority (higher priority first)
        sortedRules := pe.sortRulesByPriority()

        for _, rule := range sortedRules </span><span class="cov0" title="0">{
                if !rule.Enabled </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Check if rule matches
                <span class="cov0" title="0">if matches, reason := pe.ruleMatches(ctx, rule, pod, containerName); matches </span><span class="cov0" title="0">{
                        result.AppliedRules = append(result.AppliedRules, rule.Name)

                        // Apply rule actions
                        pe.applyRuleActions(rule, pod, containerName, currentUsage, result)

                        // Record metrics
                        if pe.metrics != nil </span><span class="cov0" title="0">{
                                pe.metrics.RecordPolicyRuleApplication(rule.Name, "resource_sizing", "applied")
                        }</span>

                        <span class="cov0" title="0">logger.Debug("Applied policy rule %s to pod %s/%s container %s",
                                rule.Name, pod.Namespace, pod.Name, containerName)

                        // If rule says to skip, break early
                        if result.Skip </span><span class="cov0" title="0">{
                                result.Reason = fmt.Sprintf("Skipped by policy rule: %s", rule.Name)
                                break</span>
                        }
                } else<span class="cov0" title="0"> if reason != "" </span><span class="cov0" title="0">{
                        logger.Debug("Rule %s did not match pod %s/%s: %s", rule.Name, pod.Namespace, pod.Name, reason)
                }</span>
        }

        <span class="cov0" title="0">return result</span>
}

// ruleMatches checks if a rule matches the given pod and container
func (pe *PolicyEngine) ruleMatches(ctx context.Context, rule Rule, pod *corev1.Pod, containerName string) (bool, string) <span class="cov0" title="0">{
        selectors := rule.Selectors

        // Check schedule
        if rule.Schedule != nil &amp;&amp; !pe.isRuleScheduleActive(rule.Schedule) </span><span class="cov0" title="0">{
                return false, "rule not active according to schedule"
        }</span>

        // Check namespace
        <span class="cov0" title="0">if len(selectors.Namespaces) &gt; 0 </span><span class="cov0" title="0">{
                found := false
                for _, ns := range selectors.Namespaces </span><span class="cov0" title="0">{
                        if ns == pod.Namespace </span><span class="cov0" title="0">{
                                found = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !found </span><span class="cov0" title="0">{
                        return false, "namespace not in selector list"
                }</span>
        }

        // Check labels
        <span class="cov0" title="0">if len(selectors.Labels) &gt; 0 </span><span class="cov0" title="0">{
                podLabels := labels.Set(pod.Labels)
                ruleLabels := labels.Set(selectors.Labels)
                if !ruleLabels.AsSelector().Matches(podLabels) </span><span class="cov0" title="0">{
                        return false, "labels do not match"
                }</span>
        }

        // Check annotations
        <span class="cov0" title="0">if len(selectors.Annotations) &gt; 0 </span><span class="cov0" title="0">{
                for key, value := range selectors.Annotations </span><span class="cov0" title="0">{
                        if podValue, exists := pod.Annotations[key]; !exists || podValue != value </span><span class="cov0" title="0">{
                                return false, fmt.Sprintf("annotation %s does not match", key)
                        }</span>
                }
        }

        // Check pod name regex
        <span class="cov0" title="0">if selectors.PodNameRegex != "" </span><span class="cov0" title="0">{
                matched, err := regexp.MatchString(selectors.PodNameRegex, pod.Name)
                if err != nil </span><span class="cov0" title="0">{
                        logger.Warn("Invalid regex in rule %s: %v", rule.Name, err)
                        return false, "invalid regex pattern"
                }</span>
                <span class="cov0" title="0">if !matched </span><span class="cov0" title="0">{
                        return false, "pod name does not match regex"
                }</span>
        }

        // Check container name
        <span class="cov0" title="0">if selectors.ContainerName != "" &amp;&amp; selectors.ContainerName != containerName </span><span class="cov0" title="0">{
                return false, "container name does not match"
        }</span>

        // Check QoS class
        <span class="cov0" title="0">if selectors.QoSClass != "" </span><span class="cov0" title="0">{
                podQoS := string(getQoSClass(pod))
                if selectors.QoSClass != podQoS </span><span class="cov0" title="0">{
                        return false, fmt.Sprintf("QoS class %s does not match %s", podQoS, selectors.QoSClass)
                }</span>
        }

        // Check workload type
        <span class="cov0" title="0">if selectors.WorkloadType != "" </span><span class="cov0" title="0">{
                workloadType := pe.getWorkloadType(pod)
                if selectors.WorkloadType != workloadType </span><span class="cov0" title="0">{
                        return false, fmt.Sprintf("workload type %s does not match %s", workloadType, selectors.WorkloadType)
                }</span>
        }

        <span class="cov0" title="0">return true, ""</span>
}

// applyRuleActions applies the actions of a matched rule
func (pe *PolicyEngine) applyRuleActions(rule Rule, pod *corev1.Pod, containerName string, currentUsage map[string]*resource.Quantity, result *PolicyEvaluationResult) <span class="cov0" title="0">{
        actions := rule.Actions

        // Check if we should skip
        if actions.Skip </span><span class="cov0" title="0">{
                result.Skip = true
                return
        }</span>

        // Get current CPU and memory usage
        <span class="cov0" title="0">var cpuUsage, memoryUsage *resource.Quantity
        if usage, exists := currentUsage["cpu"]; exists </span><span class="cov0" title="0">{
                cpuUsage = usage
        }</span>
        <span class="cov0" title="0">if usage, exists := currentUsage["memory"]; exists </span><span class="cov0" title="0">{
                memoryUsage = usage
        }</span>

        // Apply CPU multiplier
        <span class="cov0" title="0">if actions.CPUMultiplier != nil &amp;&amp; cpuUsage != nil </span><span class="cov0" title="0">{
                newCPU := resource.NewMilliQuantity(
                        int64(float64(cpuUsage.MilliValue())*(*actions.CPUMultiplier)),
                        resource.DecimalSI,
                )
                result.RecommendedCPU = newCPU
        }</span>

        // Apply memory multiplier
        <span class="cov0" title="0">if actions.MemoryMultiplier != nil &amp;&amp; memoryUsage != nil </span><span class="cov0" title="0">{
                newMemory := resource.NewQuantity(
                        int64(float64(memoryUsage.Value())*(*actions.MemoryMultiplier)),
                        resource.BinarySI,
                )
                result.RecommendedMemory = newMemory
        }</span>

        // Apply fixed CPU request
        <span class="cov0" title="0">if actions.SetCPURequest != nil </span><span class="cov0" title="0">{
                if cpu, err := resource.ParseQuantity(*actions.SetCPURequest); err == nil </span><span class="cov0" title="0">{
                        result.RecommendedCPU = &amp;cpu
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("Invalid CPU request in rule %s: %v", rule.Name, err)
                }</span>
        }

        // Apply fixed memory request
        <span class="cov0" title="0">if actions.SetMemoryRequest != nil </span><span class="cov0" title="0">{
                if mem, err := resource.ParseQuantity(*actions.SetMemoryRequest); err == nil </span><span class="cov0" title="0">{
                        result.RecommendedMemory = &amp;mem
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("Invalid memory request in rule %s: %v", rule.Name, err)
                }</span>
        }

        // Apply CPU limit
        <span class="cov0" title="0">if actions.SetCPULimit != nil </span><span class="cov0" title="0">{
                if cpu, err := resource.ParseQuantity(*actions.SetCPULimit); err == nil </span><span class="cov0" title="0">{
                        result.CPULimit = &amp;cpu
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("Invalid CPU limit in rule %s: %v", rule.Name, err)
                }</span>
        }

        // Apply memory limit
        <span class="cov0" title="0">if actions.SetMemoryLimit != nil </span><span class="cov0" title="0">{
                if mem, err := resource.ParseQuantity(*actions.SetMemoryLimit); err == nil </span><span class="cov0" title="0">{
                        result.MemoryLimit = &amp;mem
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("Invalid memory limit in rule %s: %v", rule.Name, err)
                }</span>
        }

        // Apply min/max constraints
        <span class="cov0" title="0">pe.applyMinMaxConstraints(actions, result)</span>
}

// applyMinMaxConstraints applies minimum and maximum resource constraints
func (pe *PolicyEngine) applyMinMaxConstraints(actions RuleActions, result *PolicyEvaluationResult) <span class="cov0" title="0">{
        // Apply CPU constraints
        if result.RecommendedCPU != nil </span><span class="cov0" title="0">{
                if actions.MinCPU != nil </span><span class="cov0" title="0">{
                        if minCPU, err := resource.ParseQuantity(*actions.MinCPU); err == nil </span><span class="cov0" title="0">{
                                if result.RecommendedCPU.Cmp(minCPU) &lt; 0 </span><span class="cov0" title="0">{
                                        result.RecommendedCPU = &amp;minCPU
                                }</span>
                        }
                }
                <span class="cov0" title="0">if actions.MaxCPU != nil </span><span class="cov0" title="0">{
                        if maxCPU, err := resource.ParseQuantity(*actions.MaxCPU); err == nil </span><span class="cov0" title="0">{
                                if result.RecommendedCPU.Cmp(maxCPU) &gt; 0 </span><span class="cov0" title="0">{
                                        result.RecommendedCPU = &amp;maxCPU
                                }</span>
                        }
                }
        }

        // Apply memory constraints
        <span class="cov0" title="0">if result.RecommendedMemory != nil </span><span class="cov0" title="0">{
                if actions.MinMemory != nil </span><span class="cov0" title="0">{
                        if minMem, err := resource.ParseQuantity(*actions.MinMemory); err == nil </span><span class="cov0" title="0">{
                                if result.RecommendedMemory.Cmp(minMem) &lt; 0 </span><span class="cov0" title="0">{
                                        result.RecommendedMemory = &amp;minMem
                                }</span>
                        }
                }
                <span class="cov0" title="0">if actions.MaxMemory != nil </span><span class="cov0" title="0">{
                        if maxMem, err := resource.ParseQuantity(*actions.MaxMemory); err == nil </span><span class="cov0" title="0">{
                                if result.RecommendedMemory.Cmp(maxMem) &gt; 0 </span><span class="cov0" title="0">{
                                        result.RecommendedMemory = &amp;maxMem
                                }</span>
                        }
                }
        }
}

// isRuleScheduleActive checks if a rule is currently active based on its schedule
func (pe *PolicyEngine) isRuleScheduleActive(schedule *RuleSchedule) bool <span class="cov0" title="0">{
        now := time.Now()

        // Load timezone if specified
        if schedule.Timezone != "" </span><span class="cov0" title="0">{
                if loc, err := time.LoadLocation(schedule.Timezone); err == nil </span><span class="cov0" title="0">{
                        now = now.In(loc)
                }</span> else<span class="cov0" title="0"> {
                        logger.Warn("Invalid timezone %s, using local time", schedule.Timezone)
                }</span>
        }

        // Check days of week
        <span class="cov0" title="0">if len(schedule.DaysOfWeek) &gt; 0 </span><span class="cov0" title="0">{
                currentDay := now.Weekday().String()
                dayMatch := false
                for _, day := range schedule.DaysOfWeek </span><span class="cov0" title="0">{
                        if strings.EqualFold(day, currentDay) </span><span class="cov0" title="0">{
                                dayMatch = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !dayMatch </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        // Check time ranges
        <span class="cov0" title="0">if len(schedule.TimeRanges) &gt; 0 </span><span class="cov0" title="0">{
                currentTime := now.Format("15:04")
                timeMatch := false
                for _, timeRange := range schedule.TimeRanges </span><span class="cov0" title="0">{
                        if pe.isTimeInRange(currentTime, timeRange.Start, timeRange.End) </span><span class="cov0" title="0">{
                                timeMatch = true
                                break</span>
                        }
                }
                <span class="cov0" title="0">if !timeMatch </span><span class="cov0" title="0">{
                        return false
                }</span>
        }

        <span class="cov0" title="0">return true</span>
}

// isTimeInRange checks if a time is within a given range
func (pe *PolicyEngine) isTimeInRange(current, start, end string) bool <span class="cov0" title="0">{
        return strings.Compare(current, start) &gt;= 0 &amp;&amp; strings.Compare(current, end) &lt;= 0
}</span>

// sortRulesByPriority sorts rules by priority (descending)
func (pe *PolicyEngine) sortRulesByPriority() []Rule <span class="cov0" title="0">{
        rules := make([]Rule, len(pe.rules))
        copy(rules, pe.rules)

        // Simple bubble sort by priority (higher priority first)
        for i := 0; i &lt; len(rules)-1; i++ </span><span class="cov0" title="0">{
                for j := 0; j &lt; len(rules)-i-1; j++ </span><span class="cov0" title="0">{
                        if rules[j].Priority &lt; rules[j+1].Priority </span><span class="cov0" title="0">{
                                rules[j], rules[j+1] = rules[j+1], rules[j]
                        }</span>
                }
        }

        <span class="cov0" title="0">return rules</span>
}

// getWorkloadType determines the workload type of a pod
func (pe *PolicyEngine) getWorkloadType(pod *corev1.Pod) string <span class="cov0" title="0">{
        // Check owner references to determine workload type
        for _, owner := range pod.OwnerReferences </span><span class="cov0" title="0">{
                switch owner.Kind </span>{
                case "Deployment":<span class="cov0" title="0">
                        return "Deployment"</span>
                case "StatefulSet":<span class="cov0" title="0">
                        return "StatefulSet"</span>
                case "DaemonSet":<span class="cov0" title="0">
                        return "DaemonSet"</span>
                case "Job":<span class="cov0" title="0">
                        return "Job"</span>
                case "CronJob":<span class="cov0" title="0">
                        return "CronJob"</span>
                case "ReplicaSet":<span class="cov0" title="0">
                        return "ReplicaSet"</span>
                }
        }

        // Check for specific annotations or labels
        <span class="cov0" title="0">if pod.Labels != nil </span><span class="cov0" title="0">{
                if workload, exists := pod.Labels["app.kubernetes.io/component"]; exists </span><span class="cov0" title="0">{
                        return workload
                }</span>
        }

        <span class="cov0" title="0">return "Pod"</span>
}

// getQoSClass determines the QoS class of a pod
func getQoSClass(pod *corev1.Pod) corev1.PodQOSClass <span class="cov0" title="0">{
        requests := make(corev1.ResourceList)
        limits := make(corev1.ResourceList)
        zeroQuantity := resource.MustParse("0")
        isGuaranteed := true

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Accumulate requests
                for name, quantity := range container.Resources.Requests </span><span class="cov0" title="0">{
                        if value, exists := requests[name]; !exists </span><span class="cov0" title="0">{
                                requests[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                requests[name] = value
                        }</span>
                }

                // Accumulate limits
                <span class="cov0" title="0">for name, quantity := range container.Resources.Limits </span><span class="cov0" title="0">{
                        if value, exists := limits[name]; !exists </span><span class="cov0" title="0">{
                                limits[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                limits[name] = value
                        }</span>
                }
        }

        // Check if guaranteed
        <span class="cov0" title="0">if len(requests) == 0 || len(limits) == 0 </span><span class="cov0" title="0">{
                isGuaranteed = false
        }</span> else<span class="cov0" title="0"> {
                for name, req := range requests </span><span class="cov0" title="0">{
                        if limit, exists := limits[name]; !exists || limit.Cmp(req) != 0 </span><span class="cov0" title="0">{
                                isGuaranteed = false
                                break</span>
                        }
                }
        }

        <span class="cov0" title="0">if isGuaranteed </span><span class="cov0" title="0">{
                return corev1.PodQOSGuaranteed
        }</span>

        // Check if burstable (has some requests or limits)
        <span class="cov0" title="0">for _, req := range requests </span><span class="cov0" title="0">{
                if req.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">for _, limit := range limits </span><span class="cov0" title="0">{
                if limit.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">return corev1.PodQOSBestEffort</span>
}

// parseRulesFromConfigMap parses rules from a ConfigMap
func (pe *PolicyEngine) parseRulesFromConfigMap(configMap *corev1.ConfigMap) ([]Rule, error) <span class="cov0" title="0">{
        var rules []Rule

        // For simplicity, expect rules in YAML format in the "rules.yaml" key
        if _, exists := configMap.Data["rules.yaml"]; exists </span><span class="cov0" title="0">{
                // In a real implementation, you would use a YAML parser here
                // For now, we'll create some example rules
                rules = pe.createDefaultRules()
                logger.Info("Using default rules (YAML parsing not implemented in this example)")
        }</span> else<span class="cov0" title="0"> {
                // Create some default rules if no configuration is found
                rules = pe.createDefaultRules()
                logger.Info("No rules configuration found, using default rules")
        }</span>

        <span class="cov0" title="0">return rules, nil</span>
}

// createDefaultRules creates a set of default policy rules
func (pe *PolicyEngine) createDefaultRules() []Rule <span class="cov0" title="0">{
        return []Rule{
                {
                        Name:        "high-priority-workloads",
                        Description: "Higher resource allocation for high priority workloads",
                        Priority:    100,
                        Selectors: RuleSelectors{
                                Labels: map[string]string{
                                        "priority": "high",
                                },
                        },
                        Actions: RuleActions{
                                CPUMultiplier:    floatPtr(1.5),
                                MemoryMultiplier: floatPtr(1.3),
                        },
                        Enabled: true,
                },
                {
                        Name:        "database-workloads",
                        Description: "Special handling for database workloads",
                        Priority:    90,
                        Selectors: RuleSelectors{
                                Labels: map[string]string{
                                        "app.kubernetes.io/component": "database",
                                },
                        },
                        Actions: RuleActions{
                                CPUMultiplier:    floatPtr(1.2),
                                MemoryMultiplier: floatPtr(2.0),
                                MinMemory:        stringPtr("1Gi"),
                        },
                        Enabled: true,
                },
                {
                        Name:        "batch-jobs",
                        Description: "Resource limits for batch processing jobs",
                        Priority:    50,
                        Selectors: RuleSelectors{
                                WorkloadType: "Job",
                        },
                        Actions: RuleActions{
                                CPUMultiplier:    floatPtr(1.0),
                                MemoryMultiplier: floatPtr(1.1),
                                MaxCPU:           stringPtr("2"),
                                MaxMemory:        stringPtr("4Gi"),
                        },
                        Enabled: true,
                },
                {
                        Name:        "development-namespaces",
                        Description: "Conservative resource allocation for dev environments",
                        Priority:    20,
                        Selectors: RuleSelectors{
                                Namespaces: []string{"development", "dev", "staging"},
                        },
                        Actions: RuleActions{
                                CPUMultiplier:    floatPtr(1.0),
                                MemoryMultiplier: floatPtr(1.0),
                                MaxCPU:           stringPtr("500m"),
                                MaxMemory:        stringPtr("1Gi"),
                        },
                        Enabled: true,
                },
                {
                        Name:        "skip-system-pods",
                        Description: "Skip right-sizing for system pods",
                        Priority:    200,
                        Selectors: RuleSelectors{
                                Namespaces: []string{"kube-system", "kube-public"},
                        },
                        Actions: RuleActions{
                                Skip: true,
                        },
                        Enabled: true,
                },
        }
}</span>

// Helper functions for creating pointers
func floatPtr(f float64) *float64 <span class="cov0" title="0">{
        return &amp;f
}</span>

func stringPtr(s string) *string <span class="cov0" title="0">{
        return &amp;s
}</span>

// GetRules returns all loaded rules
func (pe *PolicyEngine) GetRules() []Rule <span class="cov0" title="0">{
        return pe.rules
}</span>

// GetActiveRules returns only enabled rules
func (pe *PolicyEngine) GetActiveRules() []Rule <span class="cov0" title="0">{
        var activeRules []Rule
        for _, rule := range pe.rules </span><span class="cov0" title="0">{
                if rule.Enabled </span><span class="cov0" title="0">{
                        activeRules = append(activeRules, rule)
                }</span>
        }
        <span class="cov0" title="0">return activeRules</span>
}

// ValidateRules validates all loaded rules
func (pe *PolicyEngine) ValidateRules() error <span class="cov0" title="0">{
        for _, rule := range pe.rules </span><span class="cov0" title="0">{
                if err := pe.validateRule(rule); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("rule %s is invalid: %v", rule.Name, err)
                }</span>
        }
        <span class="cov0" title="0">return nil</span>
}

// validateRule validates a single rule
func (pe *PolicyEngine) validateRule(rule Rule) error <span class="cov0" title="0">{
        if rule.Name == "" </span><span class="cov0" title="0">{
                return fmt.Errorf("rule name cannot be empty")
        }</span>

        // Validate regex if present
        <span class="cov0" title="0">if rule.Selectors.PodNameRegex != "" </span><span class="cov0" title="0">{
                if _, err := regexp.Compile(rule.Selectors.PodNameRegex); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid pod name regex: %v", err)
                }</span>
        }

        // Validate resource quantities in actions
        <span class="cov0" title="0">actions := rule.Actions
        if actions.MinCPU != nil </span><span class="cov0" title="0">{
                if _, err := resource.ParseQuantity(*actions.MinCPU); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid minCPU: %v", err)
                }</span>
        }
        <span class="cov0" title="0">if actions.MaxCPU != nil </span><span class="cov0" title="0">{
                if _, err := resource.ParseQuantity(*actions.MaxCPU); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid maxCPU: %v", err)
                }</span>
        }
        <span class="cov0" title="0">if actions.MinMemory != nil </span><span class="cov0" title="0">{
                if _, err := resource.ParseQuantity(*actions.MinMemory); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid minMemory: %v", err)
                }</span>
        }
        <span class="cov0" title="0">if actions.MaxMemory != nil </span><span class="cov0" title="0">{
                if _, err := resource.ParseQuantity(*actions.MaxMemory); err != nil </span><span class="cov0" title="0">{
                        return fmt.Errorf("invalid maxMemory: %v", err)
                }</span>
        }

        <span class="cov0" title="0">return nil</span>
}
</pre>
		
		<pre class="file" id="file23" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package retry

import (
        "context"
        "fmt"
        "math"
        "math/rand"
        "sync"
        "time"

        "right-sizer/logger"
        "right-sizer/metrics"
)

// RetryableError represents an error that can be retried
type RetryableError struct {
        Err       error
        Retryable bool
}

func (r *RetryableError) Error() string <span class="cov0" title="0">{
        return r.Err.Error()
}</span>

// IsRetryable returns true if the error can be retried
func (r *RetryableError) IsRetryable() bool <span class="cov0" title="0">{
        return r.Retryable
}</span>

// NewRetryableError creates a new retryable error
func NewRetryableError(err error, retryable bool) *RetryableError <span class="cov0" title="0">{
        return &amp;RetryableError{Err: err, Retryable: retryable}
}</span>

// Config holds retry configuration
type Config struct {
        MaxRetries          int
        InitialDelay        time.Duration
        MaxDelay            time.Duration
        BackoffFactor       float64
        RandomizationFactor float64
        Timeout             time.Duration
}

// DefaultConfig returns a default retry configuration
func DefaultConfig() Config <span class="cov0" title="0">{
        return Config{
                MaxRetries:          3,
                InitialDelay:        100 * time.Millisecond,
                MaxDelay:            10 * time.Second,
                BackoffFactor:       2.0,
                RandomizationFactor: 0.1,
                Timeout:             30 * time.Second,
        }
}</span>

// RetryFunc is a function that can be retried
type RetryFunc func() error

// RetryFuncWithContext is a function that can be retried with context
type RetryFuncWithContext func(ctx context.Context) error

// Retryer handles retry logic with exponential backoff
type Retryer struct {
        config  Config
        metrics *metrics.OperatorMetrics
}

// New creates a new Retryer
func New(config Config, metrics *metrics.OperatorMetrics) *Retryer <span class="cov0" title="0">{
        return &amp;Retryer{
                config:  config,
                metrics: metrics,
        }
}</span>

// Do executes the function with retry logic
func (r *Retryer) Do(operation string, fn RetryFunc) error <span class="cov0" title="0">{
        return r.DoWithContext(context.Background(), operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return fn()
        }</span>)
}

// DoWithContext executes the function with retry logic and context
func (r *Retryer) DoWithContext(ctx context.Context, operation string, fn RetryFuncWithContext) error <span class="cov0" title="0">{
        if r.config.Timeout &gt; 0 </span><span class="cov0" title="0">{
                var cancel context.CancelFunc
                ctx, cancel = context.WithTimeout(ctx, r.config.Timeout)
                defer cancel()
        }</span>

        <span class="cov0" title="0">delay := r.config.InitialDelay
        var lastErr error

        for attempt := 0; attempt &lt;= r.config.MaxRetries; attempt++ </span><span class="cov0" title="0">{
                if r.metrics != nil </span><span class="cov0" title="0">{
                        r.metrics.RecordRetryAttempt(operation, attempt+1)
                }</span>

                // Execute the function
                <span class="cov0" title="0">err := fn(ctx)
                if err == nil </span><span class="cov0" title="0">{
                        if attempt &gt; 0 &amp;&amp; r.metrics != nil </span><span class="cov0" title="0">{
                                r.metrics.RecordRetrySuccess(operation)
                                logger.Info("Operation %s succeeded after %d retries", operation, attempt)
                        }</span>
                        <span class="cov0" title="0">return nil</span>
                }

                <span class="cov0" title="0">lastErr = err

                // Check if error is retryable
                if retryableErr, ok := err.(*RetryableError); ok &amp;&amp; !retryableErr.IsRetryable() </span><span class="cov0" title="0">{
                        logger.Warn("Operation %s failed with non-retryable error: %v", operation, err)
                        return err
                }</span>

                // Check if we've exhausted retries
                <span class="cov0" title="0">if attempt &gt;= r.config.MaxRetries </span><span class="cov0" title="0">{
                        logger.Error("Operation %s failed after %d attempts: %v", operation, attempt+1, err)
                        break</span>
                }

                // Check context cancellation
                <span class="cov0" title="0">select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        logger.Warn("Operation %s cancelled during retry attempt %d", operation, attempt+1)
                        return ctx.Err()</span>
                default:<span class="cov0" title="0"></span>
                }

                // Calculate next delay with exponential backoff and jitter
                <span class="cov0" title="0">nextDelay := r.calculateDelay(delay, attempt)
                logger.Debug("Operation %s failed (attempt %d/%d), retrying in %v: %v",
                        operation, attempt+1, r.config.MaxRetries+1, nextDelay, err)

                // Sleep before retry
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                case &lt;-time.After(nextDelay):<span class="cov0" title="0"></span>
                }

                <span class="cov0" title="0">delay = time.Duration(float64(delay) * r.config.BackoffFactor)
                if delay &gt; r.config.MaxDelay </span><span class="cov0" title="0">{
                        delay = r.config.MaxDelay
                }</span>
        }

        <span class="cov0" title="0">return fmt.Errorf("operation %s failed after %d attempts: %v", operation, r.config.MaxRetries+1, lastErr)</span>
}

// calculateDelay calculates the delay for the next retry with jitter
func (r *Retryer) calculateDelay(baseDelay time.Duration, attempt int) time.Duration <span class="cov0" title="0">{
        // Apply exponential backoff
        delay := time.Duration(float64(baseDelay) * math.Pow(r.config.BackoffFactor, float64(attempt)))

        // Cap at max delay
        if delay &gt; r.config.MaxDelay </span><span class="cov0" title="0">{
                delay = r.config.MaxDelay
        }</span>

        // Add randomization (jitter)
        <span class="cov0" title="0">if r.config.RandomizationFactor &gt; 0 </span><span class="cov0" title="0">{
                jitter := float64(delay) * r.config.RandomizationFactor * (rand.Float64()*2 - 1)
                delay = time.Duration(float64(delay) + jitter)
        }</span>

        // Ensure minimum delay
        <span class="cov0" title="0">if delay &lt; time.Millisecond </span><span class="cov0" title="0">{
                delay = time.Millisecond
        }</span>

        <span class="cov0" title="0">return delay</span>
}

// CircuitBreakerState represents the state of a circuit breaker
type CircuitBreakerState int

const (
        StateClosed CircuitBreakerState = iota
        StateOpen
        StateHalfOpen
)

func (s CircuitBreakerState) String() string <span class="cov0" title="0">{
        switch s </span>{
        case StateClosed:<span class="cov0" title="0">
                return "CLOSED"</span>
        case StateOpen:<span class="cov0" title="0">
                return "OPEN"</span>
        case StateHalfOpen:<span class="cov0" title="0">
                return "HALF_OPEN"</span>
        default:<span class="cov0" title="0">
                return "UNKNOWN"</span>
        }
}

// CircuitBreakerConfig holds circuit breaker configuration
type CircuitBreakerConfig struct {
        FailureThreshold int
        RecoveryTimeout  time.Duration
        SuccessThreshold int
}

// DefaultCircuitBreakerConfig returns default circuit breaker configuration
func DefaultCircuitBreakerConfig() CircuitBreakerConfig <span class="cov0" title="0">{
        return CircuitBreakerConfig{
                FailureThreshold: 5,
                RecoveryTimeout:  30 * time.Second,
                SuccessThreshold: 3,
        }
}</span>

// CircuitBreaker implements the circuit breaker pattern
type CircuitBreaker struct {
        config          CircuitBreakerConfig
        state           CircuitBreakerState
        failureCount    int
        successCount    int
        lastFailureTime time.Time
        mutex           sync.RWMutex
        metrics         *metrics.OperatorMetrics
        name            string
}

// NewCircuitBreaker creates a new circuit breaker
func NewCircuitBreaker(name string, config CircuitBreakerConfig, metrics *metrics.OperatorMetrics) *CircuitBreaker <span class="cov0" title="0">{
        return &amp;CircuitBreaker{
                config:  config,
                state:   StateClosed,
                metrics: metrics,
                name:    name,
        }
}</span>

// Execute executes the function through the circuit breaker
func (cb *CircuitBreaker) Execute(fn RetryFunc) error <span class="cov0" title="0">{
        return cb.ExecuteWithContext(context.Background(), func(ctx context.Context) error </span><span class="cov0" title="0">{
                return fn()
        }</span>)
}

// ExecuteWithContext executes the function through the circuit breaker with context
func (cb *CircuitBreaker) ExecuteWithContext(ctx context.Context, fn RetryFuncWithContext) error <span class="cov0" title="0">{
        cb.mutex.Lock()
        defer cb.mutex.Unlock()

        // Check if circuit should transition to half-open
        if cb.state == StateOpen &amp;&amp; time.Since(cb.lastFailureTime) &gt;= cb.config.RecoveryTimeout </span><span class="cov0" title="0">{
                cb.state = StateHalfOpen
                cb.successCount = 0
                logger.Info("Circuit breaker %s transitioned to HALF_OPEN", cb.name)
        }</span>

        // If circuit is open, fail fast
        <span class="cov0" title="0">if cb.state == StateOpen </span><span class="cov0" title="0">{
                return NewRetryableError(fmt.Errorf("circuit breaker %s is OPEN", cb.name), false)
        }</span>

        // Execute the function
        <span class="cov0" title="0">err := fn(ctx)

        if err != nil </span><span class="cov0" title="0">{
                cb.onFailure()
                return err
        }</span>

        <span class="cov0" title="0">cb.onSuccess()
        return nil</span>
}

// onSuccess handles successful execution
func (cb *CircuitBreaker) onSuccess() <span class="cov0" title="0">{
        cb.failureCount = 0

        if cb.state == StateHalfOpen </span><span class="cov0" title="0">{
                cb.successCount++
                if cb.successCount &gt;= cb.config.SuccessThreshold </span><span class="cov0" title="0">{
                        cb.state = StateClosed
                        cb.successCount = 0
                        logger.Info("Circuit breaker %s transitioned to CLOSED", cb.name)
                }</span>
        }
}

// onFailure handles failed execution
func (cb *CircuitBreaker) onFailure() <span class="cov0" title="0">{
        cb.failureCount++
        cb.lastFailureTime = time.Now()

        if cb.state == StateClosed &amp;&amp; cb.failureCount &gt;= cb.config.FailureThreshold </span><span class="cov0" title="0">{
                cb.state = StateOpen
                logger.Warn("Circuit breaker %s transitioned to OPEN after %d failures", cb.name, cb.failureCount)
        }</span> else<span class="cov0" title="0"> if cb.state == StateHalfOpen </span><span class="cov0" title="0">{
                cb.state = StateOpen
                logger.Warn("Circuit breaker %s transitioned back to OPEN from HALF_OPEN", cb.name)
        }</span>
}

// GetState returns the current state of the circuit breaker
func (cb *CircuitBreaker) GetState() CircuitBreakerState <span class="cov0" title="0">{
        cb.mutex.RLock()
        defer cb.mutex.RUnlock()
        return cb.state
}</span>

// GetStats returns circuit breaker statistics
func (cb *CircuitBreaker) GetStats() (state CircuitBreakerState, failures int, successes int) <span class="cov0" title="0">{
        cb.mutex.RLock()
        defer cb.mutex.RUnlock()
        return cb.state, cb.failureCount, cb.successCount
}</span>

// RetryWithCircuitBreaker combines retry logic with circuit breaker
type RetryWithCircuitBreaker struct {
        retryer        *Retryer
        circuitBreaker *CircuitBreaker
}

// NewRetryWithCircuitBreaker creates a new retry handler with circuit breaker
func NewRetryWithCircuitBreaker(name string, retryConfig Config, cbConfig CircuitBreakerConfig, metrics *metrics.OperatorMetrics) *RetryWithCircuitBreaker <span class="cov0" title="0">{
        return &amp;RetryWithCircuitBreaker{
                retryer:        New(retryConfig, metrics),
                circuitBreaker: NewCircuitBreaker(name, cbConfig, metrics),
        }
}</span>

// Execute executes the function with both retry and circuit breaker logic
func (r *RetryWithCircuitBreaker) Execute(operation string, fn RetryFunc) error <span class="cov0" title="0">{
        return r.ExecuteWithContext(context.Background(), operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return fn()
        }</span>)
}

// ExecuteWithContext executes the function with both retry and circuit breaker logic and context
func (r *RetryWithCircuitBreaker) ExecuteWithContext(ctx context.Context, operation string, fn RetryFuncWithContext) error <span class="cov0" title="0">{
        return r.retryer.DoWithContext(ctx, operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return r.circuitBreaker.ExecuteWithContext(ctx, fn)
        }</span>)
}

// GetCircuitBreakerState returns the current circuit breaker state
func (r *RetryWithCircuitBreaker) GetCircuitBreakerState() CircuitBreakerState <span class="cov0" title="0">{
        return r.circuitBreaker.GetState()
}</span>

// IsRetryableKubernetesError determines if a Kubernetes error should be retried
func IsRetryableKubernetesError(err error) bool <span class="cov0" title="0">{
        if err == nil </span><span class="cov0" title="0">{
                return false
        }</span>

        <span class="cov0" title="0">errStr := err.Error()

        // Retryable error patterns
        retryablePatterns := []string{
                "connection refused",
                "timeout",
                "temporary failure",
                "server is currently unavailable",
                "too many requests",
                "service unavailable",
                "internal server error",
                "bad gateway",
                "gateway timeout",
                "connection reset",
                "EOF",
                "i/o timeout",
        }

        for _, pattern := range retryablePatterns </span><span class="cov0" title="0">{
                if contains(errStr, pattern) </span><span class="cov0" title="0">{
                        return true
                }</span>
        }

        <span class="cov0" title="0">return false</span>
}

// contains checks if a string contains a substring (case-insensitive)
func contains(s, substr string) bool <span class="cov0" title="0">{
        return len(s) &gt;= len(substr) &amp;&amp;
                (s == substr ||
                        len(s) &gt; len(substr) &amp;&amp;
                                (s[:len(substr)] == substr ||
                                        s[len(s)-len(substr):] == substr ||
                                        containsSubstring(s, substr)))
}</span>

func containsSubstring(s, substr string) bool <span class="cov0" title="0">{
        for i := 0; i &lt;= len(s)-len(substr); i++ </span><span class="cov0" title="0">{
                if s[i:i+len(substr)] == substr </span><span class="cov0" title="0">{
                        return true
                }</span>
        }
        <span class="cov0" title="0">return false</span>
}

// WrapKubernetesError wraps a Kubernetes error as retryable or non-retryable
func WrapKubernetesError(err error) error <span class="cov0" title="0">{
        if err == nil </span><span class="cov0" title="0">{
                return nil
        }</span>

        <span class="cov0" title="0">return NewRetryableError(err, IsRetryableKubernetesError(err))</span>
}

// RetryManager provides a simple interface for retry operations
type RetryManager struct {
        retryer *Retryer
}

// NewRetryManager creates a new RetryManager with the given configuration
func NewRetryManager(config Config) *RetryManager <span class="cov0" title="0">{
        return &amp;RetryManager{
                retryer: New(config, nil),
        }
}</span>

// RetryWithBackoff performs an operation with exponential backoff retry
func (rm *RetryManager) RetryWithBackoff(fn func() error) error <span class="cov0" title="0">{
        return rm.retryer.Do("operation", fn)
}</span>

// BackoffStrategy represents different backoff strategies
type BackoffStrategy int

const (
        ExponentialBackoff BackoffStrategy = iota
        LinearBackoff
        ConstantBackoff
)

// CustomRetryer allows for more customized retry behavior
type CustomRetryer struct {
        maxRetries  int
        strategy    BackoffStrategy
        baseDelay   time.Duration
        maxDelay    time.Duration
        factor      float64
        shouldRetry func(error, int) bool
        onRetry     func(error, int)
        metrics     *metrics.OperatorMetrics
}

// CustomRetryConfig holds configuration for CustomRetryer
type CustomRetryConfig struct {
        MaxRetries  int
        Strategy    BackoffStrategy
        BaseDelay   time.Duration
        MaxDelay    time.Duration
        Factor      float64
        ShouldRetry func(error, int) bool
        OnRetry     func(error, int)
}

// NewCustomRetryer creates a new custom retryer
func NewCustomRetryer(config CustomRetryConfig, metrics *metrics.OperatorMetrics) *CustomRetryer <span class="cov0" title="0">{
        if config.ShouldRetry == nil </span><span class="cov0" title="0">{
                config.ShouldRetry = func(err error, attempt int) bool </span><span class="cov0" title="0">{
                        return IsRetryableKubernetesError(err)
                }</span>
        }

        <span class="cov0" title="0">return &amp;CustomRetryer{
                maxRetries:  config.MaxRetries,
                strategy:    config.Strategy,
                baseDelay:   config.BaseDelay,
                maxDelay:    config.MaxDelay,
                factor:      config.Factor,
                shouldRetry: config.ShouldRetry,
                onRetry:     config.OnRetry,
                metrics:     metrics,
        }</span>
}

// Execute executes the function with custom retry logic
func (cr *CustomRetryer) Execute(operation string, fn RetryFunc) error <span class="cov0" title="0">{
        return cr.ExecuteWithContext(context.Background(), operation, func(ctx context.Context) error </span><span class="cov0" title="0">{
                return fn()
        }</span>)
}

// ExecuteWithContext executes the function with custom retry logic and context
func (cr *CustomRetryer) ExecuteWithContext(ctx context.Context, operation string, fn RetryFuncWithContext) error <span class="cov0" title="0">{
        var lastErr error

        for attempt := 0; attempt &lt;= cr.maxRetries; attempt++ </span><span class="cov0" title="0">{
                if cr.metrics != nil </span><span class="cov0" title="0">{
                        cr.metrics.RecordRetryAttempt(operation, attempt+1)
                }</span>

                <span class="cov0" title="0">err := fn(ctx)
                if err == nil </span><span class="cov0" title="0">{
                        if attempt &gt; 0 &amp;&amp; cr.metrics != nil </span><span class="cov0" title="0">{
                                cr.metrics.RecordRetrySuccess(operation)
                        }</span>
                        <span class="cov0" title="0">return nil</span>
                }

                <span class="cov0" title="0">lastErr = err

                // Check if we should retry
                if !cr.shouldRetry(err, attempt) </span><span class="cov0" title="0">{
                        return err
                }</span>

                // Check if we've exhausted retries
                <span class="cov0" title="0">if attempt &gt;= cr.maxRetries </span><span class="cov0" title="0">{
                        break</span>
                }

                // Call onRetry callback if provided
                <span class="cov0" title="0">if cr.onRetry != nil </span><span class="cov0" title="0">{
                        cr.onRetry(err, attempt)
                }</span>

                // Calculate delay based on strategy
                <span class="cov0" title="0">delay := cr.calculateDelayForStrategy(attempt)

                // Check context cancellation
                select </span>{
                case &lt;-ctx.Done():<span class="cov0" title="0">
                        return ctx.Err()</span>
                case &lt;-time.After(delay):<span class="cov0" title="0"></span>
                }
        }

        <span class="cov0" title="0">return fmt.Errorf("operation %s failed after %d attempts: %v", operation, cr.maxRetries+1, lastErr)</span>
}

// calculateDelayForStrategy calculates delay based on the configured strategy
func (cr *CustomRetryer) calculateDelayForStrategy(attempt int) time.Duration <span class="cov0" title="0">{
        var delay time.Duration

        switch cr.strategy </span>{
        case ExponentialBackoff:<span class="cov0" title="0">
                delay = time.Duration(float64(cr.baseDelay) * math.Pow(cr.factor, float64(attempt)))</span>
        case LinearBackoff:<span class="cov0" title="0">
                delay = time.Duration(float64(cr.baseDelay) * (1 + cr.factor*float64(attempt)))</span>
        case ConstantBackoff:<span class="cov0" title="0">
                delay = cr.baseDelay</span>
        default:<span class="cov0" title="0">
                delay = cr.baseDelay</span>
        }

        <span class="cov0" title="0">if delay &gt; cr.maxDelay </span><span class="cov0" title="0">{
                delay = cr.maxDelay
        }</span>

        <span class="cov0" title="0">return delay</span>
}
</pre>
		
		<pre class="file" id="file24" style="display: none">// Copyright (C) 2024 right-sizer contributors
//
// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU Affero General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.
//
// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU Affero General Public License for more details.
//
// You should have received a copy of the GNU Affero General Public License
// along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

package validation

import (
        "context"
        "fmt"
        "strings"

        "right-sizer/config"
        "right-sizer/logger"
        "right-sizer/metrics"

        corev1 "k8s.io/api/core/v1"
        "k8s.io/apimachinery/pkg/api/resource"
        "k8s.io/client-go/kubernetes"
        "sigs.k8s.io/controller-runtime/pkg/client"
)

// ValidationResult represents the result of a resource validation
type ValidationResult struct {
        Valid    bool
        Errors   []string
        Warnings []string
        Info     []string
}

// IsValid returns true if the validation passed
func (vr *ValidationResult) IsValid() bool <span class="cov0" title="0">{
        return vr.Valid
}</span>

// HasWarnings returns true if there are warnings
func (vr *ValidationResult) HasWarnings() bool <span class="cov0" title="0">{
        return len(vr.Warnings) &gt; 0
}</span>

// AddError adds an error to the validation result
func (vr *ValidationResult) AddError(msg string) <span class="cov0" title="0">{
        vr.Errors = append(vr.Errors, msg)
        vr.Valid = false
}</span>

// AddWarning adds a warning to the validation result
func (vr *ValidationResult) AddWarning(msg string) <span class="cov0" title="0">{
        vr.Warnings = append(vr.Warnings, msg)
}</span>

// AddInfo adds an info message to the validation result
func (vr *ValidationResult) AddInfo(msg string) <span class="cov0" title="0">{
        vr.Info = append(vr.Info, msg)
}</span>

// String returns a string representation of the validation result
func (vr *ValidationResult) String() string <span class="cov0" title="0">{
        var parts []string

        if len(vr.Errors) &gt; 0 </span><span class="cov0" title="0">{
                parts = append(parts, fmt.Sprintf("Errors: %s", strings.Join(vr.Errors, "; ")))
        }</span>
        <span class="cov0" title="0">if len(vr.Warnings) &gt; 0 </span><span class="cov0" title="0">{
                parts = append(parts, fmt.Sprintf("Warnings: %s", strings.Join(vr.Warnings, "; ")))
        }</span>
        <span class="cov0" title="0">if len(vr.Info) &gt; 0 </span><span class="cov0" title="0">{
                parts = append(parts, fmt.Sprintf("Info: %s", strings.Join(vr.Info, "; ")))
        }</span>

        <span class="cov0" title="0">return strings.Join(parts, " | ")</span>
}

// ResourceValidator validates resource requests and limits
type ResourceValidator struct {
        client      client.Client
        clientset   *kubernetes.Clientset
        config      *config.Config
        metrics     *metrics.OperatorMetrics
        nodeCache   map[string]*corev1.Node
        quotaCache  map[string]*corev1.ResourceQuota
        limitRanges map[string][]*corev1.LimitRange
}

// NewResourceValidator creates a new resource validator
func NewResourceValidator(client client.Client, clientset *kubernetes.Clientset, cfg *config.Config, metrics *metrics.OperatorMetrics) *ResourceValidator <span class="cov0" title="0">{
        return &amp;ResourceValidator{
                client:      client,
                clientset:   clientset,
                config:      cfg,
                metrics:     metrics,
                nodeCache:   make(map[string]*corev1.Node),
                quotaCache:  make(map[string]*corev1.ResourceQuota),
                limitRanges: make(map[string][]*corev1.LimitRange),
        }
}</span>

// ValidateResourceChange validates a proposed resource change for a pod
func (rv *ResourceValidator) ValidateResourceChange(ctx context.Context, pod *corev1.Pod, newResources corev1.ResourceRequirements, containerName string) *ValidationResult <span class="cov0" title="0">{
        result := &amp;ValidationResult{Valid: true}

        // Basic resource validation
        rv.validateBasicResources(newResources, result)

        // Configuration limits validation
        rv.validateConfigurationLimits(newResources, result)

        // Safety threshold validation
        if pod.Spec.Containers != nil </span><span class="cov0" title="0">{
                for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                        if container.Name == containerName </span><span class="cov0" title="0">{
                                rv.validateSafetyThreshold(container.Resources, newResources, result)
                                break</span>
                        }
                }
        }

        // Node capacity validation
        <span class="cov0" title="0">rv.validateNodeCapacity(ctx, pod, newResources, result)

        // Resource quota validation
        rv.validateResourceQuota(ctx, pod, newResources, result)

        // Limit range validation
        rv.validateLimitRanges(ctx, pod, newResources, result)

        // QoS class validation
        rv.validateQoSImpact(pod, newResources, containerName, result)

        // Record metrics
        if rv.metrics != nil </span><span class="cov0" title="0">{
                if !result.IsValid() </span><span class="cov0" title="0">{
                        for _, err := range result.Errors </span><span class="cov0" title="0">{
                                rv.metrics.RecordResourceValidationError("resource_change", err)
                        }</span>
                }
        }

        <span class="cov0" title="0">return result</span>
}

// validateBasicResources performs basic validation on resource requests and limits
func (rv *ResourceValidator) validateBasicResources(resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        // Check that requests don't exceed limits
        if resources.Requests != nil &amp;&amp; resources.Limits != nil </span><span class="cov0" title="0">{
                if cpuRequest, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        if cpuLimit, ok := resources.Limits[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                                if cpuRequest.Cmp(cpuLimit) &gt; 0 </span><span class="cov0" title="0">{
                                        result.AddError("CPU request cannot exceed CPU limit")
                                }</span>
                        }
                }

                <span class="cov0" title="0">if memRequest, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        if memLimit, ok := resources.Limits[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                                if memRequest.Cmp(memLimit) &gt; 0 </span><span class="cov0" title="0">{
                                        result.AddError("Memory request cannot exceed memory limit")
                                }</span>
                        }
                }
        }

        // Check for negative values
        <span class="cov0" title="0">if resources.Requests != nil </span><span class="cov0" title="0">{
                for resourceName, quantity := range resources.Requests </span><span class="cov0" title="0">{
                        if quantity.Sign() &lt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Resource request for %s cannot be negative", resourceName))
                        }</span>
                }
        }

        <span class="cov0" title="0">if resources.Limits != nil </span><span class="cov0" title="0">{
                for resourceName, quantity := range resources.Limits </span><span class="cov0" title="0">{
                        if quantity.Sign() &lt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Resource limit for %s cannot be negative", resourceName))
                        }</span>
                }
        }
}

// validateConfigurationLimits validates against configured min/max limits
func (rv *ResourceValidator) validateConfigurationLimits(resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if resources.Requests != nil </span><span class="cov0" title="0">{
                if cpuRequest, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        cpuMillis := cpuRequest.MilliValue()
                        if cpuMillis &lt; rv.config.MinCPURequest </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("CPU request %dm is below minimum %dm", cpuMillis, rv.config.MinCPURequest))
                        }</span>
                }

                <span class="cov0" title="0">if memRequest, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        memMB := memRequest.Value() / (1024 * 1024)
                        if memMB &lt; rv.config.MinMemoryRequest </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Memory request %dMB is below minimum %dMB", memMB, rv.config.MinMemoryRequest))
                        }</span>
                }
        }

        <span class="cov0" title="0">if resources.Limits != nil </span><span class="cov0" title="0">{
                if cpuLimit, ok := resources.Limits[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        cpuMillis := cpuLimit.MilliValue()
                        if cpuMillis &gt; rv.config.MaxCPULimit </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("CPU limit %dm exceeds maximum %dm", cpuMillis, rv.config.MaxCPULimit))
                        }</span>
                }

                <span class="cov0" title="0">if memLimit, ok := resources.Limits[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        memMB := memLimit.Value() / (1024 * 1024)
                        if memMB &gt; rv.config.MaxMemoryLimit </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Memory limit %dMB exceeds maximum %dMB", memMB, rv.config.MaxMemoryLimit))
                        }</span>
                }
        }
}

// validateSafetyThreshold checks if the change is within safety limits
func (rv *ResourceValidator) validateSafetyThreshold(current, new corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        // Check CPU request change
        if current.Requests != nil &amp;&amp; new.Requests != nil </span><span class="cov0" title="0">{
                if currentCPU, ok := current.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        if newCPU, ok := new.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                                if !rv.config.IsChangeWithinSafetyThreshold(currentCPU.MilliValue(), newCPU.MilliValue()) </span><span class="cov0" title="0">{
                                        if rv.metrics != nil </span><span class="cov0" title="0">{
                                                rv.metrics.RecordSafetyThresholdViolation("", "", "cpu")
                                        }</span>
                                        <span class="cov0" title="0">result.AddWarning(fmt.Sprintf("CPU request change exceeds safety threshold of %.0f%%", rv.config.SafetyThreshold*100))</span>
                                }
                        }
                }
        }

        // Check memory request change
        <span class="cov0" title="0">if current.Requests != nil &amp;&amp; new.Requests != nil </span><span class="cov0" title="0">{
                if currentMem, ok := current.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        if newMem, ok := new.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                                currentMB := currentMem.Value() / (1024 * 1024)
                                newMB := newMem.Value() / (1024 * 1024)
                                if !rv.config.IsChangeWithinSafetyThreshold(currentMB, newMB) </span><span class="cov0" title="0">{
                                        if rv.metrics != nil </span><span class="cov0" title="0">{
                                                rv.metrics.RecordSafetyThresholdViolation("", "", "memory")
                                        }</span>
                                        <span class="cov0" title="0">result.AddWarning(fmt.Sprintf("Memory request change exceeds safety threshold of %.0f%%", rv.config.SafetyThreshold*100))</span>
                                }
                        }
                }
        }
}

// calculateNodeAvailableResources calculates the available resources on a node
func (rv *ResourceValidator) calculateNodeAvailableResources(ctx context.Context, node *corev1.Node, excludePod *corev1.Pod) (corev1.ResourceList, error) <span class="cov0" title="0">{
        // Start with allocatable resources (total minus system reserved)
        availableCPU := node.Status.Allocatable[corev1.ResourceCPU].DeepCopy()
        availableMemory := node.Status.Allocatable[corev1.ResourceMemory].DeepCopy()

        // List all pods on the node
        podList := &amp;corev1.PodList{}
        if err := rv.client.List(ctx, podList, client.MatchingFields{"spec.nodeName": node.Name}); err != nil </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("failed to list pods on node %s: %v", node.Name, err)
        }</span>

        // Subtract resources used by all running pods (except the pod being resized)
        <span class="cov0" title="0">for _, p := range podList.Items </span><span class="cov0" title="0">{
                // Skip the pod being resized (we'll add its new resources later)
                if excludePod != nil &amp;&amp; p.Namespace == excludePod.Namespace &amp;&amp; p.Name == excludePod.Name </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Only count pods that are running or pending
                <span class="cov0" title="0">if p.Status.Phase != corev1.PodRunning &amp;&amp; p.Status.Phase != corev1.PodPending </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Sum up all container requests
                <span class="cov0" title="0">for _, container := range p.Spec.Containers </span><span class="cov0" title="0">{
                        if cpuReq, ok := container.Resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                                availableCPU.Sub(cpuReq)
                        }</span>
                        <span class="cov0" title="0">if memReq, ok := container.Resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                                availableMemory.Sub(memReq)
                        }</span>
                }
        }

        <span class="cov0" title="0">return corev1.ResourceList{
                corev1.ResourceCPU:    availableCPU,
                corev1.ResourceMemory: availableMemory,
        }, nil</span>
}

// validateNodeCapacity checks if the new resources fit within available node capacity
func (rv *ResourceValidator) validateNodeCapacity(ctx context.Context, pod *corev1.Pod, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if pod.Spec.NodeName == "" </span><span class="cov0" title="0">{
                result.AddInfo("Pod not yet scheduled, skipping node capacity validation")
                return
        }</span>

        <span class="cov0" title="0">node, err := rv.getNode(ctx, pod.Spec.NodeName)
        if err != nil </span><span class="cov0" title="0">{
                result.AddWarning(fmt.Sprintf("Could not retrieve node %s for capacity validation: %v", pod.Spec.NodeName, err))
                return
        }</span>

        // Calculate available resources on the node (excluding current pod)
        <span class="cov0" title="0">availableResources, err := rv.calculateNodeAvailableResources(ctx, node, pod)
        if err != nil </span><span class="cov0" title="0">{
                result.AddWarning(fmt.Sprintf("Could not calculate available resources on node %s: %v", pod.Spec.NodeName, err))
                // Fall back to simple capacity check
                rv.validateAgainstTotalCapacity(node, resources, result)
                return
        }</span>

        // Check if new resources fit within available capacity
        <span class="cov0" title="0">if resources.Requests != nil </span><span class="cov0" title="0">{
                if cpuRequest, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        availableCPU := availableResources[corev1.ResourceCPU]
                        if cpuRequest.Cmp(availableCPU) &gt; 0 </span><span class="cov0" title="0">{
                                allocatableCPU := node.Status.Allocatable[corev1.ResourceCPU]
                                result.AddError(fmt.Sprintf("CPU request %s exceeds available node capacity %s (allocatable: %s)",
                                        cpuRequest.String(),
                                        (&amp;availableCPU).String(),
                                        (&amp;allocatableCPU).String()))
                        }</span>
                }

                <span class="cov0" title="0">if memRequest, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        availableMemory := availableResources[corev1.ResourceMemory]
                        if memRequest.Cmp(availableMemory) &gt; 0 </span><span class="cov0" title="0">{
                                allocatableMemory := node.Status.Allocatable[corev1.ResourceMemory]
                                result.AddError(fmt.Sprintf("Memory request %s exceeds available node capacity %s (allocatable: %s)",
                                        memRequest.String(),
                                        (&amp;availableMemory).String(),
                                        (&amp;allocatableMemory).String()))
                        }</span>
                }
        }

        // Also validate limits against allocatable (limits can't exceed allocatable)
        <span class="cov0" title="0">if resources.Limits != nil </span><span class="cov0" title="0">{
                if cpuLimit, ok := resources.Limits[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        allocatableCPU := node.Status.Allocatable[corev1.ResourceCPU]
                        if cpuLimit.Cmp(allocatableCPU) &gt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("CPU limit %s exceeds node allocatable capacity %s",
                                        cpuLimit.String(),
                                        (&amp;allocatableCPU).String()))
                        }</span>
                }

                <span class="cov0" title="0">if memLimit, ok := resources.Limits[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        allocatableMemory := node.Status.Allocatable[corev1.ResourceMemory]
                        if memLimit.Cmp(allocatableMemory) &gt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Memory limit %s exceeds node allocatable capacity %s",
                                        memLimit.String(),
                                        (&amp;allocatableMemory).String()))
                        }</span>
                }
        }
}

// validateAgainstTotalCapacity fallback validation against total capacity
func (rv *ResourceValidator) validateAgainstTotalCapacity(node *corev1.Node, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if resources.Requests != nil </span><span class="cov0" title="0">{
                if cpuRequest, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        nodeCPUCapacity := node.Status.Allocatable[corev1.ResourceCPU]
                        if cpuRequest.Cmp(nodeCPUCapacity) &gt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("CPU request %s exceeds node allocatable capacity %s", cpuRequest.String(), (&amp;nodeCPUCapacity).String()))
                        }</span>
                }

                <span class="cov0" title="0">if memRequest, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        nodeMemCapacity := node.Status.Allocatable[corev1.ResourceMemory]
                        if memRequest.Cmp(nodeMemCapacity) &gt; 0 </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("Memory request %s exceeds node allocatable capacity %s", memRequest.String(), (&amp;nodeMemCapacity).String()))
                        }</span>
                }
        }
}

// validateResourceQuota checks if the resource change violates resource quotas
func (rv *ResourceValidator) validateResourceQuota(ctx context.Context, pod *corev1.Pod, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        quota, err := rv.getResourceQuota(ctx, pod.Namespace)
        if err != nil </span><span class="cov0" title="0">{
                logger.Debug("No resource quota found for namespace %s: %v", pod.Namespace, err)
                return
        }</span>

        <span class="cov0" title="0">if quota.Status.Hard == nil </span><span class="cov0" title="0">{
                return
        }</span>

        // Calculate current usage and new usage
        <span class="cov0" title="0">rv.checkQuotaLimits(quota, resources, result)</span>
}

// validateLimitRanges checks if resources comply with limit ranges
func (rv *ResourceValidator) validateLimitRanges(ctx context.Context, pod *corev1.Pod, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        limitRanges, err := rv.getLimitRanges(ctx, pod.Namespace)
        if err != nil </span><span class="cov0" title="0">{
                logger.Debug("Could not retrieve limit ranges for namespace %s: %v", pod.Namespace, err)
                return
        }</span>

        <span class="cov0" title="0">for _, limitRange := range limitRanges </span><span class="cov0" title="0">{
                rv.checkLimitRangeCompliance(limitRange, resources, result)
        }</span>
}

// validateQoSImpact checks if the resource change affects QoS class
func (rv *ResourceValidator) validateQoSImpact(pod *corev1.Pod, newResources corev1.ResourceRequirements, containerName string, result *ValidationResult) <span class="cov0" title="0">{
        currentQoS := getQoSClass(pod)

        // Create a copy of the pod with new resources to determine new QoS
        podCopy := pod.DeepCopy()
        for i, container := range podCopy.Spec.Containers </span><span class="cov0" title="0">{
                if container.Name == containerName </span><span class="cov0" title="0">{
                        podCopy.Spec.Containers[i].Resources = newResources
                        break</span>
                }
        }

        <span class="cov0" title="0">newQoS := getQoSClass(podCopy)

        if currentQoS != newQoS </span><span class="cov0" title="0">{
                result.AddWarning(fmt.Sprintf("Resource change will modify QoS class from %s to %s", currentQoS, newQoS))
        }</span>
}

// getNode retrieves a node from cache or API
func (rv *ResourceValidator) getNode(ctx context.Context, nodeName string) (*corev1.Node, error) <span class="cov0" title="0">{
        if node, ok := rv.nodeCache[nodeName]; ok </span><span class="cov0" title="0">{
                return node, nil
        }</span>

        <span class="cov0" title="0">node := &amp;corev1.Node{}
        err := rv.client.Get(ctx, client.ObjectKey{Name: nodeName}, node)
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">rv.nodeCache[nodeName] = node
        return node, nil</span>
}

// getResourceQuota retrieves resource quota for a namespace
func (rv *ResourceValidator) getResourceQuota(ctx context.Context, namespace string) (*corev1.ResourceQuota, error) <span class="cov0" title="0">{
        if quota, ok := rv.quotaCache[namespace]; ok </span><span class="cov0" title="0">{
                return quota, nil
        }</span>

        <span class="cov0" title="0">quotaList := &amp;corev1.ResourceQuotaList{}
        err := rv.client.List(ctx, quotaList, client.InNamespace(namespace))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">if len(quotaList.Items) == 0 </span><span class="cov0" title="0">{
                return nil, fmt.Errorf("no resource quota found")
        }</span>

        // Use the first quota found
        <span class="cov0" title="0">quota := &amp;quotaList.Items[0]
        rv.quotaCache[namespace] = quota
        return quota, nil</span>
}

// getLimitRanges retrieves limit ranges for a namespace
func (rv *ResourceValidator) getLimitRanges(ctx context.Context, namespace string) ([]*corev1.LimitRange, error) <span class="cov0" title="0">{
        if ranges, ok := rv.limitRanges[namespace]; ok </span><span class="cov0" title="0">{
                return ranges, nil
        }</span>

        <span class="cov0" title="0">limitRangeList := &amp;corev1.LimitRangeList{}
        err := rv.client.List(ctx, limitRangeList, client.InNamespace(namespace))
        if err != nil </span><span class="cov0" title="0">{
                return nil, err
        }</span>

        <span class="cov0" title="0">var ranges []*corev1.LimitRange
        for i := range limitRangeList.Items </span><span class="cov0" title="0">{
                ranges = append(ranges, &amp;limitRangeList.Items[i])
        }</span>

        <span class="cov0" title="0">rv.limitRanges[namespace] = ranges
        return ranges, nil</span>
}

// checkQuotaLimits checks if resources comply with quota limits
func (rv *ResourceValidator) checkQuotaLimits(quota *corev1.ResourceQuota, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        hard := quota.Status.Hard
        used := quota.Status.Used

        if resources.Requests != nil </span><span class="cov0" title="0">{
                if cpuRequest, ok := resources.Requests[corev1.ResourceCPU]; ok </span><span class="cov0" title="0">{
                        if hardCPU, ok := hard["requests.cpu"]; ok </span><span class="cov0" title="0">{
                                if usedCPU, ok := used["requests.cpu"]; ok </span><span class="cov0" title="0">{
                                        available := hardCPU.DeepCopy()
                                        available.Sub(usedCPU)
                                        if cpuRequest.Cmp(available) &gt; 0 </span><span class="cov0" title="0">{
                                                result.AddError(fmt.Sprintf("CPU request %s exceeds available quota %s", cpuRequest.String(), (&amp;available).String()))
                                        }</span>
                                }
                        }
                }

                <span class="cov0" title="0">if memRequest, ok := resources.Requests[corev1.ResourceMemory]; ok </span><span class="cov0" title="0">{
                        if hardMem, ok := hard["requests.memory"]; ok </span><span class="cov0" title="0">{
                                if usedMem, ok := used["requests.memory"]; ok </span><span class="cov0" title="0">{
                                        available := hardMem.DeepCopy()
                                        available.Sub(usedMem)
                                        if memRequest.Cmp(available) &gt; 0 </span><span class="cov0" title="0">{
                                                result.AddError(fmt.Sprintf("Memory request %s exceeds available quota %s", memRequest.String(), (&amp;available).String()))
                                        }</span>
                                }
                        }
                }
        }
}

// checkLimitRangeCompliance checks if resources comply with limit ranges
func (rv *ResourceValidator) checkLimitRangeCompliance(limitRange *corev1.LimitRange, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        for _, limit := range limitRange.Spec.Limits </span><span class="cov0" title="0">{
                if limit.Type != corev1.LimitTypeContainer </span><span class="cov0" title="0">{
                        continue</span>
                }

                // Check minimum constraints
                <span class="cov0" title="0">if limit.Min != nil </span><span class="cov0" title="0">{
                        rv.checkMinimumConstraints(limit.Min, resources, result)
                }</span>

                // Check maximum constraints
                <span class="cov0" title="0">if limit.Max != nil </span><span class="cov0" title="0">{
                        rv.checkMaximumConstraints(limit.Max, resources, result)
                }</span>

                // Check default ratio constraints
                <span class="cov0" title="0">if limit.MaxLimitRequestRatio != nil </span><span class="cov0" title="0">{
                        rv.checkRatioConstraints(limit.MaxLimitRequestRatio, resources, result)
                }</span>
        }
}

// checkMinimumConstraints validates minimum resource constraints
func (rv *ResourceValidator) checkMinimumConstraints(min corev1.ResourceList, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if resources.Requests != nil </span><span class="cov0" title="0">{
                for resourceName, minQuantity := range min </span><span class="cov0" title="0">{
                        if requestQuantity, ok := resources.Requests[resourceName]; ok </span><span class="cov0" title="0">{
                                if requestQuantity.Cmp(minQuantity) &lt; 0 </span><span class="cov0" title="0">{
                                        result.AddError(fmt.Sprintf("%s request %s is below minimum %s", resourceName, requestQuantity.String(), (&amp;minQuantity).String()))
                                }</span>
                        }
                }
        }
}

// checkMaximumConstraints validates maximum resource constraints
func (rv *ResourceValidator) checkMaximumConstraints(max corev1.ResourceList, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if resources.Limits != nil </span><span class="cov0" title="0">{
                for resourceName, maxQuantity := range max </span><span class="cov0" title="0">{
                        if limitQuantity, ok := resources.Limits[resourceName]; ok </span><span class="cov0" title="0">{
                                if limitQuantity.Cmp(maxQuantity) &gt; 0 </span><span class="cov0" title="0">{
                                        result.AddError(fmt.Sprintf("%s limit %s exceeds maximum %s", resourceName, limitQuantity.String(), (&amp;maxQuantity).String()))
                                }</span>
                        }
                }
        }
}

// checkRatioConstraints validates limit-to-request ratio constraints
func (rv *ResourceValidator) checkRatioConstraints(maxRatio corev1.ResourceList, resources corev1.ResourceRequirements, result *ValidationResult) <span class="cov0" title="0">{
        if resources.Requests == nil || resources.Limits == nil </span><span class="cov0" title="0">{
                return
        }</span>

        <span class="cov0" title="0">for resourceName, maxRatioQuantity := range maxRatio </span><span class="cov0" title="0">{
                request, hasRequest := resources.Requests[resourceName]
                limit, hasLimit := resources.Limits[resourceName]

                if hasRequest &amp;&amp; hasLimit &amp;&amp; !request.IsZero() </span><span class="cov0" title="0">{
                        ratio := float64(limit.MilliValue()) / float64(request.MilliValue())
                        maxAllowedRatio := float64(maxRatioQuantity.MilliValue()) / 1000.0 // Convert from milli

                        if ratio &gt; maxAllowedRatio </span><span class="cov0" title="0">{
                                result.AddError(fmt.Sprintf("%s limit-to-request ratio %.2f exceeds maximum %.2f", resourceName, ratio, maxAllowedRatio))
                        }</span>
                }
        }
}

// getQoSClass determines the QoS class of a pod
func getQoSClass(pod *corev1.Pod) corev1.PodQOSClass <span class="cov0" title="0">{
        requests := make(corev1.ResourceList)
        limits := make(corev1.ResourceList)
        zeroQuantity := resource.MustParse("0")
        isGuaranteed := true

        for _, container := range pod.Spec.Containers </span><span class="cov0" title="0">{
                // Accumulate requests
                for name, quantity := range container.Resources.Requests </span><span class="cov0" title="0">{
                        if value, exists := requests[name]; !exists </span><span class="cov0" title="0">{
                                requests[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                requests[name] = value
                        }</span>
                }

                // Accumulate limits
                <span class="cov0" title="0">for name, quantity := range container.Resources.Limits </span><span class="cov0" title="0">{
                        if value, exists := limits[name]; !exists </span><span class="cov0" title="0">{
                                limits[name] = quantity.DeepCopy()
                        }</span> else<span class="cov0" title="0"> {
                                value.Add(quantity)
                                limits[name] = value
                        }</span>
                }
        }

        // Check if guaranteed
        <span class="cov0" title="0">if len(requests) == 0 || len(limits) == 0 </span><span class="cov0" title="0">{
                isGuaranteed = false
        }</span> else<span class="cov0" title="0"> {
                for name, req := range requests </span><span class="cov0" title="0">{
                        if limit, exists := limits[name]; !exists || limit.Cmp(req) != 0 </span><span class="cov0" title="0">{
                                isGuaranteed = false
                                break</span>
                        }
                }
        }

        <span class="cov0" title="0">if isGuaranteed </span><span class="cov0" title="0">{
                return corev1.PodQOSGuaranteed
        }</span>

        // Check if burstable (has some requests or limits)
        <span class="cov0" title="0">for _, req := range requests </span><span class="cov0" title="0">{
                if req.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">for _, limit := range limits </span><span class="cov0" title="0">{
                if limit.Cmp(zeroQuantity) != 0 </span><span class="cov0" title="0">{
                        return corev1.PodQOSBurstable
                }</span>
        }

        <span class="cov0" title="0">return corev1.PodQOSBestEffort</span>
}

// ClearCaches clears all internal caches
func (rv *ResourceValidator) ClearCaches() <span class="cov0" title="0">{
        rv.nodeCache = make(map[string]*corev1.Node)
        rv.quotaCache = make(map[string]*corev1.ResourceQuota)
        rv.limitRanges = make(map[string][]*corev1.LimitRange)
}</span>

// RefreshCaches refreshes all caches
func (rv *ResourceValidator) RefreshCaches(ctx context.Context) error <span class="cov0" title="0">{
        rv.ClearCaches()

        // Pre-populate node cache
        nodeList := &amp;corev1.NodeList{}
        if err := rv.client.List(ctx, nodeList); err != nil </span><span class="cov0" title="0">{
                return fmt.Errorf("failed to list nodes: %v", err)
        }</span>

        <span class="cov0" title="0">for i := range nodeList.Items </span><span class="cov0" title="0">{
                node := &amp;nodeList.Items[i]
                rv.nodeCache[node.Name] = node
        }</span>

        <span class="cov0" title="0">logger.Info("Refreshed resource validator caches with %d nodes", len(rv.nodeCache))
        return nil</span>
}
</pre>
		
		</div>
	</body>
	<script>
	(function() {
		var files = document.getElementById('files');
		var visible;
		files.addEventListener('change', onChange, false);
		function select(part) {
			if (visible)
				visible.style.display = 'none';
			visible = document.getElementById(part);
			if (!visible)
				return;
			files.value = part;
			visible.style.display = 'block';
			location.hash = part;
		}
		function onChange() {
			select(files.value);
			window.scrollTo(0, 0);
		}
		if (location.hash != "") {
			select(location.hash.substr(1));
		}
		if (!visible) {
			select("file0");
		}
	})();
	</script>
</html>
