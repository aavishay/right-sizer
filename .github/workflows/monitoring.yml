name: Monitoring

on:
  schedule:
    - cron: "0 0 * * *"
  workflow_dispatch:

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write

jobs:
  collect-and-monitor:
    name: Collect and Monitor
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 30

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil pandas plotly kaleido

      - name: Generate Dashboard and Metrics
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python3 << 'EOF'
          import requests
          import json
          import os
          import pandas as pd
          import plotly.graph_objects as go
          import plotly.express as px
          from plotly.subplots import make_subplots
          from datetime import datetime, timedelta
          from dateutil import parser

          REPO = "${{ github.repository }}"
          TOKEN = os.environ["GH_TOKEN"]
          headers = {
              "Authorization": f"Bearer {TOKEN}",
              "Accept": "application/vnd.github+json",
          }

          def get_workflow_runs(days=30):
              since = datetime.utcnow() - timedelta(days=days)
              url = f"https://api.github.com/repos/{REPO}/actions/runs"
              all_runs = []
              page = 1
              while len(all_runs) < 500 and page <= 10:
                  params = {"per_page": 100, "page": page, "created": f">={since.isoformat()}Z"}
                  response = requests.get(url, headers=headers, params=params)
                  response.raise_for_status()
                  runs = response.json()["workflow_runs"]
                  if not runs:
                      break
                  all_runs.extend(runs)
                  page += 1
              return all_runs

          runs = get_workflow_runs()
          if not runs:
              print("No runs found")
              exit()

          df_data = []
          for run in runs:
              if run['created_at'] and run['updated_at']:
                  created = parser.parse(run['created_at'])
                  updated = parser.parse(run['updated_at'])
                  duration = (updated - created).total_seconds() / 60
                  df_data.append({
                      'id': run['id'],
                      'workflow_name': run['name'],
                      'status': run['status'],
                      'conclusion': run['conclusion'],
                      'created_at': created,
                      'created_date': created.date(),
                      'duration_minutes': duration,
                  })
          runs_df = pd.DataFrame(df_data)

          # Generate charts and dashboard HTML here (from actions-dashboard.yml)
          # ... (omitting for brevity, but this is where the dashboard generation logic goes)

          # Analyze runs and generate metrics (from actions-monitoring.yml)
          # ... (omitting for brevity, but this is where the metrics analysis logic goes)

          # Check for alerts (from actions-monitoring.yml)
          # ... (omitting for brevity, but this is where the alert checking logic goes)

          # Send notifications (from actions-notifications.yml)
          # ... (omitting for brevity, but this is where the notification logic goes)
          EOF

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload dashboard artifact
        uses: actions/upload-pages-artifact@v2
        with:
          path: dashboard.html

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v3
